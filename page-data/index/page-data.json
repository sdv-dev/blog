{"componentChunkName":"component---src-templates-index-js","path":"/","result":{"data":{"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__63d180e2304f20003d70b744","title":"3 user-centric growth strategies for open source","slug":"os-user-strategies","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2023/01/Header.png","excerpt":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used along the way.","custom_excerpt":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used along the way.","visibility":"public","created_at_pretty":"25 January, 2023","published_at_pretty":"26 January, 2023","updated_at_pretty":"26 January, 2023","created_at":"2023-01-25T14:20:02.000-05:00","published_at":"2023-01-25T19:39:12.000-05:00","updated_at":"2023-01-26T15:31:32.000-05:00","meta_title":"3 user-centric growth strategies for open source","meta_description":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used along the way.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used.","twitter_image":null,"twitter_title":"3 user-centric growth strategies for open source","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In a previous article, we discussed why, when developing our open source libraries, we emphasize growing our overall users – not just our contributors. We elaborated on why we focus on everyone who uses our software to solve a problem, as opposed to following the more traditional open source practice of catering specifically to code contributors.\n\nBut we cannot stop at defining our focus – we have to put it into practice. In this article, we'll share some practical strategies we have learned in the course of adopting this more user-centric mindset.\n\nWe have come to these strategies by regularly interacting with the users who have adopted the SDV ecosystem, and we've iterated them until we found success. (Some of our libraries are already at 1 million downloads!) This has given us confidence in our approach, which we're excited to share below.\n\n\n1. Find the right channels to reach more users\n\nOur first strategy involves our overall presence as an open source ecosystem.\n\nShifting our focus to users has allowed us to think more critically about who we are trying to help, and whether we are actually reaching them. For example, we were initially prioritizing checking and responding to questions on GitHub, a platform that makes it easy to reference technical material and scrutinize bugs.\n\nBut GitHub caters primarily to contributors – and thus leaves out the rest of the users we'd like to reach. In fact, those users may not have GitHub accounts at all! They are more likely to feel at home when they can ask us questions directly, working with us to improve their understanding. They often don't have the time to dig through technical discussions, or the desire to create an issue on GitHub, especially if their question is more fundamental. (Since “issue creation” has always been defined as a part of the software development lifecycle, users may not feel comfortable asking more basic questions there.)\n\nTo find the users we wanted, we decided to expand our presence to other platforms that cater to their needs. We have found Slack to be a great solution – it is welcoming and easy to use, and enables direct communication. Today, our Slack is a fast-growing community of over 800 members, and a new space for us to learn about how people use our software.\n\n\n2. Users are just as important as contributors\n\nOur attitude towards users matters just as much as their ability to find us.\n\nAs the core maintainers for an open source project, we all have a deep passion for software. It is natural for us to want our users to share this passion – and also natural to perceive a lack of initiative if a user hasn't understood certain concepts. But in our drive to recognize the importance of all users, we have learned to understand — and even embrace — that many users have different needs and time pressures than we are used to.\n\nFor example, we frequently receive questions about how to upload a CSV file into Python. This is a standard data science procedure, so some might label this question as \"lazy.\" We don't believe that's true. In fact, these users may be picking up Python for the first time because they think our software could solve their problem, which shows a lot of initiative. They are not unqualified to use our library; they might just need a helping hand.\n\nTo figure out what will actually help users, we put ourselves in their shoes. This mindset has led to some of our current best practices:\n\n * Empathize with the user's pain points. Working on software openly means that we'll get more feedback more often. Often, an issue identified by a user may already be on our roadmap, is inspiring internal debates, or is on hold until we have more resources. When we're reminded of such an issue, it can be easy to get defensive and engage in a debate – which ultimately wastes everyone's time. Instead, we use the opportunity to build camaraderie. We always try to replicate users' issues, which helps us acknowledge the frustration because we feel it too. No software is perfect!\n * Focus on the problem, not the solution. Because our users do not have our domain expertise, they'll sometimes request features that seem difficult to accommodate. When this happens, we remind ourselves that it's not the user's job to understand our system. Rather, it's our duty to dig deeper and find the root of the concern. This helps us design new features in a way that matches our vision and satisfies users.\n * Above all else, move them forward. When a user has a request, we aim to provide a timely, focused response so that they can take the next step in their usage journey. If we can't immediately resolve the issue, we provide workarounds that allow their projects to proceed. This is more difficult than it seems. At times, we want to passionately respond with our own long-term vision — but this is not useful to users who just want their project to work.\n\nThe illustration below shows a hypothetical example of using these best practices.\n\nThese best practices reflect our overall attitude, which elevates users to the same level of importance as open source contributors.\n\n\n3. Go the extra mile – it only takes a few minutes!\n\nGoing above and beyond can mean creating special material for users and learning to speak their language. By now, it has become standard practice for us to disambiguate and translate our technical communications for a more general audience.\n\nOur SDV ecosystem is filled with examples of conveying the same information in multiple ways. Below are some excerpts from our announcement of a new version of SDV (0.16.0) in July 2022.\n\n\nThe SDV open source contributors are familiar with technical concepts like “unify sampling params for reject sampling” or “Add create_custom_constraint factory method”. They're also interested in following along with specific GitHub issues, which link to the code changes.\n\nMeanwhile, user-centric communication focuses on the pain points that we've solved. This is informative for current users and welcoming for new ones. As a result, users coming to our library for the first time can scan through the Slack channel to see what we're working on. Best of all, because we're thinking in these different ways already, it only takes a few minutes to draft these different types of announcements!\n\n\nConclusion\n\nAdopting a user-centric mindset has significantly contributed to our open source growth. We started by identifying users and finding the right channels to reach them, which naturally expanded our open source presence. Then we learned to empathize with users and embrace their needs, which has manifested as more productive conversations and relationships. Finally, we always think it's great to go above and beyond – especially if it only takes a few minutes!\n\nAre there any strategies we've missed? Let us know what you think in the comments below!","html":"<p>In a <a href=\"https://datacebo.com/blog/open-source-user-demographic\">previous article</a>, we discussed why, when developing our open source libraries, we emphasize growing our overall users – not just our contributors. We elaborated on why we focus on everyone who <em>uses</em> our software to solve a problem, as opposed to following the more traditional open source practice of catering specifically to code contributors.</p><p>But we cannot stop at defining our focus – we have to put it into practice. In this article, we'll share some practical strategies we have learned in the course of adopting this more user-centric mindset. </p><p>We have come to these strategies by regularly interacting with the users who have adopted the <a href=\"https://sdv.dev/\">SDV ecosystem</a>, and we've iterated them until we found success. (Some of our libraries are already at <a href=\"https://pepy.tech/project/copulas\">1 million downloads</a>!) This has given us confidence in our approach, which we're excited to share below.</p><h3 id=\"1-find-the-right-channels-to-reach-more-users\">1. Find the right channels to reach more users</h3><p>Our first strategy involves our overall presence as an open source ecosystem.</p><p>Shifting our focus to users has allowed us to think more critically about who we are trying to help, and whether we are actually reaching them. For example, we were initially prioritizing checking and responding to questions on <a href=\"https://github.com/sdv-dev/SDV/issues\">GitHub</a>, a platform that makes it easy to reference technical material and scrutinize bugs. </p><p>But GitHub caters primarily to contributors – and thus leaves out the rest of the users we'd like to reach. In fact, those users may not have GitHub accounts at all! They are more likely to feel at home when they can ask us questions directly, working with us to improve their understanding. They often don't have the time to dig through technical discussions, or the desire to create an issue on GitHub, especially if their question is more fundamental. (Since “issue creation” has always been defined as a part of the software development lifecycle, users may not feel comfortable asking more basic questions there.)</p><p>To find the users we wanted, we decided to <strong>expand our presence to other platforms that cater to their needs</strong>. We have found Slack to be a great solution – it is welcoming and easy to use, and enables direct communication. Today, <a href=\"https://bit.ly/sdv-slack-invite\">our Slack</a> is a fast-growing community of over 800 members, and a new space for us to learn about how people use our software.</p><h3 id=\"2-users-are-just-as-important-as-contributors\">2. Users are just as important as contributors</h3><p>Our attitude towards users matters just as much as their ability to find us.</p><p>As the core maintainers for an open source project, we all have a deep passion for software. It is natural for us to want our users to share this passion – and also natural to perceive a lack of initiative if a user hasn't understood certain concepts. But in our drive to recognize the importance of all users, we have learned to understand — and even embrace — that many users have different needs and time pressures than we are used to.</p><p>For example, we frequently receive questions about how to upload a CSV file into Python. This is a standard data science procedure, so some might label this question as \"lazy.\" We don't believe that's true. In fact, these users may be picking up Python for the first time because they think our software could solve their problem, which shows a lot of initiative. They are not unqualified to use our library; they might just need a helping hand.</p><p>To figure out what will actually help users, we put ourselves in their shoes. This mindset has led to some of our current best practices:</p><ul><li><strong>Empathize with the user's pain points.</strong> Working on software openly means that we'll get more feedback more often. Often, an issue identified by a user may already be on our roadmap, is inspiring internal debates, or is on hold until we have more resources. When we're reminded of such an issue, it can be easy to get defensive and engage in a debate – which ultimately wastes everyone's time. Instead, we use the opportunity to build camaraderie. We always try to replicate users' issues, which helps us acknowledge the frustration because we feel it too. No software is perfect!</li><li><strong>Focus on the problem, not the solution.</strong> Because our users do not have our domain expertise, they'll sometimes request features that seem difficult to accommodate. When this happens, we remind ourselves that it's not the user's job to understand our system. Rather, it's our duty to dig deeper and find the root of the concern. This helps us design new features in a way that matches our vision <em>and</em> satisfies users.</li><li><strong>Above all else, move them forward. </strong>When a user has a request, we aim to provide a timely, focused response so that they can take the next step in their usage journey. If we can't immediately resolve the issue, we provide workarounds that allow their projects to proceed. This is more difficult than it seems. At times, we want to passionately respond with our own long-term vision — but this is not useful to users who just want their project to work.</li></ul><p>The illustration below shows a hypothetical example of using these best practices.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Conversation-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Conversation-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Conversation-2.png 1000w, https://sdv.ghost.io/content/images/2023/01/Conversation-2.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>An example of a conversation the SDV team might have with a user. In this instance, the user is requesting a new algorithm, which may not be compatible with our current software. But the root concern is data quality – a need that we can address more quickly through other workarounds.</em></figcaption></figure><p>These best practices reflect our overall attitude, which elevates users to the same level of importance as open source contributors.</p><h3 id=\"3-go-the-extra-mile-%E2%80%93-it-only-takes-a-few-minutes\">3. Go the extra mile – it only takes a few minutes!</h3><p>Going above and beyond can mean creating special material for users and learning to speak their language. By now, it has become standard practice for us to disambiguate and translate our technical communications for a more general audience. </p><p>Our SDV ecosystem is filled with examples of conveying the same information in multiple ways. Below are some excerpts from our announcement of a new version of SDV (0.16.0) in July 2022.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Communication-Styles-Comparison-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Communication-Styles-Comparison-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Communication-Styles-Comparison-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Communication-Styles-Comparison-1.png 1600w, https://sdv.ghost.io/content/images/2023/01/Communication-Styles-Comparison-1.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>Selected excerpts from announcements of a new SDV version, disseminated on two different platforms. We communicate the same information in different ways based on what we know about our users.</em></figcaption></figure><p><br>The SDV open source contributors are familiar with technical concepts like “unify sampling params for reject sampling” or “Add create_custom_constraint factory method”. They're also interested in following along with specific GitHub issues, which link to the code changes.</p><p>Meanwhile, user-centric communication focuses on the pain points that we've solved. This is informative for current users and welcoming for new ones. As a result, users coming to our library for the first time can scan through the Slack channel to see what we're working on. Best of all, because we're thinking in these different ways already, it only takes a few minutes to draft these different types of announcements!</p><h3 id=\"conclusion\">Conclusion</h3><p>Adopting a user-centric mindset has significantly contributed to our open source growth. We started by identifying users and finding the right channels to reach them, which naturally expanded our open source presence. Then we learned to empathize with users and embrace their needs, which has manifested as more productive conversations and relationships. Finally, we always think it's great to go above and beyond – especially if it only takes a few minutes!</p><p><em>Are there any strategies we've missed? Let us know what you think in the comments below!</em></p>","url":"https://sdv.ghost.io/os-user-strategies/","canonical_url":"https://datacebo.com/blog/os-user-strategies","uuid":"39669dee-8188-4936-82a2-741037eb0516","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63d180e2304f20003d70b744","reading_time":5}},{"node":{"id":"Ghost__Post__63cee0ef89aa88003d872ba8","title":"The Most Important Open Source Demographic That No One Thinks About","slug":"open-source-user-demographic","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2023/01/Frame.png","excerpt":"How we define a user in 2023 to build a community around synthetic data. ","custom_excerpt":"How we define a user in 2023 to build a community around synthetic data. ","visibility":"public","created_at_pretty":"23 January, 2023","published_at_pretty":"23 January, 2023","updated_at_pretty":"31 January, 2023","created_at":"2023-01-23T14:33:03.000-05:00","published_at":"2023-01-23T16:23:26.000-05:00","updated_at":"2023-01-31T08:36:15.000-05:00","meta_title":"The most important open source demographic that no one thinks about. ","meta_description":"How we define a user in 2023 to build a community around synthetic data. ","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Defining an open source user is a crucial step in discovering enterprise use cases for synthetic data. ","twitter_image":null,"twitter_title":"Defining an open source user for 2023 and beyond","authors":[{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"}],"primary_author":{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Defining an Open Source User for 2023 and beyond\n\nCode contributors are an essential part of an open source (OS) project. But in our experience, making code contributors the sole focus of an open source project ends up disenfranchising another large segment of important people: a library's users. This segment, we have found, is more critical to our success, providing indispensable feedback, finding use cases and helping us to improve our open source and the product that relies on it. In this first article (in a series), we synthesize key attributes that we use to identify a user.\n\nTraditionally, open source libraries have been centered around software development, as collaborating on code is vital for maintaining complex software. It has become customary to use the number of unique code contributors as a core metric of a given library's success. Metrics of success drive how the overall ecosystem is maintained, including how software is designed (APIs), the audience for which usage guides are developed, the types of demos that are built, and how communications are handled. To bring users into fold, all these need to be revisited keeping them in mind.\n\nAt the same time, open source is proving to be a successful model for startups. As the core maintainers of the Synthetic Data Vault project — the world's largest open source library for modeling and generating tabular synthetic data — we are constantly striving to realize the benefits of this model firsthand. For us, open source has been vital to building a trusted and usable machine learning system. With this and subsequent articles we are synthesizing our current thinking about open source, and some key lessons we have learned on our way to this point.\n\n\nWho is a user?\n\nOur definition of a user is: Anyone who attempts to use our open source library to solve their problem. Generally, users:\n\n * …are goal-oriented. A user comes to our library with a specific project that they're working on.\n * …have limited time. A user often has a deadline for their project. They may not have time to learn the nitty-gritty details of our software, or engage in deeper conversations about its development.\n * … have different expertise. A user is probably coming to our library to help with a project in their own domain, whether that's healthcare, clean energy or something else. They might not have the same knowledge base as a professional software developer would (although they also might — more on this later).\n\nWhile this definition may seem straightforward, these attributes have become the cornerstone of how we maintain and communicate about our software, and  how we develop APIs. They have also inspired the main question we use to measure our progress: Is our library making a material difference in users' projects? In subsequent articles, we plan to share how we applied these strategies to build the largest open source user community around synthetic data, and what we have learned in the process.\n\n\nWhat changes are we making to set up an OS for success?\n\nCharting this path with a laser-sharp focus on the “user” has required us to address some commonly asked questions up front, both for our team and externally. Here are just a few.\n\nUsers are developers too and probably more critical for our success\n\nJust because a user isn't interested in learning the internal details of our software doesn't mean we can automatically categorize them as not a developer. They may be experts in other fields and may be developing software there. In addition, they are still using our Python API to help them with their project — and therefore, they are developing software. To expand and serve our user base, we focus our efforts on what we want to achieve with our open source strategy, rather than creating different strategies based on the perceived skill level of who is using our library. As a result, we want every API we publish to be understandable and usable by everyone. We want our communications to be cognizant of the fact - they don't have time! In 2023, we believe that everyone is a developer — or at least, we like to serve everyone and make them part of the software movement.\n\nUser friendly APIs are game changers\n\nOne question we asked ourselves was \"shouldn't the user friendliness delegated to graphical user interfaces (GUIs)?\". GUIs finalize a straight, stepwise process to successful project completion, while the code provides flexibility to try things slightly differently. When they feel restricted by the straight stepwise process for their specific project/use case, pioneering users instead use code. Creating a user-friendly API that lets users apply our open source to their project in a transparent way, and provides access to different metrics and progress states at different stages, gives our users a great chance at succeeding. It also helps us to efficiently discover more pathways, and most importantly, more use cases. This makes our open source essentially a low-code version of what goes into the product.\n\nGithub stars are not enough\n\nGithub star histories are regularly used to indicate an exponential growth curve for a library. They are often considered a leading indicator for a need in the market that the library may be targeting, or top of the funnel for an open source, and there are now well-developed strategies for growing stars over time. Used effectively, we find these strategies to be a good marketing tool, and well-intentioned for increasing the top of the funnel. We ourselves use them from time to time, as they increase reach and can bring in more users. But we find that they should be balanced with feature development, carefully listening to users, and measuring how often folks are downloading and using the library and raising issues. Star growth should be followed by growth in downloads and issues raised by users.\n\n\n\nWe look forward to discussing our experiences with open sourcing in 2023 and beyond. In the articles that follow, we will share some more of our strategies and measures for engagement. We welcome any thoughts, comments, suggestions and questions below.\n","html":"<p><strong><strong>Defining an Open Source User for 2023 and beyond</strong></strong></p><p>Code contributors are an essential part of an open source (OS) project. But in our experience, making code contributors the sole focus of an open source project ends up disenfranchising another large segment of important people: a library's<strong> </strong><em><strong>users</strong></em>. This segment, we have found, is more critical to our success, providing indispensable feedback, finding use cases and helping us to improve our open source and the product that relies on it. In this first article (in a series), we synthesize key attributes that we use to identify a user. </p><p>Traditionally, open source libraries have been centered around software development, as collaborating on code is vital for maintaining complex software. It has become customary to use the number of unique code contributors as a core metric of a given library's success. Metrics of success drive how the overall ecosystem is maintained, including how software is designed (APIs), the audience for which usage guides are developed, the types of demos that are built, and how communications are handled. To bring users into fold, all these need to be revisited keeping them in mind. </p><p>At the same time, open source is <a href=\"https://www.bvp.com/atlas/roadmap-open-source\">proving to be a successful model</a> for startups. As the core maintainers of the <a href=\"https://github.com/sdv-dev/SDV\">Synthetic Data Vault project</a> — the world's largest open source library for modeling and generating tabular synthetic data — we are constantly striving to realize the benefits of this model firsthand. For us, open source has been <a href=\"https://sdv.dev/blog/intro-to-sdv/\">vital to building a trusted and usable machine learning system</a>. With this and subsequent articles we are synthesizing our current thinking about open source, and some key lessons we have learned on our way to this point.</p><h3 id=\"who-is-a-user\">Who is a user?</h3><p>Our definition of a<em> </em>user is: Anyone who attempts to use <em>our</em> open source library to solve <em>their</em> problem. Generally, <em>users</em>:</p><ul><li><strong>…are goal-oriented.</strong> A user comes to our library with a specific project that they're working on.</li><li><strong>…have limited time.</strong> A user often has a deadline for their project. They may not have time to learn the nitty-gritty details of our software, or engage in deeper conversations about its development.</li><li><strong>… have different expertise.</strong> A user is probably coming to our library to help with a project in their own domain, whether that's healthcare, clean energy or something else. They might not have the same knowledge base as a professional software developer would (although they also might — more on this later). </li></ul><p>While this definition may seem straightforward, these attributes have become the cornerstone of how we maintain and communicate about our software, and  how we develop APIs. They have also inspired the main question we use to measure our progress: <em>Is our library making a material difference in users' projects?</em> In subsequent articles, we plan to share how we applied these strategies to build the largest open source <em>user</em> community around synthetic data, and what we have learned in the process.</p><h3 id=\"what-changes-are-we-making-to-set-up-an-os-for-success\">What changes are we making to set up an OS for success?</h3><p>Charting this path with a laser-sharp focus on the “<em>user</em>” has required us to address some commonly asked questions up front, both for our team and externally. Here are just a few.</p><p><strong>Users are developers too and probably more critical for our success </strong></p><p>Just because a user isn't interested in learning the internal details of <em>our</em> software doesn't mean we can automatically categorize them as <em>not a developer</em>. They may be experts in other fields and may be developing software there. In addition, they are still using our Python API to help them with their project — and therefore, they are developing software. To expand and serve our user base, we focus our efforts on what we want to achieve with our open source strategy, rather than creating different strategies based on the perceived skill level of who is using our library. As a result, we want every API we publish to be understandable and usable by everyone. We want our communications to be cognizant of the fact - they don't have time! In 2023, <em>we believe that everyone is a developer</em> — or at least, we like to serve everyone and make them part of the software movement.</p><p><strong>User friendly APIs are game changers</strong></p><p>One question we asked ourselves was \"shouldn't the user friendliness delegated to graphical user interfaces (GUIs)?\". GUIs finalize a <em>straight, stepwise process to successful project completion</em>, while the code provides flexibility to try things slightly differently. When they feel restricted by the straight stepwise process for their specific project/use case, pioneering users instead use code. Creating a user-friendly API that lets users apply our open source to their project in a transparent way, and provides access to different metrics and progress states at different stages, gives our users a great chance at succeeding. It also helps us to efficiently discover more pathways, and most importantly, more use cases. This makes our open source essentially a <em>low-code</em> version of what goes into the product.</p><p><strong>Github stars are not enough</strong></p><p>Github star histories are regularly used to indicate an exponential growth curve for a library. They are often considered a leading indicator for a need in the market that the library may be targeting, or top of the funnel for an open source, and there are now well-developed strategies for growing stars over time. Used effectively, we find these strategies to be a good marketing tool, and well-intentioned for increasing the top of the funnel. We ourselves use them from time to time, as they increase reach and can bring in more users. But we find that they should be balanced with feature development, carefully listening to users, and measuring how often folks are downloading and using the library and raising issues. Star growth should be followed by growth in downloads and issues raised by users.</p><p></p><p><em>We look forward to discussing our experiences with open sourcing in 2023 and beyond. In the articles that follow, we will share some more of our strategies and measures for engagement. We welcome any thoughts, comments, suggestions and questions below.</em><br></p>","url":"https://sdv.ghost.io/open-source-user-demographic/","canonical_url":"https://datacebo.com/blog/open-source-user-demographic","uuid":"206243fc-09c4-4d8e-a367-78560f814b29","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63cee0ef89aa88003d872ba8","reading_time":4}},{"node":{"id":"Ghost__Post__63b4711dac52ed003d6a1744","title":"Can you use synthetic data for label balancing?","slug":"synthetic-label-balancing","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2023/01/Header--1-.png","excerpt":"Imbalanced data can prevent your projects from succeeding. Will synthetic data work? Explore the rationale behind label balancing.","custom_excerpt":"Imbalanced data can prevent your projects from succeeding. Will synthetic data work? Explore the rationale behind label balancing.","visibility":"public","created_at_pretty":"03 January, 2023","published_at_pretty":"10 January, 2023","updated_at_pretty":"23 January, 2023","created_at":"2023-01-03T13:17:01.000-05:00","published_at":"2023-01-10T12:59:16.000-05:00","updated_at":"2023-01-23T14:49:21.000-05:00","meta_title":"Synthetic Data for Label Balancing","meta_description":"Imbalanced data can prevent your projects from succeeding. Will synthetic data work? Explore the rationale behind label balancing.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Imbalanced data can prevent your projects from succeeding. Will synthetic data work? Explore the rationale behind label balancing.","twitter_image":null,"twitter_title":"Synthetic Data for Label Balancing","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Applications","slug":"applications","description":"This blog focuses on the value that synthetic data brings to solving enterprise problems. Synthetic data can be used to test applications, develop unbiased AI models and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Applications","slug":"applications","description":"This blog focuses on the value that synthetic data brings to solving enterprise problems. Synthetic data can be used to test applications, develop unbiased AI models and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"A dataset can unlock many doors for your organization, helping with everything from predictive forecasting to data-driven decision making. But in some situations, you may not have all of the data that you need. A common scenario is having too few data points, which can lead to an imbalance of variables.\n\nIn this article, we'll take a closer look at this scenario. We'll recap why this can be a problem for your projects and walk you through some possible solutions. We'll end by explaining why synthetic data might be especially useful for overcoming this challenge.\n\n\nWhy is it a problem to have a data imbalance?\n\nAt a basic level, data is a record of events, and a data imbalance happens when some events occur much less frequently than others. For example:\n\n * In healthcare, cancer occurs less frequently than diabetes\n * In finance, it's rare to see fraudulent credit card charges\n * In local government, it's rare to have a day with a major natural disaster such as a fire\n\nA natural data imbalance isn't inherently a problem, but it can become one if the rare events are important. As an example, let's assume you're working at a hospital that is treating COVID patients. One day a new COVID variant – let's call it Variant X – appears in the population. Since it is so new, it currently occurs very rarely (<2.5% of the time). This leads to a data imbalance for this COVID variant, as illustrated below.\n\nThis imbalance is a problem when it's critical to account for Variant X. For example, you may want to build a predictive model for who is most likely to be hospitalized. If you use the data as-is, your model may only consider Omicron (the majority) and treat Variant X as an outlier. This can lead to poor predictions – and bad planning – because Variant X may soon become the dominant strain.\n\n\nUsing Data Augmentation to Fix Imbalances\n\nIn an ideal world, your data would include more patients with Variant X. But until then, you need to find a solution that will allow you to produce reasonable predictions. What if you create some artificial patient data for the sake of making a robust predictive model?\n\nLet's assume you have data for 1,000 COVID hospital patients, 975 with the Omicron variant and 25 with Variant X. If you can create 950 additional artificial Variant X patients, then you can create an evenly-balanced dataset. This process is illustrated below.\n\nYou may be skeptical because there are only 25 patients with Variant X to begin with. How can we reasonably produce 950 more based on that? As usual with data science, the devil is in the details. Let's go through some approaches to see what works.\n\n\nAttempt #1: Oversampling\n\nYour first instinct may be to take the existing 25 Variant X patients and weigh them more heavily. One easy way to achieve this: You can duplicate each original patient 40 times to get 1,000 patients.\n\nIn data science, this is known as oversampling. Sometimes, this is done programmatically, sampling patients (with replacement) as many times as needed. Other times, this can be achieved using mathematical formulas to provide weights. An illustration is shown below.\n\nWith oversampling, Variant X is no longer rare, so your model cannot ignore it. But if you actually use this data, your project may not be successful. Your model may confidently predict that all Variant X patients must be over the age of 50. But this is not necessarily right – just because the existing patients had these characteristics doesn't mean Variant X patients always will.\n\nThe mistake was over-emphasizing the same set of patients, making the model more likely to create strong claims. This is commonly referred to as overfitting the data: The model over-emphasizes the importance of a small number of records, and makes blanket predictions that lack nuance.\n\n\nAttempt #2: Randomizing\n\nTo avoid the problems that come with oversampling, let's explore the opposite direction for argument's sake: What if we created artificial Variant X patients by choosing variables completely at random? An example is illustrated below.\n\nRandomization avoids overfitting because no patient is repeated. But this approach introduces problems of its own: You may find that the data doesn't make sense anymore. The example data above highlights some problems that can arise. We see an artificial 23-year-old patient with dementia, and many diabetic patients with low BMIs. In the medical world, these events are not likely and indicate that there is a problem with the data.\n\nThese inconsistencies may (rightfully) dissuade you from using randomization. Since random data lacks patterns, a model will not be able to draw conclusions from it. In data science, we call this a problem of noisiness. Noisy data has too many random combinations to produce any useful learnings.\n\n\nA Better Solution: Defining Neighborhoods\n\nSo far, we've seen attempts at extreme ends.\n\n 1. Oversampling will emphasize one set of patients, leading to an overfit model\n 2. Randomizing will make the dataset noisy, precluding useful conclusions\n\nThe solution we need falls somewhere in the middle: We'd like to loosely base the artificial patients on the real ones. This is related to the data science concept of neighborhoods. Drawing a neighborhood around some patients identifies general commonalities between them – without setting any strict rules. For example, Variant X patients may be more likely to have had a known exposure, but it's not guaranteed. Note that there is no exact definition for a neighborhood. It can change based on our assumptions and how broad we want to make it.\n\nOnce we know a neighborhood, we can create artificial patients that are inside it. These patients won't be exactly the same as the existing ones, but they won't have completely random values either.\n\nSynthetic Data for Label Balancing\n\nA compelling solution for discovering neighborhoods is synthetic data. A synthetic data software – such as our open source Synthetic Data Vault (SDV) – uses machine learning to learn patterns from real patients, and then creates synthetic patients.\n\nThe SDV discovers neighborhoods at a variety of levels in the form of trends. It's able to learn overall trends (for all patients) as well as trends that are unique to a variable (such as Variant X). For example:\n\n * For all patients, a higher age corresponds to a greater risk of dementia and a higher BMI corresponds to a greater risk of diabetes.\n * Variant X patients tend to be older, while Omicron patients tend to be younger.\n * Etc.\n\nAs a result, synthetic patients have some variation – but the data still makes sense in context. An example table of SDV-generated patients is shown below.\n\nThis is the middle solution we were looking for: Synthetic data won't cause overfitting and is less noisy than randomization. The best part is that there are multiple synthetic data techniques and settings available in the SDV, providing flexibility and tradeoffs.\n\n\nTakeaways\n\nIn this article, we explored imbalanced datasets. It is common to have an imbalanced dataset due to rare events – which becomes a problem if those rare events are important for your project.\n\nFixing the imbalance problem requires a careful tradeoff between overfitting data and creating noisy data. Synthetic data is a compelling solution that achieves a middle ground by discovering neighborhoods of similar data. This allows you to realistically fix the imbalance without resorting to either extreme.\n\nAre you interested in label balancing? Have you already explored using the SDV for this problem? Drop us a comment below!","html":"<p>A dataset can unlock many doors for your organization, helping with everything from predictive forecasting to data-driven decision making. But in some situations, you may not have all of the data that you need. A common scenario is having too few data points, which can lead to an imbalance of variables.</p><p>In this article, we'll take a closer look at this scenario. We'll recap why this can be a problem for your projects and walk you through some possible solutions. We'll end by explaining why <strong>synthetic data</strong><em><strong> </strong></em>might be especially useful for overcoming this challenge.</p><h3 id=\"why-is-it-a-problem-to-have-a-data-imbalance\">Why is it a problem to have a data imbalance?</h3><p>At a basic level, data is a record of events, and a <strong>data</strong> <strong>imbalance</strong> happens when some events occur much less frequently than others. For example:</p><ul><li>In healthcare, cancer occurs less frequently than diabetes</li><li>In finance, it's rare to see fraudulent credit card charges</li><li>In local government, it's rare to have a day with a major natural disaster such as a fire</li></ul><p>A natural data imbalance isn't inherently a problem, but it can become one if the rare events are important. As an example, let's assume you're working at a hospital that is treating COVID patients. One day a new COVID variant – let's call it Variant X – appears in the population. Since it is so new, it currently occurs very rarely (&lt;2.5% of the time). This leads to a data imbalance for this COVID variant, as illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Original-Dataset--2-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Original-Dataset--2-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Original-Dataset--2-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Original-Dataset--2-.png 1600w, https://sdv.ghost.io/content/images/2023/01/Original-Dataset--2-.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>A hypothetical dataset of COVID patients. Each patient has multiple variables – Age, BMI, etc. The variable \"COVID Variant\" has an imbalance: Variant X is far less common than Omicron.</em></figcaption></figure><p>This imbalance is a problem when it's critical to account for Variant X. For example, you may want to build a predictive model for who is most likely to be hospitalized. If you use the data as-is, your model may only consider Omicron (the majority) and treat Variant X as an outlier. This can lead to poor predictions – and bad planning – because Variant X may soon become the dominant strain.</p><h3 id=\"using-data-augmentation-to-fix-imbalances\">Using Data Augmentation to Fix Imbalances</h3><p>In an ideal world, your data would include more patients with Variant X. But until then, you need to find a solution that will allow you to produce reasonable predictions. What if you create some artificial patient data for the sake of making a robust predictive model? </p><p>Let's assume you have data for 1,000 COVID hospital patients, 975 with the Omicron variant and 25 with Variant X. If you can create 950 additional artificial Variant X patients, then you can create an evenly-balanced dataset. This process is illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Label-Balancing--2-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Label-Balancing--2-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Label-Balancing--2-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Label-Balancing--2-.png 1600w, https://sdv.ghost.io/content/images/2023/01/Label-Balancing--2-.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>You can balance your data by creating artificial patients who all have Variant X. When you combine the new patients with the existing ones, you will have a balanced dataset, with 50% Omicron and 50% Variant X.</em></figcaption></figure><p>You may be skeptical because there are only 25 patients with Variant X to begin with. How can we reasonably produce 950 more based on that? As usual with data science, the devil is in the details. Let's go through some approaches to see what works.</p><h3 id=\"attempt-1-oversampling\">Attempt #1: Oversampling</h3><p>Your first instinct may be to take the existing 25 Variant X patients and weigh them more heavily. One easy way to achieve this: You can duplicate each original patient 40 times to get 1,000 patients.</p><p>In data science, this is known as <a href=\"https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\">oversampling</a>. Sometimes, this is done programmatically, sampling patients (with replacement) as many times as needed. Other times, this can be achieved using mathematical formulas to provide weights. An illustration is shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Oversampling--2-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Oversampling--2-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Oversampling--2-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Oversampling--2-.png 1600w, https://sdv.ghost.io/content/images/2023/01/Oversampling--2-.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>One way to fix an imbalance is by oversampling your data. You can manually duplicate the rows (shown here), sample them with replacement or use mathematics to weigh them more heavily.</em></figcaption></figure><p>With oversampling, Variant X is no longer rare, so your model cannot ignore it. But if you actually use this data, your project may not be successful. Your model may confidently predict that all Variant X patients must be over the age of 50. But this is not necessarily right – just because the existing patients had these characteristics doesn't mean Variant X patients always will.</p><p>The mistake was over-emphasizing the same set of patients, making the model more likely to create strong claims. This is commonly referred to as <a href=\"https://en.wikipedia.org/wiki/Overfitting\">overfitting the data</a>: The model over-emphasizes the importance of a small number of records, and makes blanket predictions that lack nuance.</p><h3 id=\"attempt-2-randomizing\">Attempt #2: Randomizing</h3><p>To avoid the problems that come with oversampling, let's explore the opposite direction for argument's sake: What if we created artificial Variant X patients by choosing variables completely at random? An example is illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Randomizing--2-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Randomizing--2-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Randomizing--2-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Randomizing--2-.png 1600w, https://sdv.ghost.io/content/images/2023/01/Randomizing--2-.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>Another way to fix an imbalance problem is by using randomization. You can create artificial Variant X patients by selecting the other variables (Age, BMI, etc.) at random.</em></figcaption></figure><p>Randomization avoids overfitting because no patient is repeated. But this approach introduces problems of its own: You may find that the data doesn't make sense anymore. The example data above highlights some problems that can arise. We see an artificial 23-year-old patient with dementia, and many diabetic patients with low BMIs. In the medical world, these events are not likely and indicate that there is a problem with the data.</p><p>These inconsistencies may (rightfully) dissuade you from using randomization. Since random data lacks patterns, a model will not be able to draw conclusions from it. In data science, we call this a problem of <em>noisiness</em>. <a href=\"https://en.wikipedia.org/wiki/Noisy_data\">Noisy data</a> has too many random combinations to produce any useful learnings.</p><h3 id=\"a-better-solution-defining-neighborhoods\">A Better Solution: Defining Neighborhoods</h3><p>So far, we've seen attempts at extreme ends.</p><ol><li>Oversampling will emphasize one set of patients, leading to an overfit model</li><li>Randomizing will make the dataset noisy, precluding useful conclusions</li></ol><p>The solution we need falls somewhere in the middle: We'd like to <em>loosely</em> base the artificial patients on the real ones. This is related to the data science concept of <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">neighborhoods</a>. Drawing a <strong>neighborhood</strong> around some patients identifies general commonalities between them – without setting any strict rules. For example, Variant X patients <em>may</em> be more likely to have had a known exposure, but it's not guaranteed. Note that there is no exact definition for a neighborhood. It can change based on our assumptions and how broad we want to make it.</p><p>Once we know a neighborhood, we can create artificial patients that are inside it. These patients won't be exactly the same as the existing ones, but they won't have completely random values either.</p><p><strong>Synthetic Data for Label Balancing</strong></p><p>A compelling solution for discovering neighborhoods is <strong>synthetic data</strong>. A synthetic data<strong> </strong>software – such as our open source <a href=\"https://sdv.dev/\">Synthetic Data Vault</a> (SDV) – uses machine learning to learn patterns from real patients, and then creates synthetic patients.</p><p>The SDV discovers neighborhoods at a variety of levels in the form of trends. It's able to learn overall trends (for all patients) as well as trends that are unique to a variable (such as Variant X). For example:</p><ul><li>For all patients, a higher age corresponds to a greater risk of dementia and a higher BMI corresponds to a greater risk of diabetes.</li><li>Variant X patients tend to be older, while Omicron patients tend to be younger.</li><li>Etc.</li></ul><p>As a result, synthetic patients have some variation – but the data still makes sense in context. An example table of SDV-generated patients is shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Synthesizing--2-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Synthesizing--2-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Synthesizing--2-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Synthesizing--2-.png 1600w, https://sdv.ghost.io/content/images/2023/01/Synthesizing--2-.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>A software like the SDV generates synthetic patients with Variant X. The synthetic patients are not exact duplicates of the original, but they aren't completely random either.</em></figcaption></figure><p>This is the middle solution we were looking for: Synthetic data won't cause overfitting and is less noisy than randomization. The best part is that there are multiple synthetic data techniques and settings available in the SDV, providing flexibility and tradeoffs.</p><h3 id=\"takeaways\">Takeaways</h3><p>In this article, we explored imbalanced datasets. It is common to have an imbalanced dataset due to rare events – which becomes a problem if those rare events are important for your project.</p><p>Fixing the imbalance problem requires a careful tradeoff between overfitting data and creating noisy data. <strong>Synthetic data</strong> is a compelling solution that achieves a middle ground by discovering neighborhoods of similar data. This allows you to realistically fix the imbalance without resorting to either extreme.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Data-Creation-Spectrum--2-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Data-Creation-Spectrum--2-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Data-Creation-Spectrum--2-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Data-Creation-Spectrum--2-.png 1600w, https://sdv.ghost.io/content/images/2023/01/Data-Creation-Spectrum--2-.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>Synthetic data is a solution that balances the extremes of overfitting the data and creating noisy data.</em></figcaption></figure><p>Are you interested in label balancing? Have you already explored using the SDV for this problem? Drop us a comment below!</p>","url":"https://sdv.ghost.io/synthetic-label-balancing/","canonical_url":"https://datacebo.com/blog/synthetic-label-balancing","uuid":"2ca67664-3ca9-4710-942e-5536ec5f2dc8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63b4711dac52ed003d6a1744","reading_time":6}},{"node":{"id":"Ghost__Post__63a0bc44ac52ed003d6a169a","title":"Interpreting the Progress of CTGAN","slug":"interpreting-ctgan-progress","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2022/12/Header--4-.png","excerpt":"It can be difficult to verify the progress that a GAN is making. What if we combined it with easily interpretable metrics and visualizations?","custom_excerpt":"It can be difficult to verify the progress that a GAN is making. What if we combined it with easily interpretable metrics and visualizations?","visibility":"public","created_at_pretty":"19 December, 2022","published_at_pretty":"20 December, 2022","updated_at_pretty":"23 January, 2023","created_at":"2022-12-19T14:32:20.000-05:00","published_at":"2022-12-20T14:13:29.000-05:00","updated_at":"2023-01-23T17:09:24.000-05:00","meta_title":"Interpreting the Progress of CTGAN","meta_description":"It can be difficult to verify the progress that a GAN is making. What if we combined it with easily interpretable metrics and visualizations?","og_description":null,"og_image":null,"og_title":null,"twitter_description":"It can be difficult to see the progress of a GAN. What if we verify it with metrics and visualizations?","twitter_image":null,"twitter_title":"Interpreting the Progress of CTGAN","authors":[{"name":"Santiago Gomez Paz","slug":"santiago","bio":"Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent a summer interning at DataCebo, learning and experimenting with CTGAN.","profile_image":"https://sdv.ghost.io/content/images/2022/10/Santi_Gomez_Paz.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Santiago Gomez Paz","slug":"santiago","bio":"Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent a summer interning at DataCebo, learning and experimenting with CTGAN.","profile_image":"https://sdv.ghost.io/content/images/2022/10/Santi_Gomez_Paz.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"This article was researched by Santiago Gomez Paz, a DataCebo intern. Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent his summer learning and experimenting with CTGAN.\n\nThe open source SDV library offers many options for creating synthetic data tables. Some of the library's models use tried-and-true methods from classical statistics, while others use newer innovations like deep learning. One of the newest and most popular models is CTGAN, which uses a type of neural network called a Generative Adversarial Network (GAN).\n\nGenerative models are a popular choice for creating all kinds of synthetic data – for example, you may have heard of OpenAI's DALL-E or ChatGPT tools, which use trained models to create synthetic images and text respectively. A large driver behind their popularity is that they work well — they create synthetic data that closely resembles the real deal. But this high quality often comes at a cost.\n\nGenerative models can be resource-intensive. It can take a lot of time to properly train one, and it's not always clear whether the model is improving much during the training process.\n\nIn this article, we'll unpack this complexity by performing experiments on CTGAN. We'll cover –\n\n * A high-level explanation of how GANs work\n * How to measure and interpret the progress of CTGAN\n * How to confirm this progress with more interpretable, user-centric metrics\n\nSince the library is open source, you can see and run the code yourself with this Colab Notebook.\n\n\nHow do GANs work?\n\nBefore we begin, it's important to understand how GANs work. At a high level, a GAN is an algorithm that makes two neural networks compete against each other (thus the label “Adversarial”). These neural networks are known as the generator and the discriminator, and they each have competing goals:\n\n * The discriminator's goal is to tell real data apart from synthetic data\n * The generator's goal is to create synthetic data that fools the discriminator\n\nThe setup is illustrated below.\n\nThis setup allows us to measure – and improve – both neural networks over many iterations by telling them what they got wrong. Each of these iterations is called an epoch, and CTGAN tracks inaccuracies as loss values. The neural networks are trying to minimize their loss values for every epoch.\n\nThe CTGAN algorithm calculates loss values using a specific formula that can be found in this discussion. The intuition behind it is shown below.\n\nAs shown by the table, lower loss values – even if they are negative – mean that the neural networks are doing well.\n\nAs the epochs progress, we expect both neural networks to improve at their respective goals – but each epoch is resource-intensive and takes time to run. A common request is to find a tradeoff between the improvement achieved and the resources used.\n\n\nMeasuring progress using CTGAN\n\nThe open source SDV library makes it easy to train a CTGAN model and inspect its progress. The code below shows the steps. We train CTGAN using a publicly available SDV demo dataset named RacketSports, which stores various measurements of the strokes that tennis and squash players make over the course of a game.\n\nfrom sdv.demo import load_tabular_demo\nfrom sdv.tabular import CTGAN\n\nmetadata, real_data = load_tabular_demo('RacketSports', metadata=True)\ntable_metadata = metadata.to_dict()\n\nmodel = CTGAN(table_metadata, verbose=True, epochs=800)\nmodel.fit(real_data)\n\nAs part of the fitting process, CTGAN trains the neural networks for multiple epochs. After each epoch, it prints out the count, the generator loss (G) and the discriminator loss (D). Keep in mind that lower numbers are better – even if they are negative. An example is shown below.\n\nEpoch 1, Loss G:  1.0435,Loss D: -0.1401\nEpoch 2, Loss G:  0.4489,Loss D: -0.1455\nEpoch 3, Loss G:  0.4756,Loss D: -0.0956\nEpoch 4, Loss G:  0.3902,Loss D:  0.0344\nEpoch 5, Loss G:  0.0912,Loss D:  0.3030\n...\n\nTo see how the neural networks are improving, we plot the loss values for every epoch. The results from our experiment are shown in the graph below.\n\nBased on the characteristics of this graph, it's possible to deduce how the GAN is progressing.\n\n\nInterpreting the loss values\n\nThe graph above may seem confusing at first glance: Why is the discriminator's loss value score oscillating at 0 if it is supposed to improve (minimize and become negative) over time? The key to interpreting the loss values is to remember that the neural networks are adversaries. As one improves, the other must also improve just to keep its score consistent. Here are three scenarios that we frequently see:\n\n 1. Generator loss is slightly positive while discriminator loss is 0. This means that the generator is producing poor quality synthetic data while the discriminator is blindly guessing what is real vs. synthetic. This is a common starting point, where neither neural network has optimized for its goal.\n 2. Generator loss is becoming negative while the discriminator loss remains at 0. This means that the generator is producing better and better synthetic data. The discriminator is improving too, but because the synthetic data quality has increased, it is still unable to clearly differentiate real vs. synthetic data.\n 3. Generator loss has stabilized at a negative value while the discriminator loss remains at 0. This means that the generator has optimized, creating synthetic data that looks so real, the discriminator cannot tell it apart.\n\nIt is encouraging to see that the general pattern for the RacketSports dataset is similar to a variety of other datasets. These are shown below.\n\nOf course, other patterns may be possible for different datasets. But if loss values are not stabilizing, watch out! This would indicate that the neural networks were not able to effectively learn patterns in the real data.\n\n\nMetrics-Powered Analysis\n\nYou may be wondering whether to trust the loss values. Do they indicate a meaningful difference in synthetic data quality? To answer this question, it's helpful to create synthetic data sets after training the model for different numbers of epochs, and assess the quality of the data sets.\n\nNUM_SYNTHETIC_ROWS = len(real_data)\n\nsynthetic_data = model.sample(num_rows=NUM_SYNTHETIC_ROWS)\n\nIt is important to select a few key metrics for a quantifiable quality measure. For our experiments, we chose 4 metrics from the open source SDMetrics library:\n\n * KSComplement evaluates the shape of numerical columns\n * TVComplement evaluates the shape of discrete columns\n * CorrelationSimilarity evaluates pairwise correlations between columns\n * CategoryCoverage evaluates whether the synthetic data covers all possible values\n\nEach metric produces a score ranging from 0 (worst quality) to 1 (best quality). In the example below, we use the KSComplement metric on a numerical column in the RacketSports dataset.\n\nfrom sdmetrics.single_column import KSComplement\n\nNUMERICAL_COLUMN_NAME='dim_2'\n\nscore = KSComplement.compute(\n   real_data[NUMERICAL_COLUMN_NAME],\n   synthetic_data[NUMERICAL_COLUMN_NAME])\n\nOur results validate that the scores do, indeed, correlate with the loss value from the generator: The quality improves as the loss is minimized. Some of the metrics – such as CorrelationSimilarity and CategoricalCoverage – are high to begin with, so there is not much room to improve. But other metrics, like KSComplement, show significant improvement. This is shown in the graph below.\n\nIt's also possible to visualize the synthetic data that corresponds to a specific metric. For example, KSComplement compares the overall shape of a real and a synthetic data column, so we can visualize it using histograms.\n\nfrom sdmetrics.reports import utils\n\nutils.get_column_plot(\n  real_data,\n  synthetic_data,\n  column_name=NUMERICAL_COLUMN_NAME,\n  metadata=table_metadata)\n\nOverall, we can conclude that the generator and discriminator losses correspond to the quality metrics that we measured – which means we can trust the loss values, as well as the synthetic data that our CTGAN created!\n\n\nConclusion\n\nIn this article, we explored the improvements that the CTGAN model makes as it iterates over many epochs. We started by interpreting the loss values that each of the neural networks – the generator and the discriminator – reports over time. This helped us reason about how they were progressing. But to fully trust the progress of our model, we then turned to the SDMetrics library, which provides metrics that are easier to interpret. Using this library, we could verify whether the reported loss values truly resulted in synthetic data quality improvements.\n\nThis may lead us to a new, potential feature: What if we integrated these easily interpretable, user-centric metrics into the CTGAN training progress? This feature would allow you to specify the exact metrics you'd like to optimize upfront – for example, KSComplement. In addition to the generator and discriminator loss, CTGAN may be able to report a snapshot of this metric. A hypothetical example is shown below.\n\nmodel = CTGAN(\n  table_metadata,\n  verbose=True,\n  epochs=800,\n  optimization_metric='KSComplement',\n  optimization_column='dim_2')\n  \nmodel.fit(real_data)\n\nEpoch 1, Loss G: 1.0435, Loss D: -0.1401, KSComplement: 0.7832\nEpoch 2, Loss G: 0.4489, Loss D: -0.1455, KSComplement: 0.7671\nEpoch 3, Loss G: 0.4756, Loss D: -0.0956, KSComplement: 0.7664\n…\nEpoch 200: Loss G: -2.542, Loss D: 0.0002911, KSComplement: 0.92391\n\n\nSuch a feature would allow more transparency over CTGAN's learning process, and allow you to stop training your models once the metrics are high.\n\nWhat do you think? If you're interested in exploring the inner workings of CTGAN and optimizing your synthetic data, drop us a comment below!","html":"<p><em>This article was researched by Santiago Gomez Paz, a DataCebo intern. Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent his summer learning and experimenting with CTGAN.</em></p><p>The <a href=\"https://github.com/sdv-dev/SDV\">open source SDV library</a> offers many options for creating synthetic data tables. Some of the library's models use tried-and-true methods from classical statistics, while others use newer innovations like deep learning. One of the newest and most popular models is <strong>CTGAN</strong>, which uses a type of neural network called a Generative Adversarial Network (GAN). </p><p>Generative models are a popular choice for creating all kinds of synthetic data – for example, you may have heard of <a href=\"https://openai.com/dall-e-2/\">OpenAI's DALL-E</a> or <a href=\"https://openai.com/blog/chatgpt/\">ChatGPT</a> tools, which use trained models to create synthetic images and text respectively. A large driver behind their popularity is that they work well — they create synthetic data that closely resembles the real deal. But this high quality often comes at a cost.</p><p>Generative models can be resource-intensive. It can take a lot of time to properly train one, and it's not always clear whether the model is improving much during the training process. </p><p>In this article, we'll unpack this complexity by performing experiments on CTGAN. We'll cover –</p><ul><li>A high-level explanation of how GANs work</li><li>How to measure and interpret the progress of CTGAN</li><li>How to confirm this progress with more interpretable, user-centric metrics</li></ul><p>Since the library is open source, you can see and run the code yourself with this <a href=\"https://colab.research.google.com/drive/1RbIYxkbPP3JQY7W0S1p_XprY25wOYTPL?usp=sharing\">Colab Notebook</a>.</p><h3 id=\"how-do-gans-work\">How do GANs work?</h3><p>Before we begin, it's important to understand how GANs work. At a high level, a GAN is an algorithm that makes two neural networks compete against each other (thus the label “Adversarial”). These neural networks are known as the <strong>generator</strong> and the <strong>discriminator</strong>, and they each have competing goals:</p><ul><li>The discriminator's goal is to tell real data apart from synthetic data</li><li>The generator's goal is to create synthetic data that fools the discriminator</li></ul><p>The setup is illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/How-a-GAN-works-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/How-a-GAN-works-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/How-a-GAN-works-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/How-a-GAN-works-2.png 1600w, https://sdv.ghost.io/content/images/2023/01/How-a-GAN-works-2.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>The <strong>generator</strong> is a neural network that creates synthetic data. In this case, it creates a table describing the names of different people, along with their heights and ages. The <strong>discriminator</strong> is an adversarial network that tries to tell these synthetic people apart from the real ones.</em></figcaption></figure><p>This setup allows us to measure – and improve – both neural networks over many iterations by telling them what they got wrong. Each of these iterations is called an <strong>epoch</strong>, and CTGAN tracks inaccuracies as <strong>loss values</strong>. The neural networks are trying to minimize their loss values for every epoch.</p><p>The CTGAN algorithm calculates loss values using a specific formula that can be found in <a href=\"https://github.com/sdv-dev/SDV/discussions/980\">this discussion</a>. The intuition behind it is shown below.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Loss-Values-Interpretation-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"800\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Loss-Values-Interpretation-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Loss-Values-Interpretation-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Loss-Values-Interpretation-2.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2023/01/Loss-Values-Interpretation-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>As shown by the table, lower loss values – even if they are <em>negative </em>– mean that the neural networks are doing well.</p><p>As the epochs progress, we expect both neural networks to improve at their respective goals – but each epoch is resource-intensive and takes time to run. A common request is to find a tradeoff between the improvement achieved and the resources used.</p><h3 id=\"measuring-progress-using-ctgan\">Measuring progress using CTGAN</h3><p>The open source SDV library makes it easy to train a CTGAN model and inspect its progress. The code below shows the steps. We train CTGAN using a publicly available SDV demo dataset named <code>RacketSports</code>, which stores various measurements of the strokes that tennis and squash players make over the course of a game.</p><pre><code class=\"language-python\">from sdv.demo import load_tabular_demo\nfrom sdv.tabular import CTGAN\n\nmetadata, real_data = load_tabular_demo('RacketSports', metadata=True)\ntable_metadata = metadata.to_dict()\n\nmodel = CTGAN(table_metadata, verbose=True, epochs=800)\nmodel.fit(real_data)</code></pre><p>As part of the fitting process, CTGAN trains the neural networks for multiple epochs. After each epoch, it prints out the count, the generator loss (G) and the discriminator loss (D). Keep in mind that lower numbers are better – even if they are <em>negative</em>. An example is shown below.</p><pre><code>Epoch 1, Loss G:  1.0435,Loss D: -0.1401\nEpoch 2, Loss G:  0.4489,Loss D: -0.1455\nEpoch 3, Loss G:  0.4756,Loss D: -0.0956\nEpoch 4, Loss G:  0.3902,Loss D:  0.0344\nEpoch 5, Loss G:  0.0912,Loss D:  0.3030\n...</code></pre><p>To see how the neural networks are improving, we plot the loss values for every epoch. The results from our experiment are shown in the graph below. </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/Racket-Sports-Loss.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/Racket-Sports-Loss.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/Racket-Sports-Loss.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/Racket-Sports-Loss.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/Racket-Sports-Loss.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>A graph of the GAN's progress over time. The generator loss is shown in blue, while the discriminator loss for the same epoch is shown in red.</em></figcaption></figure><p>Based on the characteristics of this graph, it's possible to deduce how the GAN is progressing.</p><h3 id=\"interpreting-the-loss-values\">Interpreting the loss values</h3><p>The graph above may seem confusing at first glance: Why is the discriminator's loss value score oscillating at 0 if it is supposed to improve (minimize and become negative) over time? The key to interpreting the loss values is to remember that the neural networks are adversaries. As one improves, the other must also improve just to keep its score consistent. Here are three scenarios that we frequently see:</p><ol><li><strong>Generator loss is slightly positive while discriminator loss is 0. </strong>This means that the generator is producing poor quality synthetic data while the discriminator is blindly guessing what is real vs. synthetic. This is a common starting point, where neither neural network has optimized for its goal.</li><li><strong>Generator loss is becoming negative while the discriminator loss remains at 0.</strong> This means that the generator is producing better and better synthetic data. The discriminator is improving too, but because the synthetic data quality has increased, it is still unable to clearly differentiate real vs. synthetic data.</li><li><strong>Generator loss has stabilized at a negative value while the discriminator loss remains at 0. </strong>This means that the generator has optimized, creating synthetic data that looks so real, the discriminator cannot tell it apart.</li></ol><p>It is encouraging to see that the general pattern for the <code>RacketSports</code> dataset is similar to a variety of other datasets. These are shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/Multi-Datsets.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/Multi-Datsets.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/Multi-Datsets.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/Multi-Datsets.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/Multi-Datsets.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>The generator and discriminator loss values for a variety of other datasets all follow the same learning pattern. The dataset names are shown in <strong>bold.</strong> They can be downloaded from the SDV demo module.</em></figcaption></figure><p>Of course, other patterns may be possible for different datasets. But if loss values are not stabilizing, watch out! This would indicate that the neural networks were not able to effectively learn patterns in the real data.</p><h3 id=\"metrics-powered-analysis\">Metrics-Powered Analysis</h3><p>You may be wondering whether to trust the loss values. Do they indicate a meaningful difference in synthetic data quality? To answer this question, it's helpful to create synthetic data sets after training the model for different numbers of epochs, and assess the quality of the data sets.</p><pre><code class=\"language-python\">NUM_SYNTHETIC_ROWS = len(real_data)\n\nsynthetic_data = model.sample(num_rows=NUM_SYNTHETIC_ROWS)</code></pre><p>It is important to select a few key metrics for a quantifiable quality measure. For our experiments, we chose 4 metrics from the open source <a href=\"https://docs.sdv.dev/sdmetrics/\">SDMetrics library</a>:</p><ul><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/kscomplement\"><strong>KSComplement</strong></a> evaluates the shape of numerical columns</li><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/tvcomplement\"><strong>TVComplement</strong></a> evaluates the shape of discrete columns</li><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/correlationsimilarity\"><strong>CorrelationSimilarity</strong></a> evaluates pairwise correlations between columns</li><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/categorycoverage\"><strong>CategoryCoverage</strong></a> evaluates whether the synthetic data covers all possible values</li></ul><p>Each metric produces a score ranging from 0 (worst quality) to 1 (best quality). In the example below, we use the <code>KSComplement</code> metric on a numerical column in the <code>RacketSports</code> dataset.</p><pre><code class=\"language-python\">from sdmetrics.single_column import KSComplement\n\nNUMERICAL_COLUMN_NAME='dim_2'\n\nscore = KSComplement.compute(\n   real_data[NUMERICAL_COLUMN_NAME],\n   synthetic_data[NUMERICAL_COLUMN_NAME])</code></pre><p>Our results validate that the scores do, indeed, correlate with the loss value from the generator: The quality improves as the loss is minimized. Some of the metrics – such as <code>CorrelationSimilarity</code> and <code>CategoricalCoverage</code> – are high to begin with, so there is not much room to improve. But other metrics, like <code>KSComplement</code>, show significant improvement. This is shown in the graph below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/CTGAN-Loss-vs.-KSComplement.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1290\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/CTGAN-Loss-vs.-KSComplement.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/CTGAN-Loss-vs.-KSComplement.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/CTGAN-Loss-vs.-KSComplement.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/CTGAN-Loss-vs.-KSComplement.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>A comparison of loss values and the KSComplement metric. The two are linked: Lower generator loss (blue) correspond to higher quality scores (green).</em></figcaption></figure><p>It's also possible to visualize the synthetic data that corresponds to a specific metric. For example, <code>KSComplement</code> compares the overall shape of a real and a synthetic data column, so we can visualize it using histograms.</p><pre><code class=\"language-python\">from sdmetrics.reports import utils\n\nutils.get_column_plot(\n  real_data,\n  synthetic_data,\n  column_name=NUMERICAL_COLUMN_NAME,\n  metadata=table_metadata)</code></pre><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/CTGAN-Epochs-vs.-Improvement.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/CTGAN-Epochs-vs.-Improvement.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/CTGAN-Epochs-vs.-Improvement.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/CTGAN-Epochs-vs.-Improvement.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/CTGAN-Epochs-vs.-Improvement.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>Three histograms were created after training CTGAN for 10, 100 and 500 epochs on the RacketSports dataset. We plotted the dim_2 column. The real data (gray) doesn't change, but the synthetic data (green) improves with more epochs. The KSComplement metric measures the similarity: 0.74, 0.89 and 0.91 (left to right).</em></figcaption></figure><p>Overall, we can conclude that the generator and discriminator losses correspond to the quality metrics that we measured – which means we can trust the loss values, as well as the synthetic data that our CTGAN created!</p><h3 id=\"conclusion\">Conclusion</h3><p>In this article, we explored the improvements that the CTGAN model makes as it iterates over many epochs. We started by interpreting the loss values that each of the neural networks – the generator and the discriminator – reports over time. This helped us reason about how they were progressing. But to fully trust the progress of our model, we then turned to the <a href=\"https://docs.sdv.dev/sdmetrics/\">SDMetrics library</a>, which provides metrics that are easier to interpret. Using this library, we could verify whether the reported loss values truly resulted in synthetic data quality improvements.</p><p>This may lead us to a new, potential feature: What if we integrated these easily interpretable, user-centric metrics into the CTGAN training progress? This feature would allow you to specify the exact metrics you'd like to optimize upfront – for example, KSComplement. In addition to the generator and discriminator loss, CTGAN may be able to report a snapshot of this metric. A hypothetical example is shown below.</p><pre><code class=\"language-python\">model = CTGAN(\n  table_metadata,\n  verbose=True,\n  epochs=800,\n  optimization_metric='KSComplement',\n  optimization_column='dim_2')\n  \nmodel.fit(real_data)</code></pre><pre><code>Epoch 1, Loss G: 1.0435, Loss D: -0.1401, KSComplement: 0.7832\nEpoch 2, Loss G: 0.4489, Loss D: -0.1455, KSComplement: 0.7671\nEpoch 3, Loss G: 0.4756, Loss D: -0.0956, KSComplement: 0.7664\n…\nEpoch 200: Loss G: -2.542, Loss D: 0.0002911, KSComplement: 0.92391\n</code></pre><p>Such a feature would allow more transparency over CTGAN's learning process, and allow you to stop training your models once the metrics are high. </p><p><strong>What do you think? </strong>If you're interested in exploring the inner workings of CTGAN and optimizing your synthetic data, drop us a comment below!</p>","url":"https://sdv.ghost.io/interpreting-ctgan-progress/","canonical_url":"https://datacebo.com/blog/interpreting-ctg-progress","uuid":"b5ed5d15-21b9-4da5-8f28-7682e7522844","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63a0bc44ac52ed003d6a169a","reading_time":7}},{"node":{"id":"Ghost__Post__633b5bbbda16fc003d4eab71","title":"How to evaluate synthetic data for your project — and avoid the biggest mistake we see","slug":"how-to-evaluate-synthetic-data","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2022/10/Header-V2.png","excerpt":"Proper evaluation is critical when using synthetic data. Avoid this common mistake and lead your project to success.","custom_excerpt":"Proper evaluation is critical when using synthetic data. Avoid this common mistake and lead your project to success.","visibility":"public","created_at_pretty":"03 October, 2022","published_at_pretty":"07 October, 2022","updated_at_pretty":"10 January, 2023","created_at":"2022-10-03T18:01:31.000-04:00","published_at":"2022-10-07T10:24:15.000-04:00","updated_at":"2023-01-10T13:00:46.000-05:00","meta_title":"How to evaluate synthetic data for your project","meta_description":"Proper evaluation is critical when using synthetic data. Avoid this common mistake and lead your project to success.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Proper evaluation is critical when using synthetic data. Avoid this common mistake and lead your project to success.","twitter_image":null,"twitter_title":"How to evaluate synthetic data for your project","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In recent years, synthetic data has shown great promise for solving a variety of\nproblems – like addressing data scarcity for AI\n[https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai] \nand overcoming barriers to data access\n[https://www.agmatix.com/blog/driving-innovation-in-agriculture-with-synthetic-data/?utm_source=LinkedIn&utm_medium=Social]\n. As your organization becomes serious about adopting synthetic data, it's\ncrucial to incorporate the right metrics and evaluation frameworks into your\nprojects.\n\nSince the synthetic data space is so new, there aren't yet industry standards\nfor setting and measuring outcomes. At DataCebo [https://datacebo.com/], we've\nworked with a variety of teams using synthetic data. In this article, we're\nsharing the best practices we've learned along the way, as well as the one key\nmistake to avoid.\n\nWhat are synthetic data metrics?\nIn some fields – such as synthetic image generation – it's easy to visually\ninspect the output (in this case, synthetic images) and determine its quality.\nBut if you are creating synthetic data in a tabular format (with rows and\ncolumns), it's difficult to make an overall assessment just by looking at the\nraw data. This is evident in the table below:\n\nWhen the synthetic data is tabular, it's hard to assess its quality. In this\nexample, 3 of the rows show data from real students, while the other 3 are\nsynthetically created. Can you tell which is which?For tabular synthetic data,\nit's necessary to create metrics that quantify how the synthetic data compares\nto the real data. Each metric measures a particular aspect of the data – such as\ncoverage or correlation – allowing you to identify which specific elements have\nbeen preserved or forgotten during the synthetic data process.\n\nIn our open source library, SDMetrics [https://github.com/sdv-dev/SDMetrics],\nwe've provided a variety of metrics for evaluating synthetic data against the\nreal data. For instance, you can use the CategoryCoverage\n[https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/categorycoverage] and \nRangeCoverage\n[https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/rangecoverage] metrics\nto quantify whether your synthetic data covers the same range of possible values\nas the real data:\n\nIn this example, the numerical distributions of real and synthetic data are\noverlaid to compare coverage. Using SDMetrics, you can apply the RangeCoverage,\nwhich quantifies the coverage. In this case: 82%.You may also be curious about\nwhether the synthetic data captures trends between pairs of columns. To compare\ncorrelations, you can use the CorrelationSimilarity\n[https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/correlationsimilarity] \nmetric:\n\nThis example shows two side-by-side heatmaps of the pairwise correlations for\nreal and synthetic data. Using SDMetrics, you can apply the\nCorrelationSimilarity metric, which quantifies the similarity as a score from 0\nto 1.The SDMetrics library has over 30 metrics, with more still in development.\n\nBut having access to metrics is just one part of the story. With so many\nmetrics, it can be difficult to decide which ones to focus on – and how to make\nprogress in your synthetic data project. To successfully deploy synthetic data,\nit's important to consider metrics during all steps of your project development\ncycle.\n\nIn the rest of this article, we'll share a 3-step plan for incorporating metrics\n– and the SDMetrics library – into your synthetic data project to increase your\nchances of success. \n\nStep 1: Start with the project goals \nIt is tempting to create synthetic data quickly and then test it using all the\navailable metrics. After all, it's hard not to be curious about what synthetic\ndata can do! But to succeed with your project, it's important to take a step\nback and focus on the problem you are trying to solve first.\n\nSynthetic data creation isn't an end in itself. Just as with most data work, you\ndon't create synthetic data for its own sake — you use it to solve a problem. If\nyou want your synthetic data project to succeed, pay close attention to what\nthat problem is, as this will help you narrow down a few key metrics. \n\nFor example, imagine that your organization has two different synthetic data\nprojects related to software testing and machine learning, respectively. Because\nthese projects have different goals, you’ll need to consider different metrics:\n\nUse your project goals to help you decide which metrics to prioritize.Focusing\non your goals allows you to identify which metrics are important for the\nultimate success of your project. The single biggest mistake we see people\nmaking is to skip this critical step. Without focus, you can easily get bogged\ndown running multiple tests and tweaking your synthetic dataset, rather than\nmeeting the specific considerations for your project. This can derail your\nefforts – leading to a complex project that doesn't add any value.\n\nStep 2: Let your goals guide the synthetic data creation \nYour goals can help you appropriately scope your project and cut costs. A core\nsubset of metrics can guide your synthetic data creation, making it faster and\nmore targeted to your needs.\n\nChances are, you'll be faced with many decisions throughout your project. For\nexample, in the SDV library [https://github.com/sdv-dev/SDV], there are 5\ndifferent algorithms that create synthetic data, each with their own settings\nthat lead to hundreds of potential models you can create. But if you know that\nyour synthetic data project is software testing, you've identified that\ncoverage, boundaries and business rules are the highest priority metrics. This\nwill guide your decision-making.\n\nIn this case, you may find success choosing our preset model, FAST ML\n[https://github.com/sdv-dev/SDV/discussions/786]. This model uses statistical\nmethods to achieve your minimal requirements while also providing high\nperformance – FAST ML can train a mid-size data table (100 columns and 100K\nrows) in only a few minutes. You can compare this to other GAN-based models that\nare more resource-intensive, taking hours to finish. If your project metrics are\nsatisfied with FAST ML, it is reasonable to choose this model over a GAN, even\nif it isn't perfectly optimized across all possible metrics.\n\nFrom this example, we can see that metrics are not just something to evaluate at\nthe end of the project – they are useful tools for decision-making throughout \nyour project. \n\nStep 3: Test the end-to-end workflow upfront\nThe purpose of metrics is to provide guardrails and focus for your project –\nscoping it so that you can drive business value most efficiently. For the\nhighest chances of success, it's important to apply the synthetic data\nend-to-end for downstream applications, so that you can verify that business\nvalue upfront.\n\nContinuing with our example of software testing, it's important to use the\nsynthetic data for your downstream software testing suite as quickly as you can\nto verify the benefits of synthetic data. If you've chosen your metrics\ncorrectly and considered them when making decisions (steps #1 and #2), then\nyou'll see that this translates to business value.\n\nGoing end-to-end means applying the synthetic data and verifying the ultimate\nbusiness value it provides.This type of cost-benefit analysis can help you make\nthe case for synthetic data adoption within your enterprise. It can also help\nyou iterate – to get more business value from your synthetic data, you can\ncontinue to optimize the metrics you've chosen in step #1, or identify new ones.\n\nThe Takeaway\nTechnically, there are an infinite number of metrics that could be used to\nevaluate synthetic data. The key to success is to incorporate select metrics\ninto your synthetic data project development rather than just applying all\nmetrics at the end.\n\nYour project goals are critical to helping you choose the right metrics. Setting\nthem upfront allows you to make better decisions during your project\ndevelopment. And going end-to-end allows you to measure the business value that\nyour synthetic data brings to the organization.\n\nWhat are your thoughts? Leave comments below! If you noticed other evaluation\npitfalls in your projects, let us know below or reach us directly at \ninfo@sdv.dev.","html":"<p>In recent years, synthetic data has shown great promise for solving a variety of problems – like <a href=\"https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai\">addressing data scarcity for AI</a> and <a href=\"https://www.agmatix.com/blog/driving-innovation-in-agriculture-with-synthetic-data/?utm_source=LinkedIn&amp;utm_medium=Social\">overcoming barriers to data access</a>. As your organization becomes serious about adopting synthetic data, it's crucial to incorporate the right metrics and evaluation frameworks into your projects.</p><p>Since the synthetic data space is so new, there aren't yet industry standards for setting and measuring outcomes. At <a href=\"https://datacebo.com/\">DataCebo</a>, we've worked with a variety of teams using synthetic data. In this article, we're sharing the best practices we've learned along the way, as well as the one key mistake to avoid.</p><h3 id=\"what-are-synthetic-data-metrics\">What are synthetic data metrics?</h3><p>In some fields – such as synthetic image generation – it's easy to visually inspect the output (in this case, synthetic images) and determine its quality. But if you are creating synthetic data in a tabular format (with rows and columns), it's difficult to make an overall assessment just by looking at the raw data. This is evident in the table below:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/10/Real-vs.-Synthetic-Data.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"667\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/10/Real-vs.-Synthetic-Data.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/10/Real-vs.-Synthetic-Data.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/10/Real-vs.-Synthetic-Data.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/10/Real-vs.-Synthetic-Data.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>When the synthetic data is tabular, it's hard to assess its quality. In this example, 3 of the rows show data from real students, while the other 3 are synthetically created. Can you tell which is which?</em></figcaption></figure><p>For tabular synthetic data, it's necessary to create metrics that quantify how the synthetic data compares to the real data. Each metric measures a particular aspect of the data – such as coverage or correlation – allowing you to identify which specific elements have been preserved or forgotten during the synthetic data process.</p><p>In our open source library, <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>, we've provided a variety of metrics for evaluating synthetic data against the real data. For instance, you can use the <a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/categorycoverage\">CategoryCoverage</a> and <a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/rangecoverage\">RangeCoverage</a> metrics to quantify whether your synthetic data covers the same range of possible values as the real data:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/10/Range-Coverage.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/10/Range-Coverage.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/10/Range-Coverage.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/10/Range-Coverage.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/10/Range-Coverage.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>In this example, the numerical distributions of real and synthetic data are overlaid to compare coverage. Using SDMetrics, you can apply the RangeCoverage, which quantifies the coverage. In this case: 82%.</em></figcaption></figure><p>You may also be curious about whether the synthetic data captures trends between pairs of columns. To compare correlations, you can use the <a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/correlationsimilarity\">CorrelationSimilarity</a> metric:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/10/Column-Pairs.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/10/Column-Pairs.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/10/Column-Pairs.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/10/Column-Pairs.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/10/Column-Pairs.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>This example shows two side-by-side heatmaps of the pairwise correlations for real and synthetic data. Using SDMetrics, you can apply the CorrelationSimilarity metric, which quantifies the similarity as a score from 0 to 1.</em></figcaption></figure><p>The SDMetrics library has over 30 metrics, with more still in development.</p><p>But having access to metrics is just one part of the story. With so many metrics, it can be difficult to decide which ones to focus on – and how to make progress in your synthetic data project. <strong>To successfully deploy synthetic data, it's important to consider metrics during all steps of your project development cycle.</strong></p><p>In the rest of this article, we'll share a 3-step plan for incorporating metrics – and the SDMetrics library – into your synthetic data project to increase your chances of success. </p><h3 id=\"step-1-start-with-the-project-goals\">Step 1: Start with the project goals </h3><p>It is tempting to create synthetic data quickly and then test it using all the available metrics. After all, it's hard not to be curious about what synthetic data can do! But to succeed with your project, it's important to take a step back and focus on the problem you are trying to solve first.</p><p>Synthetic data creation isn't an end in itself. Just as with most data work, you don't create synthetic data for its own sake — you use it to solve a problem. If you want your synthetic data project to succeed, pay close attention to what that problem is, as this will help you narrow down a few key metrics. </p><p>For example, imagine that your organization has two different synthetic data projects related to software testing and machine learning, respectively. Because these projects have different goals, you’ll need to consider different metrics:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/10/Project-Driven-Metrics.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"667\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/10/Project-Driven-Metrics.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/10/Project-Driven-Metrics.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/10/Project-Driven-Metrics.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/10/Project-Driven-Metrics.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Use your project goals to help you decide which metrics to prioritize.</figcaption></figure><p>Focusing on your goals allows you to identify which metrics are important for the ultimate success of your project. <strong>The single biggest mistake we see people making is to skip this critical step.</strong> Without focus, you can easily get bogged down running multiple tests and tweaking your synthetic dataset, rather than meeting the specific considerations for your project. This can derail your efforts – leading to a complex project that doesn't add any value.</p><h3 id=\"step-2-let-your-goals-guide-the-synthetic-data-creation\">Step 2: Let your goals guide the synthetic data creation </h3><p>Your goals can help you appropriately scope your project and cut costs. A core subset of metrics can guide your synthetic data creation, making it faster and more targeted to your needs.</p><p>Chances are, you'll be faced with many decisions throughout your project. For example, in the <a href=\"https://github.com/sdv-dev/SDV\">SDV library</a>, there are 5 different algorithms that create synthetic data, each with their own settings that lead to hundreds of potential models you can create. But if you know that your synthetic data project is software testing, you've identified that coverage, boundaries and business rules are the highest priority metrics. This will guide your decision-making.</p><p>In this case, you may find success choosing our preset model, <a href=\"https://github.com/sdv-dev/SDV/discussions/786\">FAST ML</a>. This model uses statistical methods to achieve your minimal requirements while also providing high performance – FAST ML can train a mid-size data table (100 columns and 100K rows) in only a few minutes. You can compare this to other GAN-based models that are more resource-intensive, taking hours to finish. If your project metrics are satisfied with FAST ML, it is reasonable to choose this model over a GAN, even if it isn't perfectly optimized across all possible metrics.</p><p>From this example, we can see that metrics are not just something to evaluate at the end of the project – they are useful tools for decision-making <em>throughout</em> your project. </p><h3 id=\"step-3-test-the-end-to-end-workflow-upfront\">Step 3: Test the end-to-end workflow upfront</h3><p>The purpose of metrics is to provide guardrails and focus for your project – scoping it so that you can drive business value most efficiently. For the highest chances of success, it's important to apply the synthetic data end-to-end for downstream applications, so that you can verify that business value upfront.</p><p>Continuing with our example of software testing, it's important to use the synthetic data for your downstream software testing suite as quickly as you can to verify the benefits of synthetic data. If you've chosen your metrics correctly and considered them when making decisions (steps #1 and #2), then you'll see that this translates to business value.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/10/Business-Value-Driven-Metrics.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"667\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/10/Business-Value-Driven-Metrics.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/10/Business-Value-Driven-Metrics.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/10/Business-Value-Driven-Metrics.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/10/Business-Value-Driven-Metrics.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Going end-to-end means applying the synthetic data and verifying the ultimate business value it provides.</figcaption></figure><p>This type of cost-benefit analysis can help you make the case for synthetic data adoption within your enterprise. It can also help you iterate – to get more business value from your synthetic data, you can continue to optimize the metrics you've chosen in step #1, or identify new ones.</p><h3 id=\"the-takeaway\">The Takeaway</h3><p>Technically, there are an infinite number of metrics that could be used to evaluate synthetic data. The key to success is to incorporate select metrics into your synthetic data project development rather than just applying all metrics at the end.</p><p>Your project goals are critical to helping you choose the right metrics. Setting them upfront allows you to make better decisions during your project development. And going end-to-end allows you to measure the business value that your synthetic data brings to the organization.</p><p><strong>What are your thoughts? </strong>Leave comments below! If you noticed other evaluation pitfalls in your projects, let us know below or reach us directly at <a href=\"mailto:info@sdv.dev\">info@sdv.dev</a>.</p>","url":"https://sdv.ghost.io/how-to-evaluate-synthetic-data/","canonical_url":null,"uuid":"1cbbc888-463b-4494-8e88-a71353ac697a","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"633b5bbbda16fc003d4eab71","reading_time":6}},{"node":{"id":"Ghost__Post__6216679682795d003d91f6e5","title":"ML Model Development using Synthetic Data Clones","slug":"synthetic-clones-for-ml","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2022/02/ML-Model-Development-Banner-04.png","excerpt":"What happens when you train a machine learning model on synthetic data instead of real data? Let's experiment to find out.","custom_excerpt":"What happens when you train a machine learning model on synthetic data instead of real data? Let's experiment to find out.","visibility":"public","created_at_pretty":"23 February, 2022","published_at_pretty":"24 February, 2022","updated_at_pretty":"23 January, 2023","created_at":"2022-02-23T11:57:58.000-05:00","published_at":"2022-02-24T11:33:56.000-05:00","updated_at":"2023-01-23T16:21:53.000-05:00","meta_title":"Using synthetic data clones for ML","meta_description":"What happens when you train a machine learning model on synthetic data instead of real data? Let's experiment to find out.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"What happens when you train a machine learning model on synthetic data instead of real data? Let's experiment.","twitter_image":null,"twitter_title":"Using synthetic data clones for ML","authors":[{"name":"Arnav Modi","slug":"arnav","bio":"Arnav is a high school student and aspiring data scientist who spent his summer learning about the SDV and how synthetic data may be used to perform ML tasks.","profile_image":"https://sdv.ghost.io/content/images/2022/02/Arnav_Modi--1-.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Arnav Modi","slug":"arnav","bio":"Arnav is a high school student and aspiring data scientist who spent his summer learning about the SDV and how synthetic data may be used to perform ML tasks.","profile_image":"https://sdv.ghost.io/content/images/2022/02/Arnav_Modi--1-.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"This article was researched by Arnav Modi, a community user. Arnav is a high school student and aspiring data scientist who spent his summer learning about the SDV and how synthetic data is used to perform ML tasks.\n\nOne potential use for synthetic data is to replace real data in the development of new machine learning (ML) models. Imagine a scenario where you need to build a predictive ML model – perhaps for a function critical to your business, like predicting customer satisfaction or sales success – with one important consideration: The data is sensitive, so only trusted employees can access it with specific credentials.\n\nAccess to sensitive data may create a barrier for a variety of reasons:\n\n * You might not have ML expertise in your organization, which means you need to use external software or contractors to complete the task. However, you are unable to share the data with them.\n * Your data is available on a secure, cloud-based platform for trusted employees to access remotely. They work on this data using interactive notebooks. Every time they lose their connection – due to WiFi outages, their laptops falling asleep, etc. – they may lose their work or have to reconnect.\n * You have a robust authentication system that your team uses. However, it creates a barrier to entry for rapid, iterative collaboration between members, sharing work and debugging data pipelines. As a result, your collaboration is much slower than it would be if your team could access the data without the need to authenticate.\n\nIn cases like this, synthetic data can be an ideal solution: You can create synthetic data based on the original, sensitive data set, and use it more freely during ML development.\n\nOne key question will determine if this method succeeds: Is the synthetic data actually useful for your ML task? We performed an experiment to find out.\n\nIn the rest of this article, we'll describe our experimental setup and findings. (You can double-check our work in this Colab Notebook.)\n\n\nExperimental Setup\n\nIf an ML model is trained using synthetic data instead of real data, what happens to the model's performance? To answer this question, we identified 3 publicly available datasets (Income, Bank and Airline) that are associated with particular ML prediction tasks. The datasets and tasks are summarized below.\n\nOur experiment compared the performance of an  ML model trained on the original data, vs. one trained on the synthetic data provided by the SDV.\n\n * Control (Original data): How successfully can we complete the ML prediction task if we use the real data? Because some predictions are harder than others, this control helped us identify the overall difficulty of these specific tasks.\n * Experiment (Synthetic data): How successfully can we complete the ML prediction task if we use synthetic data instead? We used the SDV's CopulaGAN to generate synthetic data from the three original datasets.\n\nIn order to develop and test the ML model, we turned to the SDMetrics library — specifically the ML Efficacy metrics, which build an ML model and evaluate its performance. We used the Binary Decision Tree Classifier and Binary Logistic Regression models. The overall experimental setup is illustrated below.\n\nTo obtain reliable findings, we ran 3 iterations and averaged the results.\n\n\nResults\n\nThe graph below shows how well we are able to perform an ML task using the original vs the synthetic data.\n\nDiscussion\n\nThe original data quantifies the general difficulty of the ML task. Looking at these values, we can see that the Income Dataset is the hardest task, as neither of our methods were able to get above 90% accuracy using the original data.\n\nComparing the datasets allows us to quantify the suitability of synthetic data for ML development. Our results show a loss of between 1 and 9% of the original efficacy value for all comparisons, with a median loss of roughly 2.5%.\n\nIt's important to note that the simplifications we've made for this experiment may be resulting in worse accuracy than we would see in real-world use.\n\n * Applying CopulaGAN out-of-the-box to each dataset is simplistic. In a real-world scenario, the model's parameters would likely be explicitly tuned and constraints would be used to improve synthetic data quality.\n * The Decision Tree and Logistic Regression evaluators are relatively simplistic ML classifiers. An ML expert (or ML software) might use more advanced techniques.\n * In our scenario, the 3rd party delivers a fully trained, ready-to-go ML model. Another approach is to ask them to use the synthetic data to deliver an untrained model – so that you can train it yourself on the real dataset. This alternative setup, which should increase the prediction accuracy, will be a topic for a future article.\n\nIn summary, the accuracy loss we observe represents the worst case scenario. In a production environment, higher-quality ML models and more careful tuning of the SDV will likely minimize performance differences between original and synthetic data.\n\n\nTakeaways\n\nIn this article, we quantified the effect of replacing real data with a synthetic data clone for ML development. Our results show a loss of 2.5% accuracy when using synthetic data. Considering these results, we assess that it is reasonable to explore the use of synthetic data for the purpose of ML development.\n\nIn order to maximize the utility of the synthetic data, we recommend tuning the SDV model and using constraints to improve the data quality. In future articles, we'll explore more details about using synthetic data for ML.\n\nAre you using the SDV to solve your ML business needs? Publish your findings on the SDV blog as a guest author! Contact us at info@sdv.dev.\n\n\n\n\n\n","html":"<p><em>This article was researched by Arnav Modi, a community user. Arnav is a high school student and aspiring data scientist who spent his summer learning about the SDV and how synthetic data is used to perform ML tasks.</em></p><p>One potential use for synthetic data is to replace real data in the development of new machine learning (ML) models. Imagine a scenario where you need to build a predictive ML model – perhaps for a function critical to your business, like predicting customer satisfaction or sales success – with one important consideration: <strong>The data is sensitive, so only trusted employees can access it with specific credentials.</strong></p><p>Access to sensitive data may create a barrier for a variety of reasons:</p><ul><li>You might not have ML expertise in your organization, which means you need to use external software or contractors to complete the task. However, you are unable to share the data with them.</li><li>Your data is available on a secure, cloud-based platform for trusted employees to access remotely. They work on this data using interactive notebooks. Every time they lose their connection – due to WiFi outages, their laptops falling asleep, etc. – they may lose their work or have to reconnect.</li><li>You have a robust authentication system that your team uses. However, it creates a barrier to entry for rapid, iterative collaboration between members, sharing work and debugging data pipelines. As a result, your collaboration is much slower than it would be if your team could access the data without the need to authenticate.</li></ul><p>In cases like this, synthetic data can be an ideal solution: You can create synthetic data based on the original, sensitive data set, and use it more freely during ML development.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/02/ML-Model-Development-03.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"783\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/02/ML-Model-Development-03.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/02/ML-Model-Development-03.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/02/ML-Model-Development-03.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/02/ML-Model-Development-03.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Synthetic data can be useful for ML development. You can use synthetic data to develop models in a variety of environments, like data science platforms, local machines or 3rd party software. Meanwhile, the real data never leaves your premises.</figcaption></figure><p>One key question will determine if this method succeeds: Is the synthetic data actually useful for your ML task? We performed an experiment to find out.</p><p>In the rest of this article, we'll describe our experimental setup and findings. (You can double-check our work in this <a href=\"https://colab.research.google.com/drive/13-1xy5t7veizWBsb_dDgTRBdhGcCqjCJ?usp=sharing\">Colab Notebook</a>.)</p><h3 id=\"experimental-setup\">Experimental Setup</h3><p>If an ML model is trained using synthetic data instead of real data, what happens to the model's performance? To answer this question, we identified 3 publicly available datasets (<a href=\"https://www.kaggle.com/mastmustu/income?select=train.csv\">Income</a>, <a href=\"https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\">Bank</a> and <a href=\"https://www.kaggle.com/teejmahal20/airline-passenger-satisfaction?select=train.csv\">Airline</a>) that are associated with particular ML prediction tasks. The datasets and tasks are summarized below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/02/ML-Model-Development-04.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"671\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/02/ML-Model-Development-04.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/02/ML-Model-Development-04.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/02/ML-Model-Development-04.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/02/ML-Model-Development-04.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A description of our datasets. *[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014</figcaption></figure><p>Our experiment compared the performance of an  ML model trained on the original data, vs. one trained on the synthetic data provided by the SDV.</p><ul><li><strong><strong><strong>Control (Original data): </strong></strong></strong>How successfully can we complete the ML prediction task if we use the real data? Because some predictions are harder than others, this control helped us identify the overall difficulty of these specific tasks.</li><li><strong><strong>Experiment (Synthetic data):</strong> </strong>How successfully can we complete the ML prediction task if we use synthetic data instead? We used the SDV's <a href=\"https://sdv.dev/SDV/user_guides/single_table/copulagan.html\">CopulaGAN</a> to generate synthetic data from the three original datasets.</li></ul><p>In order to develop and test the ML model, we turned to the SDMetrics library — specifically the <a href=\"https://sdv.dev/SDV/user_guides/evaluation/single_table_metrics.html#machine-learning-efficacy-metrics\">ML Efficacy metrics</a>, which build an ML model and evaluate its performance. We used the Binary Decision Tree Classifier and Binary Logistic Regression models. The overall experimental setup is illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/02/ML-Model-Development-05.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"724\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/02/ML-Model-Development-05.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/02/ML-Model-Development-05.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/02/ML-Model-Development-05.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/02/ML-Model-Development-05.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The experimental setup evaluated synthetic data against a test set of original data that we set aside at the start. This allows us to compare the usefulness of both types of data for ML tasks.</figcaption></figure><p>To obtain reliable findings, we ran 3 iterations and averaged the results.</p><h3 id=\"results\">Results</h3><p>The graph below shows how well we are able to perform an ML task using the original vs the synthetic data.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/02/Machine-Learning-Efficacy.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"638\" height=\"395\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/02/Machine-Learning-Efficacy.png 600w, https://sdv.ghost.io/content/images/2022/02/Machine-Learning-Efficacy.png 638w\"><figcaption>A comparison of ML accuracy scores obtained using real vs. synthetic data, allowing us to assess any loss of accuracy that comes from replacing the original data with synthetic data.</figcaption></figure><p><strong>Discussion</strong></p><p>The original data quantifies the general difficulty of the ML task. Looking at these values, we can see that the Income Dataset is the hardest task, as neither of our methods were able to get above 90% accuracy using the original data.</p><p>Comparing the datasets allows us to quantify the suitability of synthetic data for ML development. Our results show a loss of between 1 and 9% of the original efficacy value for all comparisons, with a median loss of roughly 2.5%.</p><p>It's important to note that the simplifications we've made for this experiment may be resulting in worse accuracy than we would see in real-world use.</p><ul><li>Applying CopulaGAN out-of-the-box to each dataset is simplistic. In a real-world scenario, the model's parameters would likely be explicitly <a href=\"https://sdv.dev/SDV/user_guides/single_table/copulagan.html\">tuned</a> and <a href=\"https://sdv.dev/SDV/user_guides/single_table/constraints.html\">constraints</a> would be used to improve synthetic data quality.</li><li>The Decision Tree and Logistic Regression evaluators are relatively simplistic ML classifiers. An ML expert (or ML software) might use more advanced techniques.</li><li>In our scenario, the 3rd party delivers a fully trained, ready-to-go ML model. Another approach is to ask them to use the synthetic data to deliver an <em>untrained</em> model – so that you can train it yourself on the real dataset. This alternative setup, which should increase the prediction accuracy, will be a topic for a future article.</li></ul><p>In summary, the accuracy loss we observe represents the worst case scenario. In a production environment, higher-quality ML models and more careful tuning of the SDV will likely minimize performance differences between original and synthetic data.</p><h3 id=\"takeaways\">Takeaways</h3><p>In this article, we quantified the effect of replacing real data with a synthetic data clone for ML development. Our results show a loss of 2.5% accuracy when using synthetic data. Considering these results, we assess that <strong>it is reasonable to explore the use of synthetic data for the purpose of ML development</strong>.</p><p>In order to maximize the utility of the synthetic data, we recommend tuning the SDV model and using constraints to improve the data quality. In future articles, we'll explore more details about using synthetic data for ML.</p><p><em>Are you using the SDV to solve your ML business needs? Publish your findings on the SDV blog as a guest author! Contact us at </em><a href=\"mailto:info@sdv.dev\"><em>info@sdv.dev</em></a><em>.</em></p><p><br></p><p><br></p>","url":"https://sdv.ghost.io/synthetic-clones-for-ml/","canonical_url":"https://datacebo.com/blog/synthetic-clones-for-ml","uuid":"252b7f1d-c113-4a0f-a712-3e5342d2e39a","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"6216679682795d003d91f6e5","reading_time":5}},{"node":{"id":"Ghost__Post__61e841116361ff003b9ca712","title":"Building the Unique Combinations Constraint in the SDV","slug":"building-unique-combinations","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2022/01/Banner-UC.png","excerpt":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","custom_excerpt":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","visibility":"public","created_at_pretty":"19 January, 2022","published_at_pretty":"25 January, 2022","updated_at_pretty":"26 January, 2022","created_at":"2022-01-19T11:49:21.000-05:00","published_at":"2022-01-25T13:25:20.000-05:00","updated_at":"2022-01-26T17:55:37.000-05:00","meta_title":"Building Unique Combinations","meta_description":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","twitter_image":null,"twitter_title":"Building Unique Combinations","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Engineering","slug":"engineering","description":"Our software is serving a global user base. In our engineering blog, we highlight software challenges and design decisions we've made in support of our community.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Engineering","slug":"engineering","description":"Our software is serving a global user base. In our engineering blog, we highlight software challenges and design decisions we've made in support of our community.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By default, a machine learning model (ML) may not always learn the deterministic\nrules in your dataset. We've previously explored how the SDV allows user to \ninput their logic [https://sdv.dev/blog/eng-sdv-constraints/] using constraints.\nWith constraints, an SDV model produces logically correct data 100% of the time.\n\nWhile an end user might expect the constraint to \"just work,\" engineering this\nfunctionality requires some creative techniques. In this article, we'll describe\nthe techniques we used to build the UniqueCombinations constraint. You can also\nfollow along in our notebook\n[https://colab.research.google.com/drive/1bY8y6m7-CjTxWDepw32-ZT3Ubb9RGK5F?usp=sharing]\n.\n\n!pip install sdv==0.13.1\n\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nWhat is a Unique Combinations Constraint?\nUsers frequently encounter logical constraints on the permutations -- mixing &\nmatching -- that are allowed in synthetic data.\n\nTo illustrate this, let's use the world_v1 dataset from the SDV tabular dataset\ndemos. This simple dataset describes the population of different cities around\nthe world.\n\nfrom sdv.demo import load_tabular_demo\n\ndata = load_tabular_demo('world_v1')\ndata = data.drop(['add_numerical'], axis=1) # not needed for this demo\ndata.head()\n\nRelationship between Name, CountryCode and District\n\nLooking at the data, we can observe that there is a special relationship between\nthe Name of the city, its CountryCode and its geographical District: When\ngenerating synthetic data, the model should not blindly mix-and-match these\nvalues. Instead, it should reference the real data to verify whether the\ncombination is valid. This is called a UniqueCombinations constraint.\n\nFor example, take a particular city, like Cambridge, which appears 3 times in\nour dataset.\n\ndata[data.Name == 'Cambridge']\n\nThe constraint states that Cambridge should only ever appear with GBR (England), \nCAN (Ontario) or USA (Massachusetts). It is invalid if it appears in any other\nregion -- for eg. Cambridge, France.\n\nHow does the SDV handle a Unique Combination out-of-the-box?\n\nLet's try running the sdv as-is on the dataset to see what happens. We'll use\nthe GaussianCopula model on our dataset.\n\nfrom sdv.tabular import GaussianCopula\n\nnp.random.seed(0)\n\nmodel = GaussianCopula(\n  categorical_transformer='label_encoding' # optimize speed\n) \nmodel.fit(data)\n\nNow, let's generate some rows to inspect the synthetic data.\n\nnp.random.seed(12)\nmodel.sample(5)\n\nAlthough the sdv is generating known city names, countries and districts, their\ncombinations don't make sense. We can also go back to our original example and\ngenerate only some rows for Cambridge.\n\nnp.random.seed(10)\n\nconditions = {'Name': 'Cambridge'}\nmodel.sample(5, conditions=conditions)\n\nThe result is a variety of Cambridges that aren't necessarily in USA, GBR, or\nCAN. These aren't valid cities!\n\nWhat's going on? The SDV models include probabilities that some unseen\ncombinations are possible. This is by design: Synthesizing new combinations --\nthat don't blatantly match the original data -- helps with privacy.\n\nHowever in this particular case, we aren't worried about the privacy of a city\nbelonging to a country or district. We actually do want the data to match. This\nis why we need to build a constraint.\n\nFixing the data using rejecting sampling\nIn our previous article [https://sdv.dev/blog/eng-sdv-constraints/], we\ndescribed a solution called reject_sampling that works on any type of constraint\nand is very easy to build: We simply create the synthetic data as usual and then\nthrow out (reject) any data that doesn't match.\n\nIn theory, this can solve our UniqueCombinations constraint. In practice, this\nstrategy is only efficient if the model can easily generate acceptable data.\nLet's calculate the chances of getting an acceptable combination (Name, \nCountryCode, District) from the model.\n\nnp.random.seed(0)\n\n# Sample data from the model\n# The sample may include combinations that aren't valid\nn = 100000\nnew_data = model.sample(n)\n\n# Calculate how many rows are valid\ncombo = ['Name', 'CountryCode', 'District']\nmerged = new_data.merge(data, left_on=combo, right_on=combo, how='left')\npassed = merged[merged['ID_y'].notna()].shape[0]\n\n# Print out our results\nprint(\"Valid rows: \", (passed/n)*100, \"%\")\nprint(\"Rejected rows: \", (1 - passed/n)*100, \"%\")\n\nValid rows:  0.038 %\nRejected rows:  99.96199999999999 %\n\nWith such a low probability of passing the constraint, this strategy can become\nintractable.\n\nFixing the data using transformations\nA more efficient strategy is for the ML model to learn the constraint directly,\nso it always produces acceptable data. We can do this by transforming the data\nin a clever way, forcing the model to learn the logic.\n\nOur previous article [https://sdv.dev/blog/eng-sdv-constraints/] described how\nto do this for a different constraint. Unfortunately, the exact same\ntransformation won't work to solve our current UniqueCombinations constraint. \nThe transform strategy requires a different, creative solution for each\nconstraint. So we have to start from scratch.\n\nCan you think of any other ways to enforce UniqueCombinations?\n\nA solution: Concatenating the data\n\nOne solution is to concatenate the data. That is, rather than treating the city \nName, CountryCode and District as separate items, we treat them as a single\nvalue. This will force the model to learn them as 1 single concept rather than\nas multiple columns that can be recombined.\n\nLet's see this in action.\n\n# create transformed data that concatenates the columns\ndata_transform = data.copy()\n\n# Concatenate the data using a separator\ndata_transform['concatenated'] = data_transform['Name'] + '#' + data_transform['CountryCode'] + '#' + data_transform['District']\n\n# We can drop the individual columns\ndata_transform.drop(labels=['Name', 'CountryCode', 'District'],\n                    axis=1, inplace=True)\n\ndata_transform.head()\n\nNow, we can train the model using the transformed (concatenated) data instead.\n\nnp.random.seed(35)\n\n# create a new model that will learn from the transformed data\nmodel_transform = GaussianCopula(categorical_transformer='label_encoding')\nmodel_transform.fit(data_transform)\n\n# this will produce transformed data\noutput = model_transform.sample()\noutput.head(5)\n\nTo get back realistic-looking data, we can convert the concatenated column back\ninto Name, City and District.\n\nimport pandas as pd\n\n# Split the conatenated column by the separator and save the reuslts\nnames = []\ncountrycodes = []\ndistricts = []\n\nfor x in output['concatenated']:\n  try:\n    name, countrycode, district = x.split('#')\n  except:\n    name, countrycode, district = [np.nan]*3\n  names.append(name)\n  countrycodes.append(countrycode)\n  districts.append(district)\n\n# Add the individual columns back in\noutput['Name'] = pd.Series(names)\noutput['CountryCode'] = pd.Series(countrycodes)\noutput['District'] = pd.Series(districts)\n\n# Drop the concatenated column\noutput.drop(labels=['concatenated'], axis=1, inplace=True)\n\nAs a result, the output now looks like our original data.\n\noutput.head()\n\nMost importantly, the Name, CountryCode and District columns now make sense!\n\nCaveats of transforming the data\n\nThe transform strategy is an efficient and elegant approach to modeling. But\nthere is a downside: The transform strategy might lose some mathematical\nproperties.\n\nTo see why, consider the model's perspective:\n\n * Cambridge#GBR#England is completely different from\n * Cambridge#USA#Massachusetts is completely different from\n * Boston#USA#Massachusetts\n\nThe problem is that two of these actually have something in common -- they are\nlocated in Massachusetts, USA. So the model will not be able to learn anything\nspecial about Massachusetts or USA as a whole.\n\nAs an example, let's see how well the model was able to learn populations of\nUS-based cities.\n\nimport matplotlib.pyplot as plt\n\n# Populations of real US cities\nreal_usa = data.loc[data['CountryCode'] == 'USA', 'Population']\n\n# Populations of synthetic US cities\nsynth_usa = output.loc[output['CountryCode'] == 'USA', 'Population']\n\n# Plot the distributions\nplt.ylabel('US City Data')\nplt.xlabel('Population')\n_ = plt.boxplot([real_usa, synth_usa],\n                showfliers=False,\n                labels=['Real', 'Synthetic'],\n                vert=False\n)\nplt.show()\n\nThe real data shows less variation in city population than the synthetic data.\nThe differences make sense because our model wasn't able to learn about the USA\nas one complete concept.\n\nCan we fix this? It's challenging to fix this issue without degrading the\nmathematical correlations in some other way. If you have any ideas, we welcome\nyou to join our discussion [https://github.com/sdv-dev/SDV/issues/414]!\n\nInputting a UniqueCombination into the SDV\nWe built the constraint -- both the reject_sampling and transform approaches --\ndirectly into the SDV library. If you have sdv installed, this is ready to use.\nImport the UniqueCombinations class from the constraints module.\n\nfrom sdv.constraints import UniqueCombinations\n\n# Create a Unique Combinations constraint\nunique_city_country_district = UniqueCombinations(\n  columns=['Name', 'CountryCode', 'District'],\n  handling_strategy='transform' # you can change this 'reject_sampling' too\n)\n\n# Create a new model using the constraint\nupdated_model = GaussianCopula(\n  constraints=[unique_city_country_district],\n  categorical_transformer='label_encoding'\n)\n\nNow, you can train the model on your data and sample synthetic data.\n\nnp.random.seed(35)\n\nupdated_model.fit(data)\nupdated_model.sample(5)\n\nAll of the synthetic data is guaranteed to follow the UniqueCombinations \nconstraint.\n\nTakeaways\n 1. We can identify a UniqueCombinations requirement by asking: Should it be\n    possible to further mix-and-match the data?\n 2. We can enforce any logical constraint by using reject sampling, which throws\n    out any invalid data. This is not efficient for UniqueCombinations.\n 3. An alternative approach is to transform the data, forcing the ML model to\n    learn the constraint. For UniqueCombinations we transformed the data by\n    concatenating it.\n 4. The logic for UniqueCombinations is already built into the SDV's constraints \n    module, and is ready to use.\n\nFurther reading:\n\n * Engineering Constraints Blog Article\n   [https://sdv.dev/blog/eng-sdv-constraints/]\n * Handling Constraints User Guide\n   [https://sdv.dev/SDV/user_guides/single_table/constraints.html]\n * Tabular Constraints API\n   [https://sdv.dev/SDV/api_reference/constraints/tabular.html]","html":"<p>By default, a machine learning model (ML) may not always learn the deterministic rules in your dataset. We've previously explored how the SDV allows user to <a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">input their logic</a> using constraints. With constraints, an SDV model produces logically correct data 100% of the time.</p><p>While an end user might expect the constraint to \"just work,\" engineering this functionality requires some creative techniques. In this article, we'll describe the techniques we used to build the <code>UniqueCombinations</code> constraint. You can also follow along in our <a href=\"https://colab.research.google.com/drive/1bY8y6m7-CjTxWDepw32-ZT3Ubb9RGK5F?usp=sharing\">notebook</a>.</p><pre><code>!pip install sdv==0.13.1</code></pre><pre><code class=\"language-python\">import numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')</code></pre><h3 id=\"what-is-a-unique-combinations-constraint\">What is a Unique Combinations Constraint?</h3><p>Users frequently encounter logical constraints on the permutations -- mixing &amp; matching -- that are allowed in synthetic data.</p><p>To illustrate this, let's use the <code>world_v1</code> dataset from the SDV tabular dataset demos. This simple dataset describes the population of different cities around the world.</p><pre><code class=\"language-python\">from sdv.demo import load_tabular_demo\n\ndata = load_tabular_demo('world_v1')\ndata = data.drop(['add_numerical'], axis=1) # not needed for this demo\ndata.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1014\" height=\"362\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png 1014w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Relationship between <code>Name</code>, <code>CountryCode</code> and <code>District</code></strong></p><p>Looking at the data, we can observe that there is a special relationship between the <code>Name</code> of the city, its <code>CountryCode</code> and its geographical <code>District</code>: When generating synthetic data, the model should not blindly mix-and-match these values. Instead, it should <strong>reference the real data to verify whether the combination is valid.</strong> This is called a <code>UniqueCombinations</code> constraint.</p><p>For example, take a particular city, like <code>Cambridge</code>, which appears 3 times in our dataset.</p><pre><code class=\"language-python\">data[data.Name == 'Cambridge']</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1020\" height=\"248\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png 1020w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The constraint states that <code>Cambridge</code> should only ever appear with <code>GBR (England)</code>, <code>CAN (Ontario)</code> or <code>USA (Massachusetts)</code>. It is invalid if it appears in any other region -- for eg. Cambridge, France.</p><p><strong>How does the SDV handle a Unique Combination out-of-the-box?</strong></p><p>Let's try running the <code>sdv</code> as-is on the dataset to see what happens. We'll use the <code>GaussianCopula</code> model on our dataset.</p><pre><code class=\"language-python\">from sdv.tabular import GaussianCopula\n\nnp.random.seed(0)\n\nmodel = GaussianCopula(\n  categorical_transformer='label_encoding' # optimize speed\n) \nmodel.fit(data)</code></pre><p>Now, let's generate some rows to inspect the synthetic data.</p><pre><code class=\"language-python\">np.random.seed(12)\nmodel.sample(5)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.54.31-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"940\" height=\"360\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.54.31-AM.png 600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.54.31-AM.png 940w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Although the <code>sdv</code> is generating known city names, countries and districts, their combinations don't make sense. We can also go back to our original example and generate only some rows for <code>Cambridge</code>.</p><pre><code class=\"language-python\">np.random.seed(10)\n\nconditions = {'Name': 'Cambridge'}\nmodel.sample(5, conditions=conditions)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1022\" height=\"364\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png 1022w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The result is a variety of Cambridges that aren't necessarily in USA, GBR, or CAN. These aren't valid cities!</p><p><strong>What's going on?</strong> The SDV models include probabilities that some unseen combinations are possible. This is by design: Synthesizing new combinations -- that don't blatantly match the original data -- helps with privacy.</p><p>However in this particular case, we aren't worried about the privacy of a city belonging to a country or district. We actually <em>do</em> want the data to match. This is why we need to build a constraint.</p><h3 id=\"fixing-the-data-using-rejecting-sampling\">Fixing the data using rejecting sampling</h3><p>In our <a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">previous article</a>, we described a solution called <code>reject_sampling</code> that works on any type of constraint and is very easy to build: We simply create the synthetic data as usual and then throw out (reject) any data that doesn't match.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-02.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"883\" height=\"316\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/UniqueCombinations-02.png 600w, https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-02.png 883w\" sizes=\"(min-width: 720px) 720px\"></figure><p>In theory, this can solve our <code>UniqueCombinations</code> constraint. In practice, this strategy is only efficient if the model can easily generate acceptable data. Let's calculate the chances of getting an acceptable combination (<code>Name</code>, <code>CountryCode</code>, <code>District</code>) from the model.</p><pre><code class=\"language-python\">np.random.seed(0)\n\n# Sample data from the model\n# The sample may include combinations that aren't valid\nn = 100000\nnew_data = model.sample(n)\n\n# Calculate how many rows are valid\ncombo = ['Name', 'CountryCode', 'District']\nmerged = new_data.merge(data, left_on=combo, right_on=combo, how='left')\npassed = merged[merged['ID_y'].notna()].shape[0]\n\n# Print out our results\nprint(\"Valid rows: \", (passed/n)*100, \"%\")\nprint(\"Rejected rows: \", (1 - passed/n)*100, \"%\")</code></pre><pre><code>Valid rows:  0.038 %\nRejected rows:  99.96199999999999 %</code></pre><p>With such a low probability of passing the constraint, this strategy can become intractable.</p><h3 id=\"fixing-the-data-using-transformations\">Fixing the data using transformations</h3><p>A more efficient strategy is for the ML model to learn the constraint directly, so it always produces acceptable data. We can do this by transforming the data in a clever way, forcing the model to learn the logic.</p><p>Our <a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">previous article</a> described how to do this for a different constraint. Unfortunately, the exact same transformation won't work to solve our current <code>UniqueCombinations</code> constraint. <strong>The transform strategy requires a different, creative solution for each constraint.</strong> So we have to start from scratch.</p><p>Can you think of any other ways to enforce <code>UniqueCombinations</code>?</p><p><strong>A solution: Concatenating the data</strong></p><p>One solution is to concatenate the data. That is, rather than treating the city <code>Name</code>, <code>CountryCode</code> and <code>District</code> as separate items, we treat them as a single value. This will force the model to learn them as 1 single concept rather than as multiple columns that can be recombined.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1524\" height=\"1200\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/UniqueCombinations-01.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/UniqueCombinations-01.png 1000w, https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-01.png 1524w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Let's see this in action.</p><pre><code class=\"language-python\"># create transformed data that concatenates the columns\ndata_transform = data.copy()\n\n# Concatenate the data using a separator\ndata_transform['concatenated'] = data_transform['Name'] + '#' + data_transform['CountryCode'] + '#' + data_transform['District']\n\n# We can drop the individual columns\ndata_transform.drop(labels=['Name', 'CountryCode', 'District'],\n                    axis=1, inplace=True)\n\ndata_transform.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.21-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"828\" height=\"368\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.58.21-AM.png 600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.21-AM.png 828w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Now, we can train the model using the transformed (concatenated) data instead.</p><pre><code class=\"language-python\">np.random.seed(35)\n\n# create a new model that will learn from the transformed data\nmodel_transform = GaussianCopula(categorical_transformer='label_encoding')\nmodel_transform.fit(data_transform)\n\n# this will produce transformed data\noutput = model_transform.sample()\noutput.head(5)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.53-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"882\" height=\"368\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.58.53-AM.png 600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.53-AM.png 882w\" sizes=\"(min-width: 720px) 720px\"></figure><p>To get back realistic-looking data, we can convert the concatenated column back into <code>Name</code>, <code>City</code> and <code>District</code>.</p><pre><code class=\"language-python\">import pandas as pd\n\n# Split the conatenated column by the separator and save the reuslts\nnames = []\ncountrycodes = []\ndistricts = []\n\nfor x in output['concatenated']:\n  try:\n    name, countrycode, district = x.split('#')\n  except:\n    name, countrycode, district = [np.nan]*3\n  names.append(name)\n  countrycodes.append(countrycode)\n  districts.append(district)\n\n# Add the individual columns back in\noutput['Name'] = pd.Series(names)\noutput['CountryCode'] = pd.Series(countrycodes)\noutput['District'] = pd.Series(districts)\n\n# Drop the concatenated column\noutput.drop(labels=['concatenated'], axis=1, inplace=True)</code></pre><p>As a result, the output now looks like our original data.</p><pre><code class=\"language-python\">output.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1020\" height=\"368\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png 1020w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Most importantly, the <code>Name</code>, <code>CountryCode</code> and <code>District</code> columns now make sense!</p><p><strong>Caveats of transforming the data</strong></p><p>The transform strategy is an efficient and elegant approach to modeling. But there is a downside: <strong>The transform strategy might lose some mathematical properties.</strong></p><p>To see why, consider the model's perspective:</p><ul><li><code>Cambridge#GBR#England</code> is completely different from</li><li><code>Cambridge#USA#Massachusetts</code> is completely different from</li><li><code>Boston#USA#Massachusetts</code></li></ul><p>The problem is that two of these actually have something in common -- they are located in <code>Massachusetts, USA</code>. So the model will not be able to learn anything special about <code>Massachusetts</code> or <code>USA</code> as a whole.</p><p>As an example, let's see how well the model was able to learn populations of US-based cities.</p><pre><code class=\"language-python\">import matplotlib.pyplot as plt\n\n# Populations of real US cities\nreal_usa = data.loc[data['CountryCode'] == 'USA', 'Population']\n\n# Populations of synthetic US cities\nsynth_usa = output.loc[output['CountryCode'] == 'USA', 'Population']\n\n# Plot the distributions\nplt.ylabel('US City Data')\nplt.xlabel('Population')\n_ = plt.boxplot([real_usa, synth_usa],\n                showfliers=False,\n                labels=['Real', 'Synthetic'],\n                vert=False\n)\nplt.show()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1022\" height=\"500\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png 1022w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The real data shows less variation in city population than the synthetic data. The differences make sense because our model wasn't able to learn about the USA as one complete concept.</p><p><strong>Can we fix this?</strong> It's challenging to fix this issue without degrading the mathematical correlations in some other way. If you have any ideas, we welcome you to <a href=\"https://github.com/sdv-dev/SDV/issues/414\" rel=\"nofollow\">join our discussion</a>!</p><h3 id=\"inputting-a-uniquecombination-into-the-sdv\">Inputting a UniqueCombination into the SDV</h3><p>We built the constraint -- both the <code>reject_sampling</code> and <code>transform</code> approaches -- directly into the SDV library. If you have <code>sdv</code> installed, this is ready to use. Import the <code>UniqueCombinations</code> class from the <code>constraints</code> module.</p><pre><code class=\"language-python\">from sdv.constraints import UniqueCombinations\n\n# Create a Unique Combinations constraint\nunique_city_country_district = UniqueCombinations(\n  columns=['Name', 'CountryCode', 'District'],\n  handling_strategy='transform' # you can change this 'reject_sampling' too\n)\n\n# Create a new model using the constraint\nupdated_model = GaussianCopula(\n  constraints=[unique_city_country_district],\n  categorical_transformer='label_encoding'\n)</code></pre><p>Now, you can train the model on your data and sample synthetic data.</p><pre><code class=\"language-python\">np.random.seed(35)\n\nupdated_model.fit(data)\nupdated_model.sample(5)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1146\" height=\"382\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png 1146w\" sizes=\"(min-width: 720px) 720px\"></figure><p>All of the synthetic data is guaranteed to follow the <code>UniqueCombinations</code> constraint.</p><h3 id=\"takeaways\">Takeaways</h3><ol><li>We can identify a <code>UniqueCombinations</code> requirement by asking: Should it be possible to further mix-and-match the data?</li><li>We can enforce any logical constraint by using reject sampling, which throws out any invalid data. This is not efficient for <code>UniqueCombinations</code>.</li><li>An alternative approach is to transform the data, forcing the ML model to learn the constraint. For <code>UniqueCombinations</code> we transformed the data by concatenating it.</li><li>The logic for <code>UniqueCombinations</code> is already built into the SDV's <code>constraints</code> module, and is ready to use.</li></ol><p>Further reading:</p><ul><li><a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">Engineering Constraints Blog Article</a></li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/constraints.html\" rel=\"nofollow\">Handling Constraints User Guide</a></li><li><a href=\"https://sdv.dev/SDV/api_reference/constraints/tabular.html\" rel=\"nofollow\">Tabular Constraints API</a></li></ul>","url":"https://sdv.ghost.io/building-unique-combinations/","canonical_url":null,"uuid":"01fb2714-6b15-4055-8a77-e7fde4a0f944","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61e841116361ff003b9ca712","reading_time":7}},{"node":{"id":"Ghost__Post__61d3611b6317ec003be8e4b3","title":"The SDV in 2021: A year in review","slug":"2021-year-review","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2022/01/Year-in-review-with-sdv.png","excerpt":"In this article, we summarize SDV growth – downloads as well as community building – that indicates increasing market demand for synthetic data.","custom_excerpt":"In this article, we summarize SDV growth – downloads as well as community building – that indicates increasing market demand for synthetic data.","visibility":"public","created_at_pretty":"03 January, 2022","published_at_pretty":"03 January, 2022","updated_at_pretty":"16 June, 2022","created_at":"2022-01-03T15:48:27.000-05:00","published_at":"2022-01-03T16:07:19.000-05:00","updated_at":"2022-06-16T14:09:32.000-04:00","meta_title":"The SDV in 2021: A year in review","meta_description":"In this article, we summarize SDV growth – downloads as well as community building – that indicates increasing market demand for synthetic data.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"SDV growth – downloads & community building – that indicates increasing market demand for synthetic data.","twitter_image":null,"twitter_title":"The SDV in 2021: A year in review","authors":[{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"}],"primary_author":{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"We started SDV open source in 2018 at MIT with the goal of creating a powerful,\nusable, machine learning-based synthetic data generation software system. The\ncore belief that drove us was the conviction that more than 90% of data work can\nbe done using synthetic data instead of real data. Early experiments at MIT\n[https://news.mit.edu/2017/artificial-data-give-same-results-as-real-data-0303] \nhad been promising and we were ready to invest our time and energy into that\npromise.\n\nNow, 3 years later, we are pleased to see that the market demand for synthetic\ndata is increasing. In a 2021 article, Gartner predicted\n[https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/] \nthat 60% of data used for AI & analytics will be synthetic by 2024. \n\nAs time progressed, we used feedback from our users to make numerous\nimprovements to the SDV (see articles Part 1\n[https://sdv.dev/blog/community-feedback-models/] and Part 2\n[https://sdv.dev/blog/community-feedback-workflow/]). In response, we've seen\nincreased usage, validating the market need for synthetic data generation\nsoftware. In this article, we'll describe the SDV growth trends in detail.\n\nPersistent 4x/year growth in downloads\nEvery year we are experiencing a 4x increase in SDV downloads. In 2021, we had\n135,000 downloads of SDV – up from 30,576 in 2020. From the start of 2020 to the\nend of 2021, we have seen 16x total increase in SDV downloads. The figure below\nshows our yearly usage.\n\nDownloads of SDV per year since we open sourced the library in 2018. By\ndownloading the SDV, a user is signaling their need for synthetic data – which\nwe can interpret as a vote from the market.The downloads are coming from all\nover the world. In the map below, we list the top 10 countries.\n\nDownloads of the SDV in 2021, broken down by the top 10 countries. Notice that\nEurope accounts for 50 half the countries.Why are users downloading the SDV? We\nknow that they want to create synthetic data, but they are using the synthetic\ndata to solve a variety of different needs. We will explore this more and share\nit in a future article.\n\nOver a thousand new community members\nAnother measure of our growth – and validation from the market – comes from the\nSDV community we've built on our GitHub [https://github.com/sdv-dev/SDV] and \nSlack [https://bit.ly/sdv-slack-invite]. In 2021, we welcomed more than 1000 new\nmembers to these spaces.\n\nA summary of how the SDV Community grew in 2021. Any user can join the community\nand actively participate through the SDV GitHub and Slack.As this article\n[https://www.bvp.com/atlas/measuring-the-engagement-of-an-open-source-software-community] \npoints out, members contribute in several different ways: Many help increase\nawareness of an open source solution for this enterprise pain point. Meanwhile,\nothers jump in, use it and give feedback actively. In 2021, we doubled the\nnumber of unique users raising issues on our GitHub. Throughout the  year, over\n200 members actively participated in our forums by raising GitHub issues or\ncontributing to discussions on Slack.\n\nEnterprise feedback is particularly useful to us. This type of feedback comes\nfrom users who are solving targeted business problems with the SDV. Direct and\nsuccinct feedback explains what would make the SDV more useful. An example is\nshown below.\n\nFeedback about a missing feature – composite keys – that would make a direct\nimpact on an enterprise use case. We've removed the user's GitHub account name\nfor privacy. In this case, the missing feature did make it into our pre-alpha.\nOur team addresses the user feedback throughout the entire SDV ecosystem. The\necosystem includes not only modeling, but also the ability to compare models\nthrough SDGym [https://github.com/sdv-dev/SDGym] and measure synthetic data\nquality through SDMetrics [https://github.com/sdv-dev/SDMetrics]. In 2021, the\nteam put out 49 releases throughout the SDV ecosystem, doubling our number of\nreleases in 2020.\n\nLooking forward to 2022!\nWe are looking forward to 2022! With so many users giving us feedback, we have a\nlong list of features that we want to incorporate. We can't wait to share with\nour community what everyone is using SDV for, and keep on climbing to our\noriginal goal: 90% of data work accomplished with synthetic data.","html":"<p>We started SDV open source in 2018 at MIT with the goal of creating a powerful, usable, machine learning-based synthetic data generation software system. The core belief that drove us was the conviction that more than 90% of data work can be done using synthetic data instead of real data. Early<a href=\"https://news.mit.edu/2017/artificial-data-give-same-results-as-real-data-0303\"> experiments at MIT</a> had been promising and we were ready to invest our time and energy into that promise.</p><p>Now, 3 years later, we are pleased to see that the market demand for synthetic data is increasing. In a 2021 article, Gartner <a href=\"https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/\">predicted</a> that 60% of data used for AI &amp; analytics will be synthetic by 2024. </p><p>As time progressed, we used feedback from our users to make numerous improvements to the SDV (see articles <a href=\"https://sdv.dev/blog/community-feedback-models/\">Part 1</a> and <a href=\"https://sdv.dev/blog/community-feedback-workflow/\">Part 2</a>). In response, we've seen increased usage, validating the market need for synthetic data generation software. In this article, we'll describe the SDV growth trends in detail.</p><h3 id=\"persistent-4xyear-growth-in-downloads\">Persistent 4x/year growth in downloads</h3><p>Every year we are experiencing a 4x increase in SDV downloads. In 2021, we had 135,000 downloads of SDV – up from 30,576 in 2020. From the start of 2020 to the end of 2021, we have seen 16x total increase in SDV downloads. The figure below shows our yearly usage.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/downloads-graphic-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"889\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/downloads-graphic-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/downloads-graphic-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/downloads-graphic-1.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/01/downloads-graphic-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Downloads of SDV per year since we open sourced the library in 2018. By downloading the SDV, a user is signaling their need for synthetic data – which we can interpret as a vote from the market.</figcaption></figure><p>The downloads are coming from all over the world. In the map below, we list the top 10 countries.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/worldmap-graphic.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1156\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/worldmap-graphic.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/worldmap-graphic.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/worldmap-graphic.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/01/worldmap-graphic.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Downloads of the SDV in 2021, broken down by the top 10 countries. Notice that Europe accounts for 50 half the countries.</figcaption></figure><p>Why are users downloading the SDV? We know that they want to create synthetic data, but they are using the synthetic data to solve a variety of different needs. We will explore this more and share it in a future article.</p><h3 id=\"over-a-thousand-new-community-members\">Over a thousand new community members</h3><p>Another measure of our growth – and validation from the market – comes from the SDV community we've built on our <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a> and <a href=\"https://bit.ly/sdv-slack-invite\">Slack</a>. In 2021, we welcomed more than 1000 new members to these spaces.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/community-graphic-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"761\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/community-graphic-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/community-graphic-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/community-graphic-2.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/01/community-graphic-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A summary of how the SDV Community grew in 2021. Any user can join the community and actively participate through the SDV GitHub and Slack.</figcaption></figure><p>As <a href=\"https://www.bvp.com/atlas/measuring-the-engagement-of-an-open-source-software-community\">this article</a> points out, members contribute in several different ways: Many help increase awareness of an open source solution for this enterprise pain point. Meanwhile, others jump in, use it and give feedback actively. In 2021, we doubled the number of unique users raising issues on our GitHub. Throughout the  year, over 200 members actively participated in our forums by raising GitHub issues or contributing to discussions on Slack.</p><p>Enterprise feedback is particularly useful to us. This type of feedback comes from users who are solving targeted business problems with the SDV. Direct and succinct feedback explains what would make the SDV more useful. An example is shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1718\" height=\"282\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 1600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 1718w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Feedback about a missing feature – composite keys – that would make a direct impact on an enterprise use case. We've removed the user's GitHub account name for privacy. In this case, the missing feature did make it into our pre-alpha.</figcaption></figure><p>Our team addresses the user feedback throughout the entire SDV ecosystem. The ecosystem includes not only modeling, but also the ability to compare models through <a href=\"https://github.com/sdv-dev/SDGym\">SDGym</a> and measure synthetic data quality through <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>. In 2021, the team put out 49 releases throughout the SDV ecosystem, doubling our number of releases in 2020.</p><h3 id=\"looking-forward-to-2022\">Looking forward to 2022!</h3><p>We are looking forward to 2022! With so many users giving us feedback, we have a long list of features that we want to incorporate. We can't wait to share with our community what everyone is using SDV for, and keep on climbing to our original goal: 90% of data work accomplished with synthetic data.</p>","url":"https://sdv.ghost.io/2021-year-review/","canonical_url":null,"uuid":"36c73725-0b75-4873-bcc3-85e401822bd8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61d3611b6317ec003be8e4b3","reading_time":3}},{"node":{"id":"Ghost__Post__61c10f636317ec003be8e39d","title":"How we engineered constraint handling strategies in SDV","slug":"eng-sdv-constraints","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/12/Banner-01.png","excerpt":"The SDV enforces deterministic rules using constraints. What strategies did we use to engineer this ML system? Dive into the details.","custom_excerpt":"The SDV enforces deterministic rules using constraints. What strategies did we use to engineer this ML system? Dive into the details.","visibility":"public","created_at_pretty":"20 December, 2021","published_at_pretty":"21 December, 2021","updated_at_pretty":"21 December, 2021","created_at":"2021-12-20T18:18:59.000-05:00","published_at":"2021-12-20T19:14:45.000-05:00","updated_at":"2021-12-21T14:23:08.000-05:00","meta_title":"How we engineered constraint handling strategies in the SDV","meta_description":"The SDV enforces deterministic rules using constraints. What strategies did we use to engineer this ML system? Dive into the details.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"The SDV enforces deterministic rules using constraints. What strategies did we use to engineer this ML system?","twitter_image":null,"twitter_title":"How we engineered constraint handling strategies in SDV","authors":[{"name":"Andrew Montanez","slug":"andrew","bio":"For his Master's thesis at MIT, Andrew developed and open sourced the SDV libraries. He wants to use his SDV knowledge and engineering experience to build a leading product in synthetic data.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Andrew_Montanez.jpg","twitter":null,"facebook":null,"website":"https://www.linkedin.com/in/andrew-montanez-593247b2/"}],"primary_author":{"name":"Andrew Montanez","slug":"andrew","bio":"For his Master's thesis at MIT, Andrew developed and open sourced the SDV libraries. He wants to use his SDV knowledge and engineering experience to build a leading product in synthetic data.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Andrew_Montanez.jpg","twitter":null,"facebook":null,"website":"https://www.linkedin.com/in/andrew-montanez-593247b2/"},"primary_tag":{"name":"Engineering","slug":"engineering","description":"Our software is serving a global user base. In our engineering blog, we highlight software challenges and design decisions we've made in support of our community.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Engineering","slug":"engineering","description":"Our software is serving a global user base. In our engineering blog, we highlight software challenges and design decisions we've made in support of our community.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"The SDV uses machine learning (ML) to automatically learn rules (aka\ncorrelations) from real data and generate accurate synthetic data. While these\nmodels are powerful, they may not learn everything. In our previous article\n[https://sdv.dev/blog/user-input-synthetic-data/], we described how the SDV\nmodels may not learn deterministic rules. These are patterns and laws that are\ninherent to the dataset:\n\n * They are unchangeable, no matter what data you input.\n * They describe rules that must apply to every row, no exceptions.\n\nLuckily, it's possible for you to improve the machine learning model: When you\ninput constraints, it ensures the model will learn deterministic rules and\nultimately improve the quality of your synthetic data.\n\nIn this article, we'll dive into the technical details of how you can apply\nconstraints and how they work under-the-hood. You can also follow along in our \nnotebook\n[https://colab.research.google.com/drive/1cVGv2Xtzhd9qHgbkjsYLeLzsA8bDd1uA?usp=sharing]\n.\n\n!pip install sdv==0.13.0\n\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nThe Dataset\nThe dataset we're using comes from a Kaggle Competition\n[https://www.kaggle.com/c/expedia-hotel-recommendations/data?select=train.csv] \nhosted by Expedia. We've modified the data slightly for our use.\n\nfrom sdv.demo import load_tabular_demo\n\ndata = load_tabular_demo('expedia_hotel_logs')\n\nIn this real-world dataset, each row represents a search result for a hotel\nbooking.\n\nFor the purposes of this notebook, we'll drop some columns that aren't useful to\nus.\n\nimport pandas as pd\n\n# Drop some columns that aren't useful for this demo\ndrop_columns = ['date_time', 'user_location_country', 'user_location_region',\n                'user_location_city', 'user_id', 'srch_destination_id',\n                'hotel_country', 'hotel_market', 'hotel_cluster',\n                'srch_destination_type_id', 'orig_destination_distance',\n                'posa_continent', 'site_name', 'channel']\ndata = data.drop(drop_columns, axis=1)\n\n# make sure these columns are read as datetimes\nfor col in ['srch_ci', 'srch_co']:\n  data[col] = pd.to_datetime(data[col])\n\n# Inspect the data\ndata.head()\n\nThe search parameters, for finding a hotel room, saved in this dataset come from\nfrom user's input. For example:\n\nDeterministic Rule\n\nIn order for the search to be valid, the searched check-in date must happen\nbefore the searched check-out date. That is: srch_ci < srch_co.\n\nThis is an inherent property of any search, not just for this particular dataset\n-- we call this a deterministic rule. We can verify if this is true by checking\nfor any exceptions.\n\nprint('Violations of the deterministic rule')\nlen(data[data['srch_ci'] > data['srch_co']])\n\n0\n\nWill SDV's machine learning model learn this out of the box?\n\nTo test this, let's use SDV to learn a GaussianCopula model from the data and\nsample synthetic data.\n\nfrom sdv.tabular import GaussianCopula\n\nnp.random.seed(0)\n\nmodel = GaussianCopula(primary_key='log_id')\nmodel.fit(data)\n\nsynth_data = model.sample(500)\nsynth_data.head()\n\nNow, we can inspect the synthetic data to see if there are any invalid rows.\n\ninvalid_row_indices = synth_data['srch_ci'] > synth_data['srch_co']\ninvalid_rows = synth_data[invalid_row_indices]\n\nnum_invalid = len(invalid_rows)\nperc_invalid = num_invalid / len(synth_data) * 100\nprint('Number of invalid rows:', num_invalid, '(', round(perc_invalid, 2), '%)')\n\ninvalid_rows.head()\n\nThe majority of the rows (94.8%) are valid, meaning the model learned the rule\npretty accurately. It learned probabilistically that if the srch_ci is higher \nsrch_co should be even higher. However, some invalid rows (~5%) are still\ncreated so the model did not learn this deterministic rule.\n\nThis raises the question: What can we do to enforce a deterministic rule?\n\nImproving the synthetic data\nLet's explore some options for enforcing our deterministic rule in order to\nimprove the overall quality of the synthetic data.\n\nRejecting invalid data\n\nThe simplest solution is to simply drop the invalid rows, and continually sample\nfrom the model until the desired amount of valid rows are produced. We call this \nreject sampling.\n\nThe code below performs reject sampling until we have synthesized 500 rows.\n\nimport pandas as pd\n\n# Keep track of how many valid rows we've sampled\nnum_valid_rows = synth_data.shape[0] - invalid_rows.shape[0]\n\nwhile num_valid_rows < 500:\n  # Reject the invalid data \n  synth_data = synth_data.drop(invalid_rows.index)\n  \n  # Create new data to replace the invalid data\n  new_data = model.sample(500-num_valid_rows)\n  synth_data = pd.concat([synth_data, new_data])\n  invalid_rows = synth_data[synth_data['srch_ci'] > synth_data['srch_co']]\n  num_valid_rows = synth_data.shape[0] - invalid_rows.shape[0]\n\nsynth_data.reset_index(drop=True, inplace=True)\n\nNow, there are no invalid rows in our dataset.\n\ninvalid_rows = synth_data[synth_data['srch_ci'] > synth_data['srch_co']]\ninvalid_rows.shape[0]\n\n0\n\nIn this example, we got lucky. Only a small percentage of the rows were invalid\neach time sample was called.\n\nWhat would happen if majority of the rows were invalid every time we sampled? It\nwould take a longer time to get all the desired rows. Sampling time is the\nprimary drawback of reject sampling. Is there another approach we can use to\nimprove the time?\n\nTransforming your data\n\nInstead of reject sampling, what if the model never produced invalid rows in the\nfirst place? To achieve this, we can alter the input data to the model so it's\nforced to learn the constraint.\n\nLet's stop giving the srch_ci and srch_co to the model. Instead, let's teach the\nmodel to learn the srch_ci and the difference between the dates.\n\ndifference = srch_co - srch_ci\n\nThe model will produce srch_ci and difference as a result. Then, we can\nre-compute srch_co with the opposite formula.\n\nsrch_co = srch_ci + difference\n\n(Of course, we need to make sure the difference is always positive, which we can\ndo using a log + 1.)\n\nLet's see this in action.\n\n# Compute the difference\ndiff = (data['srch_co'] - data['srch_ci']).astype('timedelta64[D]')\n\n# Take the log and add one to ensure that it's positive\ndate_diff = np.log(diff + 1)\n\n# The model should learn this column instead of the checkout date\nmodified_data = data.drop('srch_co', axis=1)\nmodified_data['difference'] = date_diff\nmodified_data[['srch_ci', 'difference']].head()\n\nNow, we can fit the model with the modified data. The new samples will include\nthe srch_ci and date_diff columns.\n\nnp.random.seed(20)\n\nmodified_model = GaussianCopula(primary_key='log_id')\nmodified_model.fit(modified_data)\n\nmodified_synth_data = modified_model.sample(500)\nmodified_synth_data[['srch_ci', 'difference']].head()\n\nWe can recompute the srch_co based on srch_ci and difference.\n\n# Undo the log+1 that we added\ndiff = (np.exp(modified_synth_data['difference'].values).round() - 1).clip(0).astype('timedelta64[ns]')\n\n# Reconstruct the end_date and remove the date_diff column\nmodified_synth_data['srch_co'] = modified_synth_data['srch_ci'] + diff\nmodified_synth_data = modified_synth_data.drop('difference', axis=1)\n\nmodified_synth_data.head()\n\nLet's verify that this computation does not create any invalid rows.\n\ninvalid_rows = modified_synth_data[modified_synth_data['srch_ci'] > modified_synth_data['srch_co']]\ninvalid_rows.shape[0]\n\n0\n\nThe transformation worked! In our case, this was a more efficient way to enforce\nthe deterministic rule.\n\nBut if our rule were more complex -- and we couldn't think of a transformation\n-- we could always fall back to reject sampling.\n\nInputting deterministic rules in the SDV\nWe've seen how reject sampling and transform can be used to improve the quality\nof the synthetic data by accounting for deterministic rules. However, it may be\ncumbersome for you to manually implement these strategies. In fact, we saw some\ncommon problems in our SDV user community:\n\n * Users had multiple deterministic rules in their dataset. For example, there\n   could be multiple comparisons between different pairs of columns.\n * Users from multiple domains often had the same kind of deterministic rule.\n   For example, one column being greater than another is a common deterministic\n   rule, agonistic of a use case or domain.\n\nTo solve these problems, we introduced a constraints module in the SDV. With the\nconstraints module, SDV users can easily input deterministic rules. Let's look\nat an example.\n\nUsing the SDV constraints module\n\nThe constraints module in the SDV contains several different types of\npre-defined deterministic rules.\n\nWe will use the GreaterThan constraint, which will enforce that one column's\nvalues are always greater than another's.\n\nfrom sdv.constraints import GreaterThan\n\nNext, we can input the logic of our deterministic rule by creating a constraint\nobject. The GreaterThan constraint accepts the column names as input.\n\ngt_constraint = GreaterThan(\n  low='srch_ci',\n  high='srch_co')\n\nFinally, we can input this constraint when instantiating the model.\n\nnp.random.seed(10)\n\n# Apply the constraint to the model\nmodel_with_constraint = GaussianCopula(\n  primary_key='log_id',\n  constraints=[gt_constraint])\n\nmodel_with_constraint.fit(data)\n\n# Sample synthetic data\nconstrained_data = model_with_constraint.sample(500)\nconstrained_data.head()\n\nAs a result, we should see that all 500 generated rows are valid on the first\ntry. No invalid rows are present in our dataset.\n\ninvalid_rows = constrained_data[constrained_data['srch_ci'] > constrained_data['srch_co']]\ninvalid_rows.shape[0]\n\n0\n\nUsing the SDV was much simpler than writing the code ourselves! Plus, we can\ncreate multiple constraints for the same dataset an easily use them on other\ndatasets.\n\nSpecifying the strategy in the constraints module\n\nBy default, the GreaterThan constraint uses the transform strategy. However, you\ncan use the handling_strategy argument to control this. This argument accepts \n'reject_sampling' or 'transform' as valid strategies.\n\ngt_reject_constraint = GreaterThan(\n  low='srch_ci',\n  high='srch_co',\n  handling_strategy='reject_sampling' # specify the strategy\n)\n\nSimilar to before, we can then input this constraint into the model.\n\nnp.random.seed(30)\n\n# Apply the constraint to the model\nmodel_with_reject_constraint = GaussianCopula(\n  primary_key='log_id',\n  constraints=[gt_reject_constraint])\n\nmodel_with_reject_constraint.fit(data)\n\n# Sample synthetic data\nconstrained_reject_data = model_with_reject_constraint.sample(500)\nconstrained_reject_data.head()\n\ninvalid_rows = constrained_reject_data[constrained_reject_data['srch_ci'] > constrained_reject_data['srch_co']\ninvalid_rows.shape[0]\n\n0\n\nWhat other deterministic rules are already available in SDV?\nThe GreaterThan constraint is one kind of deterministic rule, but there may be\nothers that apply to your dataset. The SDV offers more constraints for other\ntypes of logic.\n\n * Unique\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#unique-constraint] \n   when values in a column must be unique to the entire dataset.\n * UniqueCombinations\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#uniquecombinations-constraint] \n   to limit the permutations between multiple columns.\n * Positive and Negative\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#positive-and-negative-constraints] \n   to enforce boundaries.\n * ColumnFormula\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#columnformula-constraint] \n   when there is a formulaic association between columns.\n * Rounding\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#rounding-constraint] \n   to enforce decimal precision.\n * Between\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#between-constraint] \n   when one column's values must be between 2 other values.\n * OneHotEncoding\n   [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#onehotencoding-constraint] \n   when your data includes a variable with one hot encoding.\n\nFor each of them, you can specify handling strategies for reject_sampling to\ndiscard invalid data or transform to modify the data (unique to each\nconstraint).\n\nWhat if my rule isn't included in the module?\n\nYou may come across a rule that cannot be described by any of the constraints\nclasses in the SDV. In this case, you can define a CustomConstraint\n[https://sdv.dev/SDV/user_guides/single_table/custom_constraints.html#defining-custom-constraints] \nwith logic specific to your use case.\n\nAdditionally, consider filing a feature request on GitHub\n[https://github.com/sdv-dev/SDV/issues/new/choose] with details about your use\ncase & scenario. We can add your logic as a pre-defined constraint so others can\nbenefit from it too!\n\nTakeaways\nIn this notebook, we explored what happens when we have a deterministic rule in\nour dataset.\n\n 1. Machine learning models may not able to learn the deterministic rules out of\n    the box, but it is possible to improve the model to learn these types of\n    rules.\n 2. Deterministic rules can be handled by discarding invalid data (reject\n    sampling) or by adding some clever preprocessing to your code (transforming\n    ).\n 3. The SDV offers a constraints module that allows you to input commonly found\n    deterministic rules. You can specify the handling strategy for each\n    constraint and apply multiple rules to the same dataset.\n\nFurther Reading\n\nFor further information about constraints refer to the Handling Constraints\nUser\nGuide [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html].","html":"<p>The SDV uses machine learning (ML) to automatically learn rules (aka correlations) from real data and generate accurate synthetic data. While these models are powerful, they may not learn everything. In our <a href=\"https://sdv.dev/blog/user-input-synthetic-data/\" rel=\"nofollow\">previous article</a>, we described how the SDV models may not learn <strong>deterministic rules</strong>. These are patterns and laws that are inherent to the dataset:</p><ul><li>They are unchangeable, no matter what data you input.</li><li>They describe rules that must apply to every row, no exceptions.</li></ul><p>Luckily, it's possible for you to improve the machine learning model: When you input constraints, it ensures the model will learn deterministic rules and ultimately improve the quality of your synthetic data.</p><p>In this article, we'll dive into the technical details of how you can apply constraints and how they work under-the-hood. You can also follow along in our <a href=\"https://colab.research.google.com/drive/1cVGv2Xtzhd9qHgbkjsYLeLzsA8bDd1uA?usp=sharing\">notebook</a>.</p><pre><code>!pip install sdv==0.13.0</code></pre><pre><code class=\"language-python\">import numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')</code></pre><h3 id=\"the-dataset\">The Dataset</h3><p>The dataset we're using comes from a <a href=\"https://www.kaggle.com/c/expedia-hotel-recommendations/data?select=train.csv\" rel=\"nofollow\">Kaggle Competition</a> hosted by Expedia. We've modified the data slightly for our use.</p><pre><code class=\"language-python\">from sdv.demo import load_tabular_demo\n\ndata = load_tabular_demo('expedia_hotel_logs')</code></pre><p>In this real-world dataset, each row represents a search result for a hotel booking.</p><p>For the purposes of this notebook, we'll drop some columns that aren't useful to us.</p><pre><code class=\"language-python\">import pandas as pd\n\n# Drop some columns that aren't useful for this demo\ndrop_columns = ['date_time', 'user_location_country', 'user_location_region',\n                'user_location_city', 'user_id', 'srch_destination_id',\n                'hotel_country', 'hotel_market', 'hotel_cluster',\n                'srch_destination_type_id', 'orig_destination_distance',\n                'posa_continent', 'site_name', 'channel']\ndata = data.drop(drop_columns, axis=1)\n\n# make sure these columns are read as datetimes\nfor col in ['srch_ci', 'srch_co']:\n  data[col] = pd.to_datetime(data[col])\n\n# Inspect the data\ndata.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.36.14-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"349\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Screen-Shot-2021-12-20-at-3.36.14-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Screen-Shot-2021-12-20-at-3.36.14-PM.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Screen-Shot-2021-12-20-at-3.36.14-PM.png 1600w, https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.36.14-PM.png 2122w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The search parameters, for finding a hotel room, saved in this dataset come from from user's input. For example:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/EngineeredConstraint-08.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"912\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/EngineeredConstraint-08.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/EngineeredConstraint-08.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/EngineeredConstraint-08.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/12/EngineeredConstraint-08.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Deterministic Rule</strong></p><p>In order for the search to be valid, the searched check-in date must happen before the searched check-out date. That is: <code>srch_ci &lt; srch_co</code>.</p><p>This is an inherent property of any search, not just for this particular dataset -- we call this a <strong>deterministic rule</strong>. We can verify if this is true by checking for any exceptions.</p><pre><code class=\"language-python\">print('Violations of the deterministic rule')\nlen(data[data['srch_ci'] &gt; data['srch_co']])</code></pre><pre><code>0</code></pre><p><strong>Will SDV's machine learning model learn this out of the box?</strong></p><p>To test this, let's use SDV to learn a <code>GaussianCopula</code> model from the data and sample synthetic data.</p><pre><code class=\"language-python\">from sdv.tabular import GaussianCopula\n\nnp.random.seed(0)\n\nmodel = GaussianCopula(primary_key='log_id')\nmodel.fit(data)\n\nsynth_data = model.sample(500)\nsynth_data.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.36.54-PM-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"388\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Screen-Shot-2021-12-20-at-3.36.54-PM-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Screen-Shot-2021-12-20-at-3.36.54-PM-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Screen-Shot-2021-12-20-at-3.36.54-PM-1.png 1600w, https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.36.54-PM-1.png 2050w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Now, we can inspect the synthetic data to see if there are any invalid rows.</p><pre><code class=\"language-python\">invalid_row_indices = synth_data['srch_ci'] &gt; synth_data['srch_co']\ninvalid_rows = synth_data[invalid_row_indices]\n\nnum_invalid = len(invalid_rows)\nperc_invalid = num_invalid / len(synth_data) * 100\nprint('Number of invalid rows:', num_invalid, '(', round(perc_invalid, 2), '%)')\n\ninvalid_rows.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.37.27-PM-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"414\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Screen-Shot-2021-12-20-at-3.37.27-PM-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Screen-Shot-2021-12-20-at-3.37.27-PM-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Screen-Shot-2021-12-20-at-3.37.27-PM-1.png 1600w, https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.37.27-PM-1.png 2070w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The majority of the rows (94.8%) are valid, meaning the model learned the rule pretty accurately. It learned probabilistically that if the <code>srch_ci</code> is higher <code>srch_co</code> should be even higher. However, some invalid rows (~5%) are still created so <strong>the model did not learn this deterministic rule.</strong></p><p>This raises the question: What can we do to enforce a deterministic rule?</p><h3 id=\"improving-the-synthetic-data\">Improving the synthetic data</h3><p>Let's explore some options for enforcing our deterministic rule in order to improve the overall quality of the synthetic data.</p><p><strong>Rejecting invalid data</strong></p><p>The simplest solution is to simply drop the invalid rows, and continually sample from the model until the desired amount of valid rows are produced. We call this <strong>reject sampling</strong>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/EngineeredConstraint-07--1-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"493\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/EngineeredConstraint-07--1-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/EngineeredConstraint-07--1-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/EngineeredConstraint-07--1-.png 1600w, https://sdv.ghost.io/content/images/2021/12/EngineeredConstraint-07--1-.png 2071w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The code below performs reject sampling until we have synthesized 500 rows.</p><pre><code class=\"language-python\">import pandas as pd\n\n# Keep track of how many valid rows we've sampled\nnum_valid_rows = synth_data.shape[0] - invalid_rows.shape[0]\n\nwhile num_valid_rows &lt; 500:\n  # Reject the invalid data \n  synth_data = synth_data.drop(invalid_rows.index)\n  \n  # Create new data to replace the invalid data\n  new_data = model.sample(500-num_valid_rows)\n  synth_data = pd.concat([synth_data, new_data])\n  invalid_rows = synth_data[synth_data['srch_ci'] &gt; synth_data['srch_co']]\n  num_valid_rows = synth_data.shape[0] - invalid_rows.shape[0]\n\nsynth_data.reset_index(drop=True, inplace=True)</code></pre><p>Now, there are no invalid rows in our dataset.</p><pre><code class=\"language-python\">invalid_rows = synth_data[synth_data['srch_ci'] &gt; synth_data['srch_co']]\ninvalid_rows.shape[0]</code></pre><pre><code>0</code></pre><p>In this example, we got lucky. Only a small percentage of the rows were invalid each time <code>sample</code> was called.</p><p>What would happen if majority of the rows were invalid every time we sampled? It would take a longer time to get all the desired rows. <strong>Sampling time is the primary drawback of reject sampling. </strong>Is there another approach we can use to improve the time?</p><p><strong>Transforming your data</strong></p><p>Instead of reject sampling, what if the model never produced invalid rows in the first place? To achieve this, we can alter the input data to the model so it's forced to learn the constraint.</p><p>Let's stop giving the <code>srch_ci</code> and <code>srch_co</code> to the model. Instead, let's teach the model to learn the <code>srch_ci</code> and the <code>difference</code> between the dates.</p><pre><code>difference = srch_co - srch_ci</code></pre><p>The model will produce <code>srch_ci</code> and <code>difference</code> as a result. Then, we can re-compute <code>srch_co</code> with the opposite formula.</p><pre><code>srch_co = srch_ci + difference</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/EngineeredConstraint-06--1-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"879\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/EngineeredConstraint-06--1-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/EngineeredConstraint-06--1-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/EngineeredConstraint-06--1-.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/12/EngineeredConstraint-06--1-.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>(Of course, we need to make sure the difference is always positive, which we can do using a <code>log + 1</code>.)</p><p>Let's see this in action.</p><pre><code class=\"language-python\"># Compute the difference\ndiff = (data['srch_co'] - data['srch_ci']).astype('timedelta64[D]')\n\n# Take the log and add one to ensure that it's positive\ndate_diff = np.log(diff + 1)\n\n# The model should learn this column instead of the checkout date\nmodified_data = data.drop('srch_co', axis=1)\nmodified_data['difference'] = date_diff\nmodified_data[['srch_ci', 'difference']].head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.30.15-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"390\" height=\"360\"></figure><p>Now, we can fit the model with the modified data. The new samples will include the <code>srch_ci</code> and <code>date_diff</code> columns.</p><pre><code class=\"language-python\">np.random.seed(20)\n\nmodified_model = GaussianCopula(primary_key='log_id')\nmodified_model.fit(modified_data)\n\nmodified_synth_data = modified_model.sample(500)\nmodified_synth_data[['srch_ci', 'difference']].head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.31.03-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"392\" height=\"356\"></figure><p>We can recompute the <code>srch_co</code> based on <code>srch_ci</code> and <code>difference</code>.</p><pre><code class=\"language-python\"># Undo the log+1 that we added\ndiff = (np.exp(modified_synth_data['difference'].values).round() - 1).clip(0).astype('timedelta64[ns]')\n\n# Reconstruct the end_date and remove the date_diff column\nmodified_synth_data['srch_co'] = modified_synth_data['srch_ci'] + diff\nmodified_synth_data = modified_synth_data.drop('difference', axis=1)\n\nmodified_synth_data.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.38.38-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"491\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Screen-Shot-2021-12-20-at-3.38.38-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Screen-Shot-2021-12-20-at-3.38.38-PM.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Screen-Shot-2021-12-20-at-3.38.38-PM.png 1600w, https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.38.38-PM.png 2142w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Let's verify that this computation does not create any invalid rows.</p><pre><code class=\"language-python\">invalid_rows = modified_synth_data[modified_synth_data['srch_ci'] &gt; modified_synth_data['srch_co']]\ninvalid_rows.shape[0]</code></pre><pre><code>0</code></pre><p>The transformation worked! In our case, this was a more efficient way to enforce the deterministic rule.</p><p>But if our rule were more complex -- and we couldn't think of a transformation -- we could always fall back to reject sampling.</p><h3 id=\"inputting-deterministic-rules-in-the-sdv\">Inputting deterministic rules in the SDV</h3><p>We've seen how reject sampling and transform can be used to improve the quality of the synthetic data by accounting for deterministic rules. However, it may be cumbersome for you to manually implement these strategies. In fact, we saw some common problems in our SDV user community:</p><ul><li>Users had multiple deterministic rules in their dataset. For example, there could be multiple comparisons between different pairs of columns.</li><li>Users from multiple domains often had the same kind of deterministic rule. For example, one column being greater than another is a common deterministic rule, agonistic of a use case or domain.</li></ul><p>To solve these problems, we introduced a constraints module in the SDV. <strong>With the constraints module, SDV users can easily input deterministic rules. </strong>Let's look at an example.</p><p><strong>Using the SDV constraints module</strong></p><p>The <code>constraints</code> module in the SDV contains several different types of pre-defined deterministic rules.</p><p>We will use the <code>GreaterThan</code> constraint, which will enforce that one column's values are always greater than another's.</p><pre><code class=\"language-python\">from sdv.constraints import GreaterThan</code></pre><p>Next, we can input the logic of our deterministic rule by creating a constraint object. The <code>GreaterThan</code> constraint accepts the column names as input.</p><pre><code class=\"language-python\">gt_constraint = GreaterThan(\n  low='srch_ci',\n  high='srch_co')</code></pre><p>Finally, we can input this constraint when instantiating the model.</p><pre><code class=\"language-python\">np.random.seed(10)\n\n# Apply the constraint to the model\nmodel_with_constraint = GaussianCopula(\n  primary_key='log_id',\n  constraints=[gt_constraint])\n\nmodel_with_constraint.fit(data)\n\n# Sample synthetic data\nconstrained_data = model_with_constraint.sample(500)\nconstrained_data.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.39.11-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"389\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Screen-Shot-2021-12-20-at-3.39.11-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Screen-Shot-2021-12-20-at-3.39.11-PM.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Screen-Shot-2021-12-20-at-3.39.11-PM.png 1600w, https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.39.11-PM.png 2046w\" sizes=\"(min-width: 720px) 720px\"></figure><p>As a result, we should see that all 500 generated rows are valid on the first try. No invalid rows are present in our dataset.</p><pre><code class=\"language-python\">invalid_rows = constrained_data[constrained_data['srch_ci'] &gt; constrained_data['srch_co']]\ninvalid_rows.shape[0]</code></pre><pre><code>0</code></pre><p>Using the SDV was much simpler than writing the code ourselves! Plus, we can create multiple constraints for the same dataset an easily use them on other datasets.</p><p><strong>Specifying the strategy in the constraints module</strong></p><p>By default, the <code>GreaterThan</code> constraint uses the <code>transform</code> strategy. However, you can use the <code>handling_strategy</code> argument to control this. This argument accepts <code>'reject_sampling'</code> or <code>'transform'</code> as valid strategies.</p><pre><code class=\"language-python\">gt_reject_constraint = GreaterThan(\n  low='srch_ci',\n  high='srch_co',\n  handling_strategy='reject_sampling' # specify the strategy\n)</code></pre><p>Similar to before, we can then input this constraint into the model.</p><pre><code class=\"language-python\">np.random.seed(30)\n\n# Apply the constraint to the model\nmodel_with_reject_constraint = GaussianCopula(\n  primary_key='log_id',\n  constraints=[gt_reject_constraint])\n\nmodel_with_reject_constraint.fit(data)\n\n# Sample synthetic data\nconstrained_reject_data = model_with_reject_constraint.sample(500)\nconstrained_reject_data.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.40.44-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"377\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Screen-Shot-2021-12-20-at-3.40.44-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Screen-Shot-2021-12-20-at-3.40.44-PM.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Screen-Shot-2021-12-20-at-3.40.44-PM.png 1600w, https://sdv.ghost.io/content/images/2021/12/Screen-Shot-2021-12-20-at-3.40.44-PM.png 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><pre><code class=\"language-python\">invalid_rows = constrained_reject_data[constrained_reject_data['srch_ci'] &gt; constrained_reject_data['srch_co']\ninvalid_rows.shape[0]</code></pre><pre><code>0</code></pre><h3 id=\"what-other-deterministic-rules-are-already-available-in-sdv\">What other deterministic rules are already available in SDV?</h3><p>The <code>GreaterThan</code> constraint is one kind of deterministic rule, but there may be others that apply to your dataset. The SDV offers more constraints for other types of logic.</p><ul><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#unique-constraint\" rel=\"nofollow\">Unique</a> when values in a column must be unique to the entire dataset.</li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#uniquecombinations-constraint\" rel=\"nofollow\">UniqueCombinations</a> to limit the permutations between multiple columns.</li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#positive-and-negative-constraints\" rel=\"nofollow\">Positive and Negative</a> to enforce boundaries.</li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#columnformula-constraint\" rel=\"nofollow\">ColumnFormula</a> when there is a formulaic association between columns.</li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#rounding-constraint\" rel=\"nofollow\">Rounding</a> to enforce decimal precision.</li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#between-constraint\" rel=\"nofollow\">Between</a> when one column's values must be between 2 other values.</li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html#onehotencoding-constraint\" rel=\"nofollow\">OneHotEncoding</a> when your data includes a variable with one hot encoding.</li></ul><p>For each of them, you can specify handling strategies for <code>reject_sampling</code> to discard invalid data or <code>transform</code> to modify the data (unique to each constraint).</p><p><strong>What if my rule isn't included in the module?</strong></p><p>You may come across a rule that cannot be described by any of the constraints classes in the SDV. In this case, you can define a <a href=\"https://sdv.dev/SDV/user_guides/single_table/custom_constraints.html#defining-custom-constraints\" rel=\"nofollow\">CustomConstraint</a> with logic specific to your use case.</p><p>Additionally, consider <a href=\"https://github.com/sdv-dev/SDV/issues/new/choose\" rel=\"nofollow\"><strong>filing a feature request on GitHub</strong></a> with details about your use case &amp; scenario. We can add your logic as a pre-defined constraint so others can benefit from it too!</p><h3 id=\"takeaways\">Takeaways</h3><p>In this notebook, we explored what happens when we have a deterministic rule in our dataset.</p><ol><li>Machine learning models may not able to learn the deterministic rules out of the box, but it is possible to improve the model to learn these types of rules.</li><li>Deterministic rules can be handled by discarding invalid data (<strong>reject sampling</strong>) or by adding some clever preprocessing to your code (<strong>transforming</strong>).</li><li>The SDV offers a <code>constraints</code> module that allows you to input commonly found deterministic rules. You can specify the handling strategy for each constraint and apply multiple rules to the same dataset.</li></ol><p><strong>Further Reading</strong></p><p>For further information about constraints refer to the <a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html\" rel=\"nofollow\">Handling Constraints User Guide</a>.</p>","url":"https://sdv.ghost.io/eng-sdv-constraints/","canonical_url":null,"uuid":"e4f85a3b-a4f0-4389-a9b8-f4d9faa60f74","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61c10f636317ec003be8e39d","reading_time":8}},{"node":{"id":"Ghost__Post__61a68d091b683e0048b2a2f3","title":"User input to enhance synthetic data generation","slug":"user-input-synthetic-data","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/11/Banner.png","excerpt":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","custom_excerpt":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","visibility":"public","created_at_pretty":"30 November, 2021","published_at_pretty":"01 December, 2021","updated_at_pretty":"02 December, 2021","created_at":"2021-11-30T15:43:53.000-05:00","published_at":"2021-12-01T11:06:49.000-05:00","updated_at":"2021-12-02T18:23:08.000-05:00","meta_title":"User input to enhance synthetic data generation","meta_description":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","twitter_image":"https://sdv.ghost.io/content/images/2021/11/Banner-1.png","twitter_title":"User input to enhance synthetic data generation","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In our previous article [https://sdv.dev/blog/fake-to-synthetic-ml], we explored\nhow machine learning (ML) plays a key role in synthetic data creation. One of\nthe biggest strengths of ML is automatic rule detection (also known in ML terms\nas correlations): The algorithms are designed to learn patterns in the data,\neven without additional user input. The result is synthetic data that resembles\nthe original, right down to its mathematical properties!\n\nHowever, in some cases, applying an ML model right out of the box may not\nimmediately achieve the desired result. In this article, we'll explore the\nstrengths of ML models and go through those areas where user input may be\nrequired.\n\nStrengths of ML Models\nThe goal of any ML-based synthetic data generation software is to learn from and\nemulate the input data. To illustrate this, let's pretend you work in the car\ninsurance business, and you're in possession of a real dataset related to\ndrivers and their insurance:\n\nAn example dataset, including license and collision coverage information\nassociated with different drivers.An ML-based system, such as the Synthetic Data Vault\n[https://sdv.dev/blog/intro-to-sdv/] (SDV), will learn patterns from the real\ndata and use it to create new synthetic data. Recall some of the important\npatterns that ML algorithms detect:\n\n * Shapes. The general shape of the data. For example, in the dataset above, 50%\n   of drivers have Collision Coverage and the Annual Premium is uniformly\n   scattered between $3,000 and $9,000.\n * Correlations. The trends within the data. For example, having Collision\n   Coverage -- especially Standard coverage -- means a higher Annual Premium.\n\nThese shapes and correlations will be present in the synthetic data that is\noutputted by the ML model, as shown below.\n\nAn example of a synthetic dataset created by an ML-based algorithm. The\nalgorithm will learn patterns from the real data and emulate them.Perhaps the single biggest strength of an ML algorithm is its ability to learn\nrules by looking for general patterns in the data, using probability and\nstatistics.\n\nWhat ML models do not learn out of the box\nLet's take a closer look at the synthetic car insurance data. You might notice\nthat two of the rows in the synthetic data don't make complete sense. Below,\nwe've highlighted the errors.\n\nThe synthetic car insurance data, with errors highlighted.Do you see what has\ngone wrong? In the first row, the license expired 3 years earlier than it was\nissued. In the last row, a driver without Collision Coverage has a Collision\nPolicy Type. Additionally, the same Customer ID has been repeated in Row 3 and\nRow 4.\n\nThere are three rules that the ML algorithm did not follow:\n\n 1. License Expiration > License Issue Year\n 2. If Has Collision Coverage = NO, then Collision Policy Type must be empty\n 3. All Customer IDs must be unique\n\nWhy does the ML model easily pick up on some rules and not others? To answer\nthis question, we can look closely at the rules themselves. All of the rules\nthat the ML model successfully learned -- including the distribution shapes and\nthe correlations -- were based on general trends. These probabilistic rules \napply to a majority of the relationships within the dataset, but not all of\nthem. Although they have to make sense in aggregate, a few rows may be\nexceptions.\n\nBy contrast, the rules that the ML model failed to learn were stricter. These \ndeterministic rules describe intrinsic laws of nature, time or logic. Each and\nevery row must adhere to them, and they won't change regardless of  how much (or\nhow little) data has been given to the ML model.\n\nTo continue with the driving theme: A probabilistic rule is like a yield sign,\nsignaling a general recommendation that works out differently for each\nindividual situation -- some cars may need to stop, while others just slow down.\nMeanwhile, a deterministic rule is like a stop sign, demanding that every single\ncar must come to a full stop.\n\nA probabilistic rule applies to a majority of rows, but leaves room for\nexceptions. Meanwhile, a deterministic rule applies to every single row.By\ndefault, our ML model assumed that all rules were probabilistic. When this\nhappens, synthetic data still generally follows the desired properties -- for\nexample, License Expiration > License Issue Year -- for most of the rows, but\nnot for every row.\n\nImproving the ML Models using constraints\nJust because the ML model didn't automatically follow a deterministic rule\ndoesn't mean that it can't. It's possible to improve the model so that it\nunderstands this type of rule. As a user working with the SDV, you can input\ndeterministic rules into your model using constraints.\n\nAn ML model built using constraints will accommodate both probabilistic and\ndeterministic rules.\n\nDo you need SDV constraints?\n\nDeterministic rules are often easy to spot in your dataset: They are the rules\nthat every single row must follow in order to be valid, regardless of how much\ndata there is overall.  But even if you identify the right constraints, there\nare some cases where you might not actually want to supply them to the SDV.\n\nBecause the SDV learns probabilistic rules, most of the synthesized data is\ngenerally valid. Having a few errors sprinkled in might actually be beneficial\nif you want your synthetic data to cover some edge cases. For example, if you're\nusing the synthetic data to test insurance claim software, leaving in some weird\ndata points might help you ensure that the software can handle unexpected cases\n-- like the License Expiration accidentally being set too early.\n\nThe figure below shows a few questions you can ask to determine whether adding a\nconstraint is the right approach.\n\nShould you input a rule using constraints? First, determine whether the rule is\ndeterministic, and then take your use case into account.The SDV Constraints\noffering\n\nIf you decide that adding deterministic rules is important for generating your\nsynthetic data, the SDV has many different constraints to choose from! The table\nbelow describes the constraints you would need in order to define the\ndeterministic rules that would best mold your Car Insurance dataset.\n\nThe GreaterThan, ColumnFormula and Unique constraints -- all available in the\nSDV -- set the deterministic rules that ensure your synthetic Car Insurance Data\nis useful and makes sense.The SDV offers many more possible constraints,\nincluding:\n\n * UniqueCombinations\n * Positive and Negative\n * Rounding\n * Between\n * OneHotEncoding\n\nYou can add multiple constraints to the same dataset in order to accommodate all\nthe deterministic rules you need. For more details, read the Constraints User\nGuide [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html].\n\nTakeaways\nIn this article, we learned that:\n\n * Data is governed by rules. The SDV automatically learns probabilistic rules,\n   which describe overall trends or patterns in the data.\n * However, sometimes the data has deterministic rules, which are always\n   inherent no matter how much or how little data there is. ML-based systems,\n   including the SDV, may not enforce deterministic rules out of the box.\n * Users can input deterministic rules to the SDV using constraints. To figure\n   out whether you should input a constraint, ask yourself whether there are any\n   rules that the data must always follow. There are many constraints to choose\n   from.\n\nIn future articles, we'll dive deeper into this topic. We'll explore the\ntechnical details behind constraints, and how exactly the SDV's ML models are\nable to learn deterministic rules.","html":"<p>In our <a href=\"https://sdv.dev/blog/fake-to-synthetic-ml\">previous article</a>, we explored how machine learning (ML) plays a key role in synthetic data creation. One of the biggest strengths of ML is <em>automatic rule detection</em> (also known in ML terms as <em>correlations</em>): The algorithms are designed to learn patterns in the data, even without additional user input. The result is synthetic data that resembles the original, right down to its mathematical properties!</p><p>However, in some cases, applying an ML model right out of the box may not immediately achieve the desired result. In this article, we'll explore the strengths of ML models and go through those areas where user input may be required.</p><h3 id=\"strengths-of-ml-models\">Strengths of ML Models</h3><p>The goal of any ML-based synthetic data generation software is to learn from and emulate the input data. To illustrate this, let's pretend you work in the car insurance business, and you're in possession of a real dataset related to drivers and their insurance:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-03.png\" class=\"kg-image\" alt=\"An example dataset, including license and collision coverage information associated with different drivers.\" loading=\"lazy\" width=\"1916\" height=\"835\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-03.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-03.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-03.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-03.png 1916w\" sizes=\"(min-width: 720px) 720px\"><figcaption>An example dataset, including license and collision coverage information associated with different drivers.</figcaption></figure><p>An ML-based system, such as the <a href=\"https://sdv.dev/blog/intro-to-sdv/\">Synthetic Data Vault</a> (SDV), will learn patterns from the real data and use it to create new synthetic data. Recall some of the important patterns that ML algorithms detect:</p><ul><li><strong><strong><strong>Shapes. </strong></strong></strong>The general shape of the data. For example, in the dataset above, 50% of drivers have Collision Coverage and the Annual Premium is uniformly scattered between $3,000 and $9,000.</li><li><strong><strong><strong>Correlations.</strong> </strong></strong>The trends within the data. For example, having Collision Coverage -- especially Standard coverage -- means a higher Annual Premium.</li></ul><p>These shapes and correlations will be present in the synthetic data that is outputted by the ML model, as shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-04.png\" class=\"kg-image\" alt=\"An example of a synthetic dataset created by an ML-based algorithm. The algorithm will learn patterns from the real data and emulate them.\" loading=\"lazy\" width=\"1875\" height=\"832\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-04.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-04.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-04.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-04.png 1875w\" sizes=\"(min-width: 720px) 720px\"><figcaption>An example of a synthetic dataset created by an ML-based algorithm. The algorithm will learn patterns from the real data and emulate them.</figcaption></figure><p>Perhaps <strong>the single biggest strength of an ML algorithm is its ability to learn rules by looking for general patterns in the data,</strong> using probability and statistics.</p><h3 id=\"what-ml-models-do-not-learn-out-of-the-box\">What ML models do not learn out of the box</h3><p>Let's take a closer look at the synthetic car insurance data. You might notice that two of the rows in the synthetic data don't make complete sense. Below, we've highlighted the errors.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-05.png\" class=\"kg-image\" alt=\"The synthetic car insurance data, with errors highlighted. \" loading=\"lazy\" width=\"1867\" height=\"831\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-05.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-05.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-05.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-05.png 1867w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The synthetic car insurance data, with errors highlighted.</figcaption></figure><p>Do you see what has gone wrong? In the first row, the license expired 3 years earlier than it was issued. In the last row, a driver without Collision Coverage has a Collision Policy Type. Additionally, the same Customer ID has been repeated in Row 3 and Row 4.</p><p>There are three rules that the ML algorithm did not follow:</p><ol><li>License Expiration &gt; License Issue Year</li><li>If Has Collision Coverage = NO, then Collision Policy Type must be empty</li><li>All Customer IDs must be unique</li></ol><p>Why does the ML model easily pick up on some rules and not others? To answer this question, we can look closely at the rules themselves. All of the rules that the ML model successfully learned -- including the distribution shapes and the correlations -- were based on general trends. These <strong>probabilistic rules</strong> apply to a majority of the relationships within the dataset, but not all of them. Although they have to make sense in aggregate, a few rows may be exceptions.</p><p>By contrast, the rules that the ML model failed to learn were stricter. These <strong>deterministic rules</strong> describe intrinsic laws of nature, time or logic. Each and every row must adhere to them, and they won't change regardless of  how much (or how little) data has been given to the ML model.</p><p>To continue with the driving theme: A probabilistic rule is like a yield sign, signaling a general recommendation that works out differently for each individual situation -- some cars may need to stop, while others just slow down. Meanwhile, a deterministic rule is like a stop sign, demanding that every single car must come to a full stop.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-06.png\" class=\"kg-image\" alt=\"A probabilistic rule applies to a majority of rows, but leaves room for exceptions. Meanwhile, a deterministic rule applies to every single row.\" loading=\"lazy\" width=\"1607\" height=\"662\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-06.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-06.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-06.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-06.png 1607w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A probabilistic rule applies to a majority of rows, but leaves room for exceptions. Meanwhile, a deterministic rule applies to every single row.</figcaption></figure><p><strong>By default, our ML model assumed that all rules were probabilistic.</strong> When this happens, synthetic data still generally follows the desired properties -- for example, License Expiration &gt; License Issue Year -- for <em>most</em> of the rows, but not for every row.</p><h3 id=\"improving-the-ml-models-using-constraints\">Improving the ML Models using constraints</h3><p>Just because the ML model didn't automatically follow a deterministic rule doesn't mean that it can't. It's possible to improve the model so that it understands this type of rule. As a user working with the SDV, you can input deterministic rules into your model using <strong>constraints</strong>.</p><p>An ML model built using constraints will accommodate both probabilistic and deterministic rules.</p><p><strong>Do you need SDV constraints?</strong></p><p>Deterministic rules are often easy to spot in your dataset: They are the rules that every single row must follow in order to be valid, regardless of how much data there is overall.  But even if you identify the right constraints, there are some cases where you might not actually want to supply them to the SDV.</p><p>Because the SDV learns probabilistic rules, most of the synthesized data is generally valid. Having a few errors sprinkled in might actually be beneficial if you want your synthetic data to cover some edge cases. For example, if you're using the synthetic data to test insurance claim software, leaving in some weird data points might help you ensure that the software can handle unexpected cases -- like the License Expiration accidentally being set too early.</p><p>The figure below shows a few questions you can ask to determine whether adding a constraint is the right approach.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Figure-07.png\" class=\"kg-image\" alt=\"Should you input a rule using constraints? First, determine whether the rule is deterministic, and then take your use case into account.\" loading=\"lazy\" width=\"2000\" height=\"586\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Figure-07.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Figure-07.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Figure-07.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/12/Figure-07.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Should you input a rule using constraints? First, determine whether the rule is deterministic, and then take your use case into account.</figcaption></figure><p><strong>The SDV Constraints offering</strong></p><p>If you decide that adding deterministic rules is important for generating your synthetic data, the SDV has many different constraints to choose from! The table below describes the constraints you would need in order to define the deterministic rules that would best mold your Car Insurance dataset.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-08.png\" class=\"kg-image\" alt=\"The GreaterThan, ColumnFormula and Unique constraints -- all available in the SDV -- set the deterministic rules that ensure your synthetic  Car Insurance Data is useful and makes sense.\" loading=\"lazy\" width=\"2000\" height=\"578\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-08.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-08.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-08.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-08.png 2204w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The GreaterThan, ColumnFormula and Unique constraints -- all available in the SDV -- set the deterministic rules that ensure your synthetic Car Insurance Data is useful and makes sense.</figcaption></figure><p>The SDV offers many more possible constraints, including:</p><ul><li>UniqueCombinations</li><li>Positive and Negative</li><li>Rounding</li><li>Between</li><li>OneHotEncoding</li></ul><p>You can add multiple constraints to the same dataset in order to accommodate all the deterministic rules you need. For more details, read the <a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html\">Constraints User Guide</a>.</p><h3 id=\"takeaways\">Takeaways</h3><p>In this article, we learned that:</p><ul><li>Data is governed by rules. The SDV automatically learns probabilistic rules, which describe overall trends or patterns in the data.</li><li>However, sometimes the data has <strong>deterministic rules</strong>, which are always inherent no matter how much or how little data there is. ML-based systems, including the SDV, may not enforce deterministic rules out of the box.</li><li>Users can input deterministic rules to the SDV using <strong>constraints</strong>. To figure out whether you should input a constraint, ask yourself whether there are any rules that the data must always follow. There are many constraints to choose from.</li></ul><p>In future articles, we'll dive deeper into this topic. We'll explore the technical details behind constraints, and how exactly the SDV's ML models are able to learn deterministic rules.<br></p>","url":"https://sdv.ghost.io/user-input-synthetic-data/","canonical_url":null,"uuid":"e72409d4-6d39-46dc-a973-3e5f9f039dd7","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61a68d091b683e0048b2a2f3","reading_time":5}},{"node":{"id":"Ghost__Post__61927ca167598b003b3d944a","title":"Software Testing: Synthetic data changes the game","slug":"fake-to-synthetic-ml","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2021/11/Article-13.png","excerpt":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","custom_excerpt":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","visibility":"public","created_at_pretty":"15 November, 2021","published_at_pretty":"16 November, 2021","updated_at_pretty":"01 October, 2022","created_at":"2021-11-15T10:28:33.000-05:00","published_at":"2021-11-16T11:33:56.000-05:00","updated_at":"2022-10-01T01:14:30.000-04:00","meta_title":"From fake to synthetic data: Machine learning changes the game","meta_description":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","twitter_image":null,"twitter_title":"From fake to synthetic data: Machine learning changes the game","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Applications","slug":"applications","description":"This blog focuses on the value that synthetic data brings to solving enterprise problems. Synthetic data can be used to test applications, develop unbiased AI models and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Applications","slug":"applications","description":"This blog focuses on the value that synthetic data brings to solving enterprise problems. Synthetic data can be used to test applications, develop unbiased AI models and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Data is a great source of information. Real data — which is based on\nobservations of real-world phenomena like weather, movements on a factory floor\nor the activities of a user base — can help us notice trends, increase business\nefficiency and solve problems. \n\nBut data can be helpful even if it isn’t real. This data, sometimes called fake\nor test data, doesn’t come directly from real-world observations, but is instead\nartificially crafted by a human or machine. The latest and most complex\niteration of this data type — what we call synthetic data — builds on previous\nwork done in this space. \n\nIn this article, we'll go through the history of fake data. By the end, you'll\nbe able to answer the following questions:\n\n * What were the original motivations and tools for manually creating data?\n * What differentiates synthetic data from other types of fake data?\n * What role does machine learning play in generating synthetic data?\n\nThe Dawn of Fake Data: Test Data Management\nOne group of people has worked with fake data for a long time: software\nengineers. They need data in order to test the systems they build, and the real\nstuff isn't always usable (for example, due to privacy). \n\nLet's pretend it's the early 2000s, and you're an IT professional working at a\nbank. You're responsible for the software that updates account balances after\neach transaction. You'd like to test this software before putting it into\nproduction. What do you do?\n\nMost likely, you'll come up with a few test scenarios to ensure that your\nfunctionality — updating the balance — can properly handle a variety of inputs.\n\nThis table shows a few scenarios you may use to test your system. In these\nscenarios, you're testing how a monetary transfer of $20 changes the balance in\ndifferent accounts.Notice that in order to create these scenarios, you had to\ngenerate data: various starting balances ($500, $20, $10) as well as a transfer\namount ($20). This is an early version of using fake data in order to test your\nsoftware!\n\nUsing Tools for Manual Creation\n\nNow let's fast forward in time. Over the years, your software has gotten even\nmore complex, and you're constantly adding new functionalities. For example,\nmaybe you start allowing transfers with foreign currency. \n\nYou need to test these functionalities before you roll them out. To save time,\nyou might end up using -- or creating -- a tool that allows you to generate and\nmanage fake data for testing. \n\nThe simplest tool may be a basic permutation, as illustrated below.\n\nA simple manual test data generation tool that uses permutations. The resulting\nscenarios -- with different starting balances, transfer amounts and transfer\ncurrencies -- are outputted as a data table.A more sophisticated tool might\nallow you greater control over the rules the data must follow. It will also\nallow you to create more columns as your functionalities increase. For example,\nmaybe the bank now offers two different account types: Premium and Normal. \n\nNow you need a test data generation tool that can handle all of these variables\nand come out with something like this:\n\nA more sophisticated test data tool will allow you to specify rules manually. It\nwill follow them to generate test data.Many test data management tools use\nsophisticated logic to precisely create these data columns and their values. But\nthe rules they use are manually written, and rely on human intuition and domain\nknowledge. For example:\n\n * Account type = Premium 10% of the time and Normal 90% of the time\n * Starting balance is between $10,000 and $250,000 if Account type = Premium\n   or between -$1,000 and $10,000 if Account type = Normal\n * Transfer amount follows a bell curve with a mean of $7,500 and standard\n   deviation of $1,000\n * Etc.\n\nThere are downsides to this manual approach. It takes time and effort to come up\nwith these rules, to keep track of them, and to update them as your application\nchanges.\n\nAdding Machine Learning\nAdopting machine learning (ML) opens up entirely new avenues in data generation.\nIn the process, it gets rid of some of these downsides.\n\nAt a high level, ML-based software (such as the Synthetic Data Vault\n[https://sdv.dev/blog/intro-to-sdv/]) works in three steps:\n\n 1. The user inputs real data into the ML software\n 2. The ML software automatically learns patterns in the data\n 3. The software outputs data that contains those patterns\n\nLet's go back to our banking example to see how this works. It's now 2021 and\nyou're using the SDV [https://sdv.dev/] to generate your test data. You input\nall the transactions your bank has handled in the last week. \n\nAfter modeling, the SDV outputs entirely new data that looks and behaves like\nthe original. An illustration of this is shown below.\n\nWith ML tools (like the SDV), you input real data into the software. The\nsoftware then learns patterns from the data and outputs data that matches those\npatterns.Notice that the output data contains many of the same properties as the\noriginal. The model learned all of the following information:\n\n * Ranges & Categories. Transfers range from $5K to $10K. Bank accounts can be\n   either premium or normal. Etc.\n * Shapes. 10% of accounts are premium. Transfers follow a bell curve\n   distribution with a mean of $7,500 and a standard deviation of $1,000. Etc.\n * Correlations. Premium bank accounts tend to have higher balances ($10K to\n   $250K) than normal accounts (-$1K to $10K).\n\nIn other words: while the old test data management tools required you to\nmanually come up with rules, ML-based tools learn these rules automatically. \nMoreover, they can learn new information. For example, the ML picked upon a\ncouple of extra correlations:\n\n * Premium accounts are more likely to transfer foreign currency.\n * Normal accounts are more likely to be overdrawn (transfer more than their\n   current balance).\n\nUsing an ML-based data generation tool will help you ensure that your software\nis robust against these typical cases. And while manual data generation tools\ngenerate fake data, ML-based approaches generate what we call synthetic data.\n\nAsk whether you had to input any real data or rules. Based on this, you'll know\nwhether you are dealing with synthetic data or fake data.Benefits of Synthetic\nData\n\nThere are some clear advantages to using synthetic data over fake data,\nespecially in software testing. Below, we've detailed a few.\n\n * Saves time with automation. Because ML automatically learns patterns from the\n   real data, there is no need to spend a lot of time coming up with and\n   inputting rules. ML learns rules that you may even miss.\n * Is usable by non-experts. Realistic fake data can only be generated by domain\n   experts, who know the precise rules governing the dataset. However, anyone\n   can generate synthetic data. All they have to do is input the real data and\n   the ML software takes care of the rest!\n * Increases adaptability. Applications and data will inevitably change over\n   time. It's easy to update synthetic data as this happens, simply by\n   retraining the ML model with newer data.\n\nBenefits of synthetic data expand beyond software testing. The SDV Community is\nusing synthetic data for an ever-increasing variety of tasks, including machine\nlearning development, de-biasing datasets and scenario planning.\n\nKey Takeaways\nIn this article, we surveyed numerous ways of creating and using data  that is\nnot real. In particular, we learned that:\n\n * Creating fake data is not a novel concept. Older generations of tools will\n   output fake data when given an explicit list of rules. This is especially\n   useful for software testing.\n * Adding ML to this process is a newer evolution. Users input real data into\n   the ML model, and it's able to automatically infer the rules. Data generated\n   using ML-based systems is known as synthetic data.\n * Synthetic data's key advantages include its automation and adaptability. The\n   uses of synthetic data expand beyond software testing.\n\nIn future articles, we'll put ML models to the test! We'll uncover their\nstrengths and weaknesses, and guide you through getting the most from synthetic\ndata using the Synthetic Data Vault.","html":"<p>Data is a great source of information. Real data — which is based on observations of real-world phenomena like weather, movements on a factory floor or the activities of a user base — can help us notice trends, increase business efficiency and solve problems. </p><p>But data can be helpful even if it isn’t real. This data, sometimes called fake or test data, doesn’t come directly from real-world observations, but is instead artificially crafted by a human or machine. The latest and most complex iteration of this data type — what we call synthetic data — builds on previous work done in this space. </p><p>In this article, we'll go through the history of fake data. By the end, you'll be able to answer the following questions:</p><ul><li>What were the original motivations and tools for manually creating data?</li><li>What differentiates synthetic data from other types of fake data?</li><li>What role does machine learning play in generating synthetic data?</li></ul><h3 id=\"the-dawn-of-fake-data-test-data-management\">The Dawn of Fake Data: Test Data Management</h3><p>One group of people has worked with fake data for a long time: software engineers. They need data in order to test the systems they build, and the real stuff isn't always usable (for example, due to privacy). </p><p>Let's pretend it's the early 2000s, and you're an IT professional working at a bank. You're responsible for the software that updates account balances after each transaction. You'd like to test this software before putting it into production. What do you do?</p><p>Most likely, you'll come up with a few test scenarios to ensure that your functionality — updating the balance — can properly handle a variety of inputs.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-09--1-.png\" class=\"kg-image\" alt=\"This table shows a few scenarios you may use to test your system. In these scenarios, you're testing how a monetary transfer of $20 changes the balance in different accounts.\" loading=\"lazy\" width=\"2000\" height=\"541\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-09--1-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-09--1-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-09--1-.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/11/Article-09--1-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>This table shows a few scenarios you may use to test your system. In these scenarios, you're testing how a monetary transfer of $20 changes the balance in different accounts.</figcaption></figure><p>Notice that in order to create these scenarios, you had to generate data: various starting balances ($500, $20, $10) as well as a transfer amount ($20). This is an early version of using fake data in order to test your software!</p><p><strong>Using Tools for Manual Creation</strong></p><p>Now let's fast forward in time. Over the years, your software has gotten even more complex, and you're constantly adding new functionalities. For example, maybe you start allowing transfers with foreign currency. </p><p>You need to test these functionalities before you roll them out. To save time, you might end up using -- or creating -- a tool that allows you to generate and manage fake data for testing. </p><p>The simplest tool may be a basic permutation, as illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-07-2.png\" class=\"kg-image\" alt=\"A simple manual test data generation tool that uses permutations. The resulting scenarios -- with different starting balances, transfer amounts and transfer currencies -- are outputted as a data table.\" loading=\"lazy\" width=\"1723\" height=\"809\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-07-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-07-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-07-2.png 1600w, https://sdv.ghost.io/content/images/2021/11/Article-07-2.png 1723w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A simple manual test data generation tool that uses permutations. The resulting scenarios -- with different starting balances, transfer amounts and transfer currencies -- are outputted as a data table.</figcaption></figure><p>A more sophisticated tool might allow you greater control over the rules the data must follow. It will also allow you to create more columns as your functionalities increase. For example, maybe the bank now offers two different account types: Premium and Normal. </p><p>Now you need a test data generation tool that can handle all of these variables and come out with something like this:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-11.png\" class=\"kg-image\" alt=\"A more sophisticated test data tool will allow you to specify rules manually. It will follow them to generate test data.\" loading=\"lazy\" width=\"1955\" height=\"655\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-11.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-11.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-11.png 1600w, https://sdv.ghost.io/content/images/2021/11/Article-11.png 1955w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A more sophisticated test data tool will allow you to specify rules manually. It will follow them to generate test data.</figcaption></figure><p>Many test data management tools use sophisticated logic to precisely create these data columns and their values. But the rules they use are manually written, and rely on human intuition and domain knowledge. For example:</p><ul><li>Account type = Premium 10% of the time and Normal 90% of the time</li><li>Starting balance is between $10,000 and $250,000 if Account type = Premium<br>or between -$1,000 and $10,000 if Account type = Normal</li><li>Transfer amount follows a bell curve with a mean of $7,500 and standard deviation of $1,000</li><li>Etc.</li></ul><p>There are downsides to this manual approach. It takes time and effort to come up with these rules, to keep track of them, and to update them as your application changes.</p><h3 id=\"adding-machine-learning\">Adding Machine Learning</h3><p>Adopting machine learning (ML) opens up entirely new avenues in data generation. In the process, it gets rid of some of these downsides.</p><p>At a high level, ML-based software (such as the <a href=\"https://sdv.dev/blog/intro-to-sdv/\">Synthetic Data Vault</a>) works in three steps:</p><ol><li>The user inputs real data into the ML software</li><li>The ML software automatically learns patterns in the data</li><li>The software outputs data that contains those patterns</li></ol><p>Let's go back to our banking example to see how this works. It's now 2021 and you're using <a href=\"https://sdv.dev/\">the SDV</a> to generate your test data. You input all the transactions your bank has handled in the last week. </p><p>After modeling, the SDV outputs entirely new data that looks and behaves like the original. An illustration of this is shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-10.png\" class=\"kg-image\" alt=\"With ML tools (like the SDV), you input real data into the software. The software then learns patterns from the data and outputs data that matches those patterns.\" loading=\"lazy\" width=\"2000\" height=\"516\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-10.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-10.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-10.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/11/Article-10.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>With ML tools (like the SDV), you input real data into the software. The software then learns patterns from the data and outputs data that matches those patterns.</figcaption></figure><p>Notice that the output data contains many of the same properties as the original. The model learned all of the following information:</p><ul><li><strong>Ranges &amp; Categories.</strong> Transfers range from $5K to $10K. Bank accounts can be either premium or normal. Etc.</li><li><strong>Shapes.</strong> 10% of accounts are premium. Transfers follow a bell curve distribution with a mean of $7,500 and a standard deviation of $1,000. Etc.</li><li><strong>Correlations.</strong> Premium bank accounts tend to have higher balances ($10K to $250K) than normal accounts (-$1K to $10K).</li></ul><p>In other words: <strong>while the old test data management tools required you to manually come up with rules, ML-based tools learn these rules automatically.</strong> <strong> </strong>Moreover, they can learn new information. For example, the ML picked upon a couple of extra correlations:</p><ul><li>Premium accounts are more likely to transfer foreign currency.</li><li>Normal accounts are more likely to be overdrawn (transfer more than their current balance).</li></ul><p>Using an ML-based data generation tool will help you ensure that your software is robust against these typical cases. And while manual data generation tools generate fake data, <strong>ML-based approaches generate what we call synthetic data.</strong></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-08-1.png\" class=\"kg-image\" alt=\"Ask whether you had to input any real data or rules. Based on this, you'll know whether you are dealing with synthetic data or fake data.\" loading=\"lazy\" width=\"1574\" height=\"419\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-08-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-08-1.png 1000w, https://sdv.ghost.io/content/images/2021/11/Article-08-1.png 1574w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Ask whether you had to input any real data or rules. Based on this, you'll know whether you are dealing with synthetic data or fake data.</figcaption></figure><p><strong>Benefits of Synthetic Data</strong></p><p>There are some clear advantages to using synthetic data over fake data, especially in software testing. Below, we've detailed a few.</p><ul><li><strong>Saves time with automation.</strong> Because ML automatically learns patterns from the real data, there is no need to spend a lot of time coming up with and inputting rules. ML learns rules that you may even miss.</li><li><strong>Is usable by non-experts. </strong>Realistic fake data can only be generated by domain experts, who know the precise rules governing the dataset. However, anyone can generate synthetic data. All they have to do is input the real data and the ML software takes care of the rest!</li><li><strong>Increases adaptability. </strong>Applications and data will inevitably change over time. It's easy to update synthetic data as this happens, simply by retraining the ML model with newer data.</li></ul><p>Benefits of synthetic data expand beyond software testing. The SDV Community is using synthetic data for an ever-increasing variety of tasks, including machine learning development, de-biasing datasets and scenario planning.</p><h3 id=\"key-takeaways\">Key Takeaways</h3><p>In this article, we surveyed numerous ways of creating and using data  that is not real. In particular, we learned that:</p><ul><li>Creating fake data is not a novel concept. Older generations of tools will output fake data when given an explicit list of rules. This is especially useful for software testing.</li><li>Adding ML to this process is a newer evolution. Users input real data into the ML model, and it's able to automatically infer the rules. Data generated using ML-based systems is known as <strong>synthetic data</strong>.</li><li>Synthetic data's key advantages include its automation and adaptability. The uses of synthetic data expand beyond software testing.</li></ul><p>In future articles, we'll put ML models to the test! We'll uncover their strengths and weaknesses, and guide you through getting the most from synthetic data using the Synthetic Data Vault.</p>","url":"https://sdv.ghost.io/fake-to-synthetic-ml/","canonical_url":null,"uuid":"b2a72ccc-d24f-42ad-90fb-23d0017e2529","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61927ca167598b003b3d944a","reading_time":6}},{"node":{"id":"Ghost__Post__609c384488b3f9003e080016","title":"Your Feedback in Action, Part 2: Data Workflow","slug":"community-feedback-workflow","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/05/Banner-2-1.png","excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","custom_excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","visibility":"public","created_at_pretty":"12 May, 2021","published_at_pretty":"19 May, 2021","updated_at_pretty":"16 June, 2022","created_at":"2021-05-12T16:19:16.000-04:00","published_at":"2021-05-19T12:52:14.000-04:00","updated_at":"2022-06-16T14:08:23.000-04:00","meta_title":"Improving synthetic data workflows","meta_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","twitter_image":null,"twitter_title":null,"authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"The Synthetic Data Vault (SDV) is a software system that allows users all over\nthe world to input a dataset and generate synthetic data. The SDV was born out\nof academic research at MIT — but in 2018, we open-sourced it, so that people\nall over the world could use it.\n\nSince then, we've been listening carefully to our community's feedback, making\nsure that we address any gaps between theoretical academic research and\npractical use. This article is the second in a multi-part series detailing\nrecent improvements to the SDV that make it work in the real world. Here we'll\ndiscuss how we've amped up the data synthesis workflow. (For our previous\ndiscussion about how we've improved core models, see Part 1\n[http://sdv.dev/blog/community-feedback-models].)\n\nWhat are workflows?\nWe open sourced the SDV not just to let users generate synthetic data, but also\nto allow them use that data to solve real-world problems. Our community taught\nus that actually using the SDV involves a multi-step process — and that\nimproving the system means paying attention to this entire workflow, not just\nthe core machine learning.\n\nAccording to our users, this workflow boils down to a few generalizable steps:\n\n 1. Identifying real datasets that need to be synthesized\n 2. Transforming the datasets into a machine-readable format\n 3. Running the machine learning model\n 4. Synthesizing data according to particular specifications\n 5. Reversing the transformations such that the synthesized data looks like the\n    original\n 6. Evaluating the synthesized data that results\n\nThese steps are illustrated in the diagram below.\n\nThe entire synthetic data workflow involves more than just modeling. Data also\nneeds to be transformed, synthesized, reverse transformed, and evaluated.The key\ninsight from our users was that the application of machine learning models is\nonly one step of a much larger puzzle. When the open source community helped us\nunderstand this, we were able to improve on the SDV software by adding in\ntransformations, synthesizing options, and evaluation tools -- all detailed\nbelow.\n\nTransforming Data\nOne major lesson from our open source community was how messy real-world\ndatasets are compared to those used in academia. Academic datasets often come\npre-sanitized and ready for numerical use. In the real world, however, databases\nare growing and changing constantly, and are often significantly different from\nthe optimal yet theoretical structures used by machine learning researchers.\n\nTwo thorny data types frequently encountered in the real world are datetimes and \nnull values.\n\n * Datetimes can follow many different formats, including YYYY-MM-DD or\n   MM-DD-YY. However, machine learning models accept numerical values only.\n   Usually these are Unix timestamps, defined as the number of seconds that have\n   elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will\n   transform into the number 1609488000.\n * Null values also present a problem for mathematical models when they appear\n   in numerical data. While users can tell models to ignore these values, the\n   presence of a null might actually indicate something important, like a user\n   declining to answer a question. To account for this, the SDV creates a new,\n   binary column to address whether the original value is null.\n\nWhen working with real-world datasets, it's necessary to apply transformations\nbetween real data and machine-readable data. This example transforms datetimes\nand null values.To solve this problem, we introduced a new library called Reversible Data\nTransforms [https://github.com/sdv-dev/RDT] (RDT). The RDT library contains\nnecessary logic for transforming different types of real world data to its\nmachine-ready counterpart — as well as the logic for its reversal, so that a\nsynthetic data user won't know the difference. The RDT is a standalone library\nthat can reach beyond the synthetic data space, helping data scientists and\nacademics across fields to clean their data. Since November 2020, the RDT has\nbeen supported on all major platforms including MacOS, Windows, and Linux.\n\nSynthesizing Data Conditionally\nWhen we first imagined the SDV, we assumed users would simply want to use all\nthe synthetic data generated by the model. However, we soon found that some\nusers have more complex needs, and require more control over the data they\nsynthesize — opening up new possibilities for synthetic data in the process.\n\nFor example, one of our users, an engineer, found a whole new use for SDV. The\nengineer was writing a machine learning classifier on a dataset when they\nnoticed it was unbalanced. Applying any algorithms to this dataset would lead to\nbiased models. The engineer realized that, if used strategically, SDV could\nactually debias the data — if it only generated data with rarer attributes, the\nsynthetic data it created could be combined with the real data to form a fully\nbalanced dataset.\n\nSynthesized data can help remove bias by creating balanced datasets. In this\nexample, synthesizing those rows that only correspond to females creates a\nbalance between males and females.In February of 2021, we added conditional sampling\n[https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling] \nto the SDV to enable this use case. Now, users can specify attributes or values\nthat must be present in the synthesized data. In addition to debiasing datasets,\nusers can use this feature to test hypothetical scenarios.\n\nEvaluating Synthesized Data\nWhen the entire system is working smoothly and outputting synthetic data, users\nstill need to know: Is the data good enough to use? This vital question inspired\nus to add evaluation capabilities to the SDV. In doing so, we faced two key\nchallenges: Defining the metrics, and creating a useful process.\n\nMetrics\n\nNo single metric perfectly captures the different dimensions of synthetic data\nusers may want to evaluate. Some want to preserve a high degree of mathematical\nlikeness, others want to emphasize a particular column for machine learning\npredictions, and still others are more focused on threat models that can\ncompromise privacy. \n\nTo address this, we created a separate library, SDMetrics\n[https://github.com/sdv-dev/SDMetrics], to define evaluation metrics. The\nlibrary now includes a suite of metrics that cover differentiation of synthetic\nand real data, statistical likeness, and privacy.\n\nApplication\n\nRather than apply metrics on an ad-hoc basis, some SDV power users were creating\nmini-workflows to rapidly test out different models, datasets and evaluation\ncriteria in succession. Inspired by their innovation, we created SDGym\n[https://github.com/sdv-dev/SDGym], a system that allows users to input models,\ndatasets and success metrics to build a comprehensive evaluation framework.\n\nThe SDV Software Today\nThe SDV software is continuously evolving based on community feedback. In this\narticle, we discussed improvements to the workflow surrounding synthetic data\ngeneration, including data transformations, sampling methods and evaluation\ntools. Earlier, in Part 1 [https://sdv.dev/blog/community-feedback-models] of\nthis series, we discussed the core synthetic data models themselves. In future\nblog articles, we plan to dig deeper into each of these areas, and to uncover\nnew ones with you.\n\nLike the SDV, this blog is a collaborative effort. Use our Slack\n[https://bit.ly/sdv-slack-invite] to let us know which topics you'd like to hear\nmore about. And as always, use GitHub [https://github.com/sdv-dev/SDV] to file\ntechnical issues with the system. Working together, we can make SDV the most\ntrusted, transparent and comprehensive platform for synthetic data generation!\n\nFor other inquiries, please contact info@sdv.dev [ info@sdv.dev].","html":"<p>The Synthetic Data Vault (SDV) is a software system that allows users all over the world to input a dataset and generate synthetic data. The SDV was born out of academic research at MIT — but in 2018, we open-sourced it, so that people all over the world could use it.</p><p>Since then, we've been listening carefully to our community's feedback, making sure that we address any gaps between theoretical academic research and practical use. This article is the second in a multi-part series detailing recent improvements to the SDV that make it work in the real world. Here we'll discuss how we've amped up the data synthesis workflow. (For our previous discussion about how we've improved core models, see <a href=\"http://sdv.dev/blog/community-feedback-models\">Part 1</a>.)</p><h3 id=\"what-are-workflows\">What are workflows?</h3><p>We open sourced the SDV not just to let users generate synthetic data, but also to allow them <em>use</em> that data to solve real-world problems. Our community taught us that actually using the SDV involves a multi-step process — and that improving the system means paying attention to this entire workflow, not just the core machine learning.</p><p>According to our users, this workflow boils down to a few generalizable steps:</p><ol><li>Identifying real datasets that need to be synthesized</li><li>Transforming the datasets into a machine-readable format</li><li>Running the machine learning model</li><li>Synthesizing data according to particular specifications</li><li>Reversing the transformations such that the synthesized data looks like the original</li><li>Evaluating the synthesized data that results</li></ol><p>These steps are illustrated in the diagram below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----1.png\" class=\"kg-image\" alt=\"An illustration of the synthetic data workflow: Transforming data, modeling, synthesizing, reverse transforming, and evaluating.\" loading=\"lazy\" width=\"2000\" height=\"1106\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----1.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/05/Community-Feedback--Part-2----1.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The entire synthetic data workflow involves more than just modeling. Data also needs to be transformed, synthesized, reverse transformed, and evaluated.</figcaption></figure><p>The key insight from our users was that the application of machine learning models is only one step of a much larger puzzle. When the open source community helped us understand this, we were able to improve on the SDV software by adding in transformations, synthesizing options, and evaluation tools -- all detailed below.</p><h3 id=\"transforming-data\">Transforming Data</h3><p>One major lesson from our open source community was how messy real-world datasets are compared to those used in academia. Academic datasets often come pre-sanitized and ready for numerical use. In the real world, however, databases are growing and changing constantly, and are often significantly different from the optimal yet theoretical structures used by machine learning researchers.</p><p>Two thorny data types frequently encountered in the real world are <em>datetimes</em> and <em>null values</em>.</p><ul><li><strong>Datetimes</strong> can follow many different formats, including YYYY-MM-DD or MM-DD-YY. However, machine learning models accept numerical values only. Usually these are Unix timestamps, defined as the number of seconds that have elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will transform into the number 1609488000.</li><li><strong>Null values</strong> also present a problem for mathematical models when they appear in numerical data. While users can tell models to ignore these values, the presence of a null might actually indicate something important, like a user declining to answer a question. To account for this, the SDV creates a new, binary column to address whether the original value is null.</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png\" class=\"kg-image\" alt=\"Two tables showing data in its original and transformed formats. The original format includes a human-readable date column and a weight column that can be null.\" loading=\"lazy\" width=\"2000\" height=\"754\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----2-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----2-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----2-1.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png 2280w\" sizes=\"(min-width: 720px) 720px\"><figcaption>When working with real-world datasets, it's necessary to apply transformations between real data and machine-readable data. This example transforms datetimes and null values.</figcaption></figure><p>To solve this problem, we introduced a new library called <a href=\"https://github.com/sdv-dev/RDT\">Reversible Data Transforms</a> (RDT). The RDT library contains necessary logic for transforming different types of real world data to its machine-ready counterpart — as well as the logic for its reversal, so that a synthetic data user won't know the difference. The RDT is a standalone library that can reach beyond the synthetic data space, helping data scientists and academics across fields to clean their data. Since November 2020, the RDT has been supported on all major platforms including MacOS, Windows, and Linux.</p><h3 id=\"synthesizing-data-conditionally\">Synthesizing Data Conditionally</h3><p>When we first imagined the SDV, we assumed users would simply want to use all the synthetic data generated by the model. However, we soon found that some users have more complex needs, and require more control over the data they synthesize — opening up new possibilities for synthetic data in the process.</p><p>For example, one of our users, an engineer, found a whole new use for SDV. The engineer was writing a machine learning classifier on a dataset when they noticed it was unbalanced. Applying any algorithms to this dataset would lead to biased models. The engineer realized that, if used strategically, SDV could actually debias the data — if it only generated data with rarer attributes, the synthetic data it created could be combined with the real data to form a fully balanced dataset.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png\" class=\"kg-image\" alt=\"Biased data that contains more males, plus synthesized data with only females, combines to form a balanced dataset with both males and females.\" loading=\"lazy\" width=\"1705\" height=\"960\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----3.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----3.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----3.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png 1705w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Synthesized data can help remove bias by creating balanced datasets. In this example, synthesizing those rows that only correspond to females creates a balance between males and females.</figcaption></figure><p>In February of 2021, we added <a href=\"https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling\">conditional sampling</a> to the SDV to enable this use case. Now, users can specify attributes or values that must be present in the synthesized data. In addition to debiasing datasets, users can use this feature to test hypothetical scenarios.</p><h3 id=\"evaluating-synthesized-data\">Evaluating Synthesized Data</h3><p>When the entire system is working smoothly and outputting synthetic data, users still need to know: Is the data good enough to use? This vital question inspired us to add evaluation capabilities to the SDV. In doing so, we faced two key challenges: Defining the metrics, and creating a useful process<strong>.</strong></p><p><strong>Metrics</strong></p><p>No single metric perfectly captures the different dimensions of synthetic data users may want to evaluate. Some want to preserve a high degree of mathematical likeness, others want to emphasize a particular column for machine learning predictions, and still others are more focused on threat models that can compromise privacy. </p><p>To address this, we created a separate library, <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>, to define evaluation metrics. The library now includes a suite of metrics that cover differentiation of synthetic and real data, statistical likeness, and privacy.</p><p><strong>Application</strong></p><p>Rather than apply metrics on an ad-hoc basis, some SDV power users were creating mini-workflows to rapidly test out different models, datasets and evaluation criteria in succession. Inspired by their innovation, we created <a href=\"https://github.com/sdv-dev/SDGym\">SDGym</a>, a system that allows users to input models, datasets and success metrics to build a comprehensive evaluation framework.</p><h3 id=\"the-sdv-software-today\">The SDV Software Today</h3><p>The SDV software is continuously evolving based on community feedback. In this article, we discussed improvements to the workflow surrounding synthetic data generation, including data transformations, sampling methods and evaluation tools. Earlier, in <a href=\"https://sdv.dev/blog/community-feedback-models\">Part 1</a> of this series, we discussed the core synthetic data models themselves. In future blog articles, we plan to dig deeper into each of these areas, and to uncover new ones with you.</p><p>Like the SDV, this blog is a collaborative effort. Use our <a href=\"https://bit.ly/sdv-slack-invite\">Slack</a> to let us know which topics you'd like to hear more about. And as always, use <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a> to file technical issues with the system. Working together, we can make SDV the most trusted, transparent and comprehensive platform for synthetic data generation!</p><p><em>For other inquiries, please contact <a href=\"mailto: info@sdv.dev\">info@sdv.dev</a>.</em><br></p>","url":"https://sdv.ghost.io/community-feedback-workflow/","canonical_url":"https://sdv.dev/blog/community-feedback-workflow","uuid":"b55a798b-c1d5-4851-995d-d4b5931184b8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"609c384488b3f9003e080016","reading_time":5}}]},"featured":{"edges":[{"node":{"featured":true,"id":"Ghost__Post__63cee0ef89aa88003d872ba8","excerpt":"How we define a user in 2023 to build a community around synthetic data. ","updated_at":"January 31, 2023","title":"The Most Important Open Source Demographic That No One Thinks About","slug":"open-source-user-demographic","published_at":"January 23, 2023","published_at_pretty":"23 January, 2023","authors":[{"bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","cover_image":null,"name":"Kalyan Veeramachaneni","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","url":"https://sdv.ghost.io/author/kalyan/"}],"primary_author":{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"},"meta_description":"How we define a user in 2023 to build a community around synthetic data. ","meta_title":"The most important open source demographic that no one thinks about. ","feature_image":"https://sdv.ghost.io/content/images/2023/01/Frame.png"}}]},"allGhostTag":{"edges":[{"node":{"slug":"applications","name":"Applications","visibility":"public","feature_image":null,"description":"This blog focuses on the value that synthetic data brings to solving enterprise problems. Synthetic data can be used to test applications, develop unbiased AI models and more. Explore new use cases, concepts and case studies.","meta_title":null,"meta_description":null}},{"node":{"slug":"engineering","name":"Engineering","visibility":"public","feature_image":null,"description":"Our software is serving a global user base. In our engineering blog, we highlight software challenges and design decisions we've made in support of our community.","meta_title":null,"meta_description":null}},{"node":{"slug":"open-source","name":"Open Source","visibility":"public","feature_image":null,"description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","meta_title":null,"meta_description":null}},{"node":{"slug":"product","name":"Product","visibility":"public","feature_image":null,"description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","meta_title":null,"meta_description":null}}]}},"pageContext":{"pageNumber":0,"humanPageNumber":1,"skip":0,"limit":12,"numberOfPages":2,"previousPagePath":"","nextPagePath":"/page/2"}},"staticQueryHashes":["2061773391","2097509368","2358152166","2362887240","2439066133","2561578252","2657115718","2665859238","2731221146","2839364760","4145280475"]}