{"componentChunkName":"component---src-templates-tag-js","path":"/tag/open-source/","result":{"data":{"ghostTag":{"slug":"open-source","name":"Open Source","visibility":"public","feature_image":null,"description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","meta_title":null,"meta_description":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__63d180e2304f20003d70b744","title":"3 user-centric growth strategies for open source","slug":"os-user-strategies","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2023/01/Header.png","excerpt":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used along the way.","custom_excerpt":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used along the way.","visibility":"public","created_at_pretty":"25 January, 2023","published_at_pretty":"26 January, 2023","updated_at_pretty":"26 January, 2023","created_at":"2023-01-25T14:20:02.000-05:00","published_at":"2023-01-25T19:39:12.000-05:00","updated_at":"2023-01-26T15:31:32.000-05:00","meta_title":"3 user-centric growth strategies for open source","meta_description":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used along the way.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Our open source grew faster when we adopted a user-centric mindset. Here are 3 strategies we used.","twitter_image":null,"twitter_title":"3 user-centric growth strategies for open source","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In a previous article, we discussed why, when developing our open source libraries, we emphasize growing our overall users – not just our contributors. We elaborated on why we focus on everyone who uses our software to solve a problem, as opposed to following the more traditional open source practice of catering specifically to code contributors.\n\nBut we cannot stop at defining our focus – we have to put it into practice. In this article, we'll share some practical strategies we have learned in the course of adopting this more user-centric mindset.\n\nWe have come to these strategies by regularly interacting with the users who have adopted the SDV ecosystem, and we've iterated them until we found success. (Some of our libraries are already at 1 million downloads!) This has given us confidence in our approach, which we're excited to share below.\n\n\n1. Find the right channels to reach more users\n\nOur first strategy involves our overall presence as an open source ecosystem.\n\nShifting our focus to users has allowed us to think more critically about who we are trying to help, and whether we are actually reaching them. For example, we were initially prioritizing checking and responding to questions on GitHub, a platform that makes it easy to reference technical material and scrutinize bugs.\n\nBut GitHub caters primarily to contributors – and thus leaves out the rest of the users we'd like to reach. In fact, those users may not have GitHub accounts at all! They are more likely to feel at home when they can ask us questions directly, working with us to improve their understanding. They often don't have the time to dig through technical discussions, or the desire to create an issue on GitHub, especially if their question is more fundamental. (Since “issue creation” has always been defined as a part of the software development lifecycle, users may not feel comfortable asking more basic questions there.)\n\nTo find the users we wanted, we decided to expand our presence to other platforms that cater to their needs. We have found Slack to be a great solution – it is welcoming and easy to use, and enables direct communication. Today, our Slack is a fast-growing community of over 800 members, and a new space for us to learn about how people use our software.\n\n\n2. Users are just as important as contributors\n\nOur attitude towards users matters just as much as their ability to find us.\n\nAs the core maintainers for an open source project, we all have a deep passion for software. It is natural for us to want our users to share this passion – and also natural to perceive a lack of initiative if a user hasn't understood certain concepts. But in our drive to recognize the importance of all users, we have learned to understand — and even embrace — that many users have different needs and time pressures than we are used to.\n\nFor example, we frequently receive questions about how to upload a CSV file into Python. This is a standard data science procedure, so some might label this question as \"lazy.\" We don't believe that's true. In fact, these users may be picking up Python for the first time because they think our software could solve their problem, which shows a lot of initiative. They are not unqualified to use our library; they might just need a helping hand.\n\nTo figure out what will actually help users, we put ourselves in their shoes. This mindset has led to some of our current best practices:\n\n * Empathize with the user's pain points. Working on software openly means that we'll get more feedback more often. Often, an issue identified by a user may already be on our roadmap, is inspiring internal debates, or is on hold until we have more resources. When we're reminded of such an issue, it can be easy to get defensive and engage in a debate – which ultimately wastes everyone's time. Instead, we use the opportunity to build camaraderie. We always try to replicate users' issues, which helps us acknowledge the frustration because we feel it too. No software is perfect!\n * Focus on the problem, not the solution. Because our users do not have our domain expertise, they'll sometimes request features that seem difficult to accommodate. When this happens, we remind ourselves that it's not the user's job to understand our system. Rather, it's our duty to dig deeper and find the root of the concern. This helps us design new features in a way that matches our vision and satisfies users.\n * Above all else, move them forward. When a user has a request, we aim to provide a timely, focused response so that they can take the next step in their usage journey. If we can't immediately resolve the issue, we provide workarounds that allow their projects to proceed. This is more difficult than it seems. At times, we want to passionately respond with our own long-term vision — but this is not useful to users who just want their project to work.\n\nThe illustration below shows a hypothetical example of using these best practices.\n\nThese best practices reflect our overall attitude, which elevates users to the same level of importance as open source contributors.\n\n\n3. Go the extra mile – it only takes a few minutes!\n\nGoing above and beyond can mean creating special material for users and learning to speak their language. By now, it has become standard practice for us to disambiguate and translate our technical communications for a more general audience.\n\nOur SDV ecosystem is filled with examples of conveying the same information in multiple ways. Below are some excerpts from our announcement of a new version of SDV (0.16.0) in July 2022.\n\n\nThe SDV open source contributors are familiar with technical concepts like “unify sampling params for reject sampling” or “Add create_custom_constraint factory method”. They're also interested in following along with specific GitHub issues, which link to the code changes.\n\nMeanwhile, user-centric communication focuses on the pain points that we've solved. This is informative for current users and welcoming for new ones. As a result, users coming to our library for the first time can scan through the Slack channel to see what we're working on. Best of all, because we're thinking in these different ways already, it only takes a few minutes to draft these different types of announcements!\n\n\nConclusion\n\nAdopting a user-centric mindset has significantly contributed to our open source growth. We started by identifying users and finding the right channels to reach them, which naturally expanded our open source presence. Then we learned to empathize with users and embrace their needs, which has manifested as more productive conversations and relationships. Finally, we always think it's great to go above and beyond – especially if it only takes a few minutes!\n\nAre there any strategies we've missed? Let us know what you think in the comments below!","html":"<p>In a <a href=\"https://datacebo.com/blog/open-source-user-demographic\">previous article</a>, we discussed why, when developing our open source libraries, we emphasize growing our overall users – not just our contributors. We elaborated on why we focus on everyone who <em>uses</em> our software to solve a problem, as opposed to following the more traditional open source practice of catering specifically to code contributors.</p><p>But we cannot stop at defining our focus – we have to put it into practice. In this article, we'll share some practical strategies we have learned in the course of adopting this more user-centric mindset. </p><p>We have come to these strategies by regularly interacting with the users who have adopted the <a href=\"https://sdv.dev/\">SDV ecosystem</a>, and we've iterated them until we found success. (Some of our libraries are already at <a href=\"https://pepy.tech/project/copulas\">1 million downloads</a>!) This has given us confidence in our approach, which we're excited to share below.</p><h3 id=\"1-find-the-right-channels-to-reach-more-users\">1. Find the right channels to reach more users</h3><p>Our first strategy involves our overall presence as an open source ecosystem.</p><p>Shifting our focus to users has allowed us to think more critically about who we are trying to help, and whether we are actually reaching them. For example, we were initially prioritizing checking and responding to questions on <a href=\"https://github.com/sdv-dev/SDV/issues\">GitHub</a>, a platform that makes it easy to reference technical material and scrutinize bugs. </p><p>But GitHub caters primarily to contributors – and thus leaves out the rest of the users we'd like to reach. In fact, those users may not have GitHub accounts at all! They are more likely to feel at home when they can ask us questions directly, working with us to improve their understanding. They often don't have the time to dig through technical discussions, or the desire to create an issue on GitHub, especially if their question is more fundamental. (Since “issue creation” has always been defined as a part of the software development lifecycle, users may not feel comfortable asking more basic questions there.)</p><p>To find the users we wanted, we decided to <strong>expand our presence to other platforms that cater to their needs</strong>. We have found Slack to be a great solution – it is welcoming and easy to use, and enables direct communication. Today, <a href=\"https://bit.ly/sdv-slack-invite\">our Slack</a> is a fast-growing community of over 800 members, and a new space for us to learn about how people use our software.</p><h3 id=\"2-users-are-just-as-important-as-contributors\">2. Users are just as important as contributors</h3><p>Our attitude towards users matters just as much as their ability to find us.</p><p>As the core maintainers for an open source project, we all have a deep passion for software. It is natural for us to want our users to share this passion – and also natural to perceive a lack of initiative if a user hasn't understood certain concepts. But in our drive to recognize the importance of all users, we have learned to understand — and even embrace — that many users have different needs and time pressures than we are used to.</p><p>For example, we frequently receive questions about how to upload a CSV file into Python. This is a standard data science procedure, so some might label this question as \"lazy.\" We don't believe that's true. In fact, these users may be picking up Python for the first time because they think our software could solve their problem, which shows a lot of initiative. They are not unqualified to use our library; they might just need a helping hand.</p><p>To figure out what will actually help users, we put ourselves in their shoes. This mindset has led to some of our current best practices:</p><ul><li><strong>Empathize with the user's pain points.</strong> Working on software openly means that we'll get more feedback more often. Often, an issue identified by a user may already be on our roadmap, is inspiring internal debates, or is on hold until we have more resources. When we're reminded of such an issue, it can be easy to get defensive and engage in a debate – which ultimately wastes everyone's time. Instead, we use the opportunity to build camaraderie. We always try to replicate users' issues, which helps us acknowledge the frustration because we feel it too. No software is perfect!</li><li><strong>Focus on the problem, not the solution.</strong> Because our users do not have our domain expertise, they'll sometimes request features that seem difficult to accommodate. When this happens, we remind ourselves that it's not the user's job to understand our system. Rather, it's our duty to dig deeper and find the root of the concern. This helps us design new features in a way that matches our vision <em>and</em> satisfies users.</li><li><strong>Above all else, move them forward. </strong>When a user has a request, we aim to provide a timely, focused response so that they can take the next step in their usage journey. If we can't immediately resolve the issue, we provide workarounds that allow their projects to proceed. This is more difficult than it seems. At times, we want to passionately respond with our own long-term vision — but this is not useful to users who just want their project to work.</li></ul><p>The illustration below shows a hypothetical example of using these best practices.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Conversation-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1500\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Conversation-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Conversation-2.png 1000w, https://sdv.ghost.io/content/images/2023/01/Conversation-2.png 1500w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>An example of a conversation the SDV team might have with a user. In this instance, the user is requesting a new algorithm, which may not be compatible with our current software. But the root concern is data quality – a need that we can address more quickly through other workarounds.</em></figcaption></figure><p>These best practices reflect our overall attitude, which elevates users to the same level of importance as open source contributors.</p><h3 id=\"3-go-the-extra-mile-%E2%80%93-it-only-takes-a-few-minutes\">3. Go the extra mile – it only takes a few minutes!</h3><p>Going above and beyond can mean creating special material for users and learning to speak their language. By now, it has become standard practice for us to disambiguate and translate our technical communications for a more general audience. </p><p>Our SDV ecosystem is filled with examples of conveying the same information in multiple ways. Below are some excerpts from our announcement of a new version of SDV (0.16.0) in July 2022.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Communication-Styles-Comparison-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Communication-Styles-Comparison-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Communication-Styles-Comparison-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Communication-Styles-Comparison-1.png 1600w, https://sdv.ghost.io/content/images/2023/01/Communication-Styles-Comparison-1.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>Selected excerpts from announcements of a new SDV version, disseminated on two different platforms. We communicate the same information in different ways based on what we know about our users.</em></figcaption></figure><p><br>The SDV open source contributors are familiar with technical concepts like “unify sampling params for reject sampling” or “Add create_custom_constraint factory method”. They're also interested in following along with specific GitHub issues, which link to the code changes.</p><p>Meanwhile, user-centric communication focuses on the pain points that we've solved. This is informative for current users and welcoming for new ones. As a result, users coming to our library for the first time can scan through the Slack channel to see what we're working on. Best of all, because we're thinking in these different ways already, it only takes a few minutes to draft these different types of announcements!</p><h3 id=\"conclusion\">Conclusion</h3><p>Adopting a user-centric mindset has significantly contributed to our open source growth. We started by identifying users and finding the right channels to reach them, which naturally expanded our open source presence. Then we learned to empathize with users and embrace their needs, which has manifested as more productive conversations and relationships. Finally, we always think it's great to go above and beyond – especially if it only takes a few minutes!</p><p><em>Are there any strategies we've missed? Let us know what you think in the comments below!</em></p>","url":"https://sdv.ghost.io/os-user-strategies/","canonical_url":"https://datacebo.com/blog/os-user-strategies","uuid":"39669dee-8188-4936-82a2-741037eb0516","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63d180e2304f20003d70b744","reading_time":5}},{"node":{"id":"Ghost__Post__63cee0ef89aa88003d872ba8","title":"The Most Important Open Source Demographic That No One Thinks About","slug":"open-source-user-demographic","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2023/01/Frame.png","excerpt":"How we define a user in 2023 to build a community around synthetic data. ","custom_excerpt":"How we define a user in 2023 to build a community around synthetic data. ","visibility":"public","created_at_pretty":"23 January, 2023","published_at_pretty":"23 January, 2023","updated_at_pretty":"31 January, 2023","created_at":"2023-01-23T14:33:03.000-05:00","published_at":"2023-01-23T16:23:26.000-05:00","updated_at":"2023-01-31T08:36:15.000-05:00","meta_title":"The most important open source demographic that no one thinks about. ","meta_description":"How we define a user in 2023 to build a community around synthetic data. ","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Defining an open source user is a crucial step in discovering enterprise use cases for synthetic data. ","twitter_image":null,"twitter_title":"Defining an open source user for 2023 and beyond","authors":[{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"}],"primary_author":{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Defining an Open Source User for 2023 and beyond\n\nCode contributors are an essential part of an open source (OS) project. But in our experience, making code contributors the sole focus of an open source project ends up disenfranchising another large segment of important people: a library's users. This segment, we have found, is more critical to our success, providing indispensable feedback, finding use cases and helping us to improve our open source and the product that relies on it. In this first article (in a series), we synthesize key attributes that we use to identify a user.\n\nTraditionally, open source libraries have been centered around software development, as collaborating on code is vital for maintaining complex software. It has become customary to use the number of unique code contributors as a core metric of a given library's success. Metrics of success drive how the overall ecosystem is maintained, including how software is designed (APIs), the audience for which usage guides are developed, the types of demos that are built, and how communications are handled. To bring users into fold, all these need to be revisited keeping them in mind.\n\nAt the same time, open source is proving to be a successful model for startups. As the core maintainers of the Synthetic Data Vault project — the world's largest open source library for modeling and generating tabular synthetic data — we are constantly striving to realize the benefits of this model firsthand. For us, open source has been vital to building a trusted and usable machine learning system. With this and subsequent articles we are synthesizing our current thinking about open source, and some key lessons we have learned on our way to this point.\n\n\nWho is a user?\n\nOur definition of a user is: Anyone who attempts to use our open source library to solve their problem. Generally, users:\n\n * …are goal-oriented. A user comes to our library with a specific project that they're working on.\n * …have limited time. A user often has a deadline for their project. They may not have time to learn the nitty-gritty details of our software, or engage in deeper conversations about its development.\n * … have different expertise. A user is probably coming to our library to help with a project in their own domain, whether that's healthcare, clean energy or something else. They might not have the same knowledge base as a professional software developer would (although they also might — more on this later).\n\nWhile this definition may seem straightforward, these attributes have become the cornerstone of how we maintain and communicate about our software, and  how we develop APIs. They have also inspired the main question we use to measure our progress: Is our library making a material difference in users' projects? In subsequent articles, we plan to share how we applied these strategies to build the largest open source user community around synthetic data, and what we have learned in the process.\n\n\nWhat changes are we making to set up an OS for success?\n\nCharting this path with a laser-sharp focus on the “user” has required us to address some commonly asked questions up front, both for our team and externally. Here are just a few.\n\nUsers are developers too and probably more critical for our success\n\nJust because a user isn't interested in learning the internal details of our software doesn't mean we can automatically categorize them as not a developer. They may be experts in other fields and may be developing software there. In addition, they are still using our Python API to help them with their project — and therefore, they are developing software. To expand and serve our user base, we focus our efforts on what we want to achieve with our open source strategy, rather than creating different strategies based on the perceived skill level of who is using our library. As a result, we want every API we publish to be understandable and usable by everyone. We want our communications to be cognizant of the fact - they don't have time! In 2023, we believe that everyone is a developer — or at least, we like to serve everyone and make them part of the software movement.\n\nUser friendly APIs are game changers\n\nOne question we asked ourselves was \"shouldn't the user friendliness delegated to graphical user interfaces (GUIs)?\". GUIs finalize a straight, stepwise process to successful project completion, while the code provides flexibility to try things slightly differently. When they feel restricted by the straight stepwise process for their specific project/use case, pioneering users instead use code. Creating a user-friendly API that lets users apply our open source to their project in a transparent way, and provides access to different metrics and progress states at different stages, gives our users a great chance at succeeding. It also helps us to efficiently discover more pathways, and most importantly, more use cases. This makes our open source essentially a low-code version of what goes into the product.\n\nGithub stars are not enough\n\nGithub star histories are regularly used to indicate an exponential growth curve for a library. They are often considered a leading indicator for a need in the market that the library may be targeting, or top of the funnel for an open source, and there are now well-developed strategies for growing stars over time. Used effectively, we find these strategies to be a good marketing tool, and well-intentioned for increasing the top of the funnel. We ourselves use them from time to time, as they increase reach and can bring in more users. But we find that they should be balanced with feature development, carefully listening to users, and measuring how often folks are downloading and using the library and raising issues. Star growth should be followed by growth in downloads and issues raised by users.\n\n\n\nWe look forward to discussing our experiences with open sourcing in 2023 and beyond. In the articles that follow, we will share some more of our strategies and measures for engagement. We welcome any thoughts, comments, suggestions and questions below.\n","html":"<p><strong><strong>Defining an Open Source User for 2023 and beyond</strong></strong></p><p>Code contributors are an essential part of an open source (OS) project. But in our experience, making code contributors the sole focus of an open source project ends up disenfranchising another large segment of important people: a library's<strong> </strong><em><strong>users</strong></em>. This segment, we have found, is more critical to our success, providing indispensable feedback, finding use cases and helping us to improve our open source and the product that relies on it. In this first article (in a series), we synthesize key attributes that we use to identify a user. </p><p>Traditionally, open source libraries have been centered around software development, as collaborating on code is vital for maintaining complex software. It has become customary to use the number of unique code contributors as a core metric of a given library's success. Metrics of success drive how the overall ecosystem is maintained, including how software is designed (APIs), the audience for which usage guides are developed, the types of demos that are built, and how communications are handled. To bring users into fold, all these need to be revisited keeping them in mind. </p><p>At the same time, open source is <a href=\"https://www.bvp.com/atlas/roadmap-open-source\">proving to be a successful model</a> for startups. As the core maintainers of the <a href=\"https://github.com/sdv-dev/SDV\">Synthetic Data Vault project</a> — the world's largest open source library for modeling and generating tabular synthetic data — we are constantly striving to realize the benefits of this model firsthand. For us, open source has been <a href=\"https://sdv.dev/blog/intro-to-sdv/\">vital to building a trusted and usable machine learning system</a>. With this and subsequent articles we are synthesizing our current thinking about open source, and some key lessons we have learned on our way to this point.</p><h3 id=\"who-is-a-user\">Who is a user?</h3><p>Our definition of a<em> </em>user is: Anyone who attempts to use <em>our</em> open source library to solve <em>their</em> problem. Generally, <em>users</em>:</p><ul><li><strong>…are goal-oriented.</strong> A user comes to our library with a specific project that they're working on.</li><li><strong>…have limited time.</strong> A user often has a deadline for their project. They may not have time to learn the nitty-gritty details of our software, or engage in deeper conversations about its development.</li><li><strong>… have different expertise.</strong> A user is probably coming to our library to help with a project in their own domain, whether that's healthcare, clean energy or something else. They might not have the same knowledge base as a professional software developer would (although they also might — more on this later). </li></ul><p>While this definition may seem straightforward, these attributes have become the cornerstone of how we maintain and communicate about our software, and  how we develop APIs. They have also inspired the main question we use to measure our progress: <em>Is our library making a material difference in users' projects?</em> In subsequent articles, we plan to share how we applied these strategies to build the largest open source <em>user</em> community around synthetic data, and what we have learned in the process.</p><h3 id=\"what-changes-are-we-making-to-set-up-an-os-for-success\">What changes are we making to set up an OS for success?</h3><p>Charting this path with a laser-sharp focus on the “<em>user</em>” has required us to address some commonly asked questions up front, both for our team and externally. Here are just a few.</p><p><strong>Users are developers too and probably more critical for our success </strong></p><p>Just because a user isn't interested in learning the internal details of <em>our</em> software doesn't mean we can automatically categorize them as <em>not a developer</em>. They may be experts in other fields and may be developing software there. In addition, they are still using our Python API to help them with their project — and therefore, they are developing software. To expand and serve our user base, we focus our efforts on what we want to achieve with our open source strategy, rather than creating different strategies based on the perceived skill level of who is using our library. As a result, we want every API we publish to be understandable and usable by everyone. We want our communications to be cognizant of the fact - they don't have time! In 2023, <em>we believe that everyone is a developer</em> — or at least, we like to serve everyone and make them part of the software movement.</p><p><strong>User friendly APIs are game changers</strong></p><p>One question we asked ourselves was \"shouldn't the user friendliness delegated to graphical user interfaces (GUIs)?\". GUIs finalize a <em>straight, stepwise process to successful project completion</em>, while the code provides flexibility to try things slightly differently. When they feel restricted by the straight stepwise process for their specific project/use case, pioneering users instead use code. Creating a user-friendly API that lets users apply our open source to their project in a transparent way, and provides access to different metrics and progress states at different stages, gives our users a great chance at succeeding. It also helps us to efficiently discover more pathways, and most importantly, more use cases. This makes our open source essentially a <em>low-code</em> version of what goes into the product.</p><p><strong>Github stars are not enough</strong></p><p>Github star histories are regularly used to indicate an exponential growth curve for a library. They are often considered a leading indicator for a need in the market that the library may be targeting, or top of the funnel for an open source, and there are now well-developed strategies for growing stars over time. Used effectively, we find these strategies to be a good marketing tool, and well-intentioned for increasing the top of the funnel. We ourselves use them from time to time, as they increase reach and can bring in more users. But we find that they should be balanced with feature development, carefully listening to users, and measuring how often folks are downloading and using the library and raising issues. Star growth should be followed by growth in downloads and issues raised by users.</p><p></p><p><em>We look forward to discussing our experiences with open sourcing in 2023 and beyond. In the articles that follow, we will share some more of our strategies and measures for engagement. We welcome any thoughts, comments, suggestions and questions below.</em><br></p>","url":"https://sdv.ghost.io/open-source-user-demographic/","canonical_url":"https://datacebo.com/blog/open-source-user-demographic","uuid":"206243fc-09c4-4d8e-a367-78560f814b29","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63cee0ef89aa88003d872ba8","reading_time":4}},{"node":{"id":"Ghost__Post__61d3611b6317ec003be8e4b3","title":"The SDV in 2021: A year in review","slug":"2021-year-review","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2022/01/Year-in-review-with-sdv.png","excerpt":"In this article, we summarize SDV growth – downloads as well as community building – that indicates increasing market demand for synthetic data.","custom_excerpt":"In this article, we summarize SDV growth – downloads as well as community building – that indicates increasing market demand for synthetic data.","visibility":"public","created_at_pretty":"03 January, 2022","published_at_pretty":"03 January, 2022","updated_at_pretty":"16 June, 2022","created_at":"2022-01-03T15:48:27.000-05:00","published_at":"2022-01-03T16:07:19.000-05:00","updated_at":"2022-06-16T14:09:32.000-04:00","meta_title":"The SDV in 2021: A year in review","meta_description":"In this article, we summarize SDV growth – downloads as well as community building – that indicates increasing market demand for synthetic data.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"SDV growth – downloads & community building – that indicates increasing market demand for synthetic data.","twitter_image":null,"twitter_title":"The SDV in 2021: A year in review","authors":[{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"}],"primary_author":{"name":"Kalyan Veeramachaneni","slug":"kalyan","bio":"Kalyan is a Principal Research Scientist at MIT, leading a group called Data-to-AI. A 3-time startup founder, Kalyan is interested in big data science and deployable machine learning systems.","profile_image":"https://sdv.ghost.io/content/images/2021/12/Kalyan_Veeramachaneni.jpg","twitter":"@kveeramac","facebook":null,"website":"https://www.linkedin.com/in/kalyan-veeramachaneni-9861b821/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"We started SDV open source in 2018 at MIT with the goal of creating a powerful,\nusable, machine learning-based synthetic data generation software system. The\ncore belief that drove us was the conviction that more than 90% of data work can\nbe done using synthetic data instead of real data. Early experiments at MIT\n[https://news.mit.edu/2017/artificial-data-give-same-results-as-real-data-0303] \nhad been promising and we were ready to invest our time and energy into that\npromise.\n\nNow, 3 years later, we are pleased to see that the market demand for synthetic\ndata is increasing. In a 2021 article, Gartner predicted\n[https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/] \nthat 60% of data used for AI & analytics will be synthetic by 2024. \n\nAs time progressed, we used feedback from our users to make numerous\nimprovements to the SDV (see articles Part 1\n[https://sdv.dev/blog/community-feedback-models/] and Part 2\n[https://sdv.dev/blog/community-feedback-workflow/]). In response, we've seen\nincreased usage, validating the market need for synthetic data generation\nsoftware. In this article, we'll describe the SDV growth trends in detail.\n\nPersistent 4x/year growth in downloads\nEvery year we are experiencing a 4x increase in SDV downloads. In 2021, we had\n135,000 downloads of SDV – up from 30,576 in 2020. From the start of 2020 to the\nend of 2021, we have seen 16x total increase in SDV downloads. The figure below\nshows our yearly usage.\n\nDownloads of SDV per year since we open sourced the library in 2018. By\ndownloading the SDV, a user is signaling their need for synthetic data – which\nwe can interpret as a vote from the market.The downloads are coming from all\nover the world. In the map below, we list the top 10 countries.\n\nDownloads of the SDV in 2021, broken down by the top 10 countries. Notice that\nEurope accounts for 50 half the countries.Why are users downloading the SDV? We\nknow that they want to create synthetic data, but they are using the synthetic\ndata to solve a variety of different needs. We will explore this more and share\nit in a future article.\n\nOver a thousand new community members\nAnother measure of our growth – and validation from the market – comes from the\nSDV community we've built on our GitHub [https://github.com/sdv-dev/SDV] and \nSlack [https://bit.ly/sdv-slack-invite]. In 2021, we welcomed more than 1000 new\nmembers to these spaces.\n\nA summary of how the SDV Community grew in 2021. Any user can join the community\nand actively participate through the SDV GitHub and Slack.As this article\n[https://www.bvp.com/atlas/measuring-the-engagement-of-an-open-source-software-community] \npoints out, members contribute in several different ways: Many help increase\nawareness of an open source solution for this enterprise pain point. Meanwhile,\nothers jump in, use it and give feedback actively. In 2021, we doubled the\nnumber of unique users raising issues on our GitHub. Throughout the  year, over\n200 members actively participated in our forums by raising GitHub issues or\ncontributing to discussions on Slack.\n\nEnterprise feedback is particularly useful to us. This type of feedback comes\nfrom users who are solving targeted business problems with the SDV. Direct and\nsuccinct feedback explains what would make the SDV more useful. An example is\nshown below.\n\nFeedback about a missing feature – composite keys – that would make a direct\nimpact on an enterprise use case. We've removed the user's GitHub account name\nfor privacy. In this case, the missing feature did make it into our pre-alpha.\nOur team addresses the user feedback throughout the entire SDV ecosystem. The\necosystem includes not only modeling, but also the ability to compare models\nthrough SDGym [https://github.com/sdv-dev/SDGym] and measure synthetic data\nquality through SDMetrics [https://github.com/sdv-dev/SDMetrics]. In 2021, the\nteam put out 49 releases throughout the SDV ecosystem, doubling our number of\nreleases in 2020.\n\nLooking forward to 2022!\nWe are looking forward to 2022! With so many users giving us feedback, we have a\nlong list of features that we want to incorporate. We can't wait to share with\nour community what everyone is using SDV for, and keep on climbing to our\noriginal goal: 90% of data work accomplished with synthetic data.","html":"<p>We started SDV open source in 2018 at MIT with the goal of creating a powerful, usable, machine learning-based synthetic data generation software system. The core belief that drove us was the conviction that more than 90% of data work can be done using synthetic data instead of real data. Early<a href=\"https://news.mit.edu/2017/artificial-data-give-same-results-as-real-data-0303\"> experiments at MIT</a> had been promising and we were ready to invest our time and energy into that promise.</p><p>Now, 3 years later, we are pleased to see that the market demand for synthetic data is increasing. In a 2021 article, Gartner <a href=\"https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/\">predicted</a> that 60% of data used for AI &amp; analytics will be synthetic by 2024. </p><p>As time progressed, we used feedback from our users to make numerous improvements to the SDV (see articles <a href=\"https://sdv.dev/blog/community-feedback-models/\">Part 1</a> and <a href=\"https://sdv.dev/blog/community-feedback-workflow/\">Part 2</a>). In response, we've seen increased usage, validating the market need for synthetic data generation software. In this article, we'll describe the SDV growth trends in detail.</p><h3 id=\"persistent-4xyear-growth-in-downloads\">Persistent 4x/year growth in downloads</h3><p>Every year we are experiencing a 4x increase in SDV downloads. In 2021, we had 135,000 downloads of SDV – up from 30,576 in 2020. From the start of 2020 to the end of 2021, we have seen 16x total increase in SDV downloads. The figure below shows our yearly usage.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/downloads-graphic-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"889\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/downloads-graphic-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/downloads-graphic-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/downloads-graphic-1.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/01/downloads-graphic-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Downloads of SDV per year since we open sourced the library in 2018. By downloading the SDV, a user is signaling their need for synthetic data – which we can interpret as a vote from the market.</figcaption></figure><p>The downloads are coming from all over the world. In the map below, we list the top 10 countries.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/worldmap-graphic.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1156\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/worldmap-graphic.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/worldmap-graphic.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/worldmap-graphic.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/01/worldmap-graphic.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Downloads of the SDV in 2021, broken down by the top 10 countries. Notice that Europe accounts for 50 half the countries.</figcaption></figure><p>Why are users downloading the SDV? We know that they want to create synthetic data, but they are using the synthetic data to solve a variety of different needs. We will explore this more and share it in a future article.</p><h3 id=\"over-a-thousand-new-community-members\">Over a thousand new community members</h3><p>Another measure of our growth – and validation from the market – comes from the SDV community we've built on our <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a> and <a href=\"https://bit.ly/sdv-slack-invite\">Slack</a>. In 2021, we welcomed more than 1000 new members to these spaces.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/community-graphic-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"761\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/community-graphic-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/community-graphic-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/community-graphic-2.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/01/community-graphic-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A summary of how the SDV Community grew in 2021. Any user can join the community and actively participate through the SDV GitHub and Slack.</figcaption></figure><p>As <a href=\"https://www.bvp.com/atlas/measuring-the-engagement-of-an-open-source-software-community\">this article</a> points out, members contribute in several different ways: Many help increase awareness of an open source solution for this enterprise pain point. Meanwhile, others jump in, use it and give feedback actively. In 2021, we doubled the number of unique users raising issues on our GitHub. Throughout the  year, over 200 members actively participated in our forums by raising GitHub issues or contributing to discussions on Slack.</p><p>Enterprise feedback is particularly useful to us. This type of feedback comes from users who are solving targeted business problems with the SDV. Direct and succinct feedback explains what would make the SDV more useful. An example is shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1718\" height=\"282\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 1600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-03-at-12.55.08-PM.png 1718w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Feedback about a missing feature – composite keys – that would make a direct impact on an enterprise use case. We've removed the user's GitHub account name for privacy. In this case, the missing feature did make it into our pre-alpha.</figcaption></figure><p>Our team addresses the user feedback throughout the entire SDV ecosystem. The ecosystem includes not only modeling, but also the ability to compare models through <a href=\"https://github.com/sdv-dev/SDGym\">SDGym</a> and measure synthetic data quality through <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>. In 2021, the team put out 49 releases throughout the SDV ecosystem, doubling our number of releases in 2020.</p><h3 id=\"looking-forward-to-2022\">Looking forward to 2022!</h3><p>We are looking forward to 2022! With so many users giving us feedback, we have a long list of features that we want to incorporate. We can't wait to share with our community what everyone is using SDV for, and keep on climbing to our original goal: 90% of data work accomplished with synthetic data.</p>","url":"https://sdv.ghost.io/2021-year-review/","canonical_url":null,"uuid":"36c73725-0b75-4873-bcc3-85e401822bd8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61d3611b6317ec003be8e4b3","reading_time":3}},{"node":{"id":"Ghost__Post__609c384488b3f9003e080016","title":"Your Feedback in Action, Part 2: Data Workflow","slug":"community-feedback-workflow","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/05/Banner-2-1.png","excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","custom_excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","visibility":"public","created_at_pretty":"12 May, 2021","published_at_pretty":"19 May, 2021","updated_at_pretty":"16 June, 2022","created_at":"2021-05-12T16:19:16.000-04:00","published_at":"2021-05-19T12:52:14.000-04:00","updated_at":"2022-06-16T14:08:23.000-04:00","meta_title":"Improving synthetic data workflows","meta_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","twitter_image":null,"twitter_title":null,"authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"The Synthetic Data Vault (SDV) is a software system that allows users all over\nthe world to input a dataset and generate synthetic data. The SDV was born out\nof academic research at MIT — but in 2018, we open-sourced it, so that people\nall over the world could use it.\n\nSince then, we've been listening carefully to our community's feedback, making\nsure that we address any gaps between theoretical academic research and\npractical use. This article is the second in a multi-part series detailing\nrecent improvements to the SDV that make it work in the real world. Here we'll\ndiscuss how we've amped up the data synthesis workflow. (For our previous\ndiscussion about how we've improved core models, see Part 1\n[http://sdv.dev/blog/community-feedback-models].)\n\nWhat are workflows?\nWe open sourced the SDV not just to let users generate synthetic data, but also\nto allow them use that data to solve real-world problems. Our community taught\nus that actually using the SDV involves a multi-step process — and that\nimproving the system means paying attention to this entire workflow, not just\nthe core machine learning.\n\nAccording to our users, this workflow boils down to a few generalizable steps:\n\n 1. Identifying real datasets that need to be synthesized\n 2. Transforming the datasets into a machine-readable format\n 3. Running the machine learning model\n 4. Synthesizing data according to particular specifications\n 5. Reversing the transformations such that the synthesized data looks like the\n    original\n 6. Evaluating the synthesized data that results\n\nThese steps are illustrated in the diagram below.\n\nThe entire synthetic data workflow involves more than just modeling. Data also\nneeds to be transformed, synthesized, reverse transformed, and evaluated.The key\ninsight from our users was that the application of machine learning models is\nonly one step of a much larger puzzle. When the open source community helped us\nunderstand this, we were able to improve on the SDV software by adding in\ntransformations, synthesizing options, and evaluation tools -- all detailed\nbelow.\n\nTransforming Data\nOne major lesson from our open source community was how messy real-world\ndatasets are compared to those used in academia. Academic datasets often come\npre-sanitized and ready for numerical use. In the real world, however, databases\nare growing and changing constantly, and are often significantly different from\nthe optimal yet theoretical structures used by machine learning researchers.\n\nTwo thorny data types frequently encountered in the real world are datetimes and \nnull values.\n\n * Datetimes can follow many different formats, including YYYY-MM-DD or\n   MM-DD-YY. However, machine learning models accept numerical values only.\n   Usually these are Unix timestamps, defined as the number of seconds that have\n   elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will\n   transform into the number 1609488000.\n * Null values also present a problem for mathematical models when they appear\n   in numerical data. While users can tell models to ignore these values, the\n   presence of a null might actually indicate something important, like a user\n   declining to answer a question. To account for this, the SDV creates a new,\n   binary column to address whether the original value is null.\n\nWhen working with real-world datasets, it's necessary to apply transformations\nbetween real data and machine-readable data. This example transforms datetimes\nand null values.To solve this problem, we introduced a new library called Reversible Data\nTransforms [https://github.com/sdv-dev/RDT] (RDT). The RDT library contains\nnecessary logic for transforming different types of real world data to its\nmachine-ready counterpart — as well as the logic for its reversal, so that a\nsynthetic data user won't know the difference. The RDT is a standalone library\nthat can reach beyond the synthetic data space, helping data scientists and\nacademics across fields to clean their data. Since November 2020, the RDT has\nbeen supported on all major platforms including MacOS, Windows, and Linux.\n\nSynthesizing Data Conditionally\nWhen we first imagined the SDV, we assumed users would simply want to use all\nthe synthetic data generated by the model. However, we soon found that some\nusers have more complex needs, and require more control over the data they\nsynthesize — opening up new possibilities for synthetic data in the process.\n\nFor example, one of our users, an engineer, found a whole new use for SDV. The\nengineer was writing a machine learning classifier on a dataset when they\nnoticed it was unbalanced. Applying any algorithms to this dataset would lead to\nbiased models. The engineer realized that, if used strategically, SDV could\nactually debias the data — if it only generated data with rarer attributes, the\nsynthetic data it created could be combined with the real data to form a fully\nbalanced dataset.\n\nSynthesized data can help remove bias by creating balanced datasets. In this\nexample, synthesizing those rows that only correspond to females creates a\nbalance between males and females.In February of 2021, we added conditional sampling\n[https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling] \nto the SDV to enable this use case. Now, users can specify attributes or values\nthat must be present in the synthesized data. In addition to debiasing datasets,\nusers can use this feature to test hypothetical scenarios.\n\nEvaluating Synthesized Data\nWhen the entire system is working smoothly and outputting synthetic data, users\nstill need to know: Is the data good enough to use? This vital question inspired\nus to add evaluation capabilities to the SDV. In doing so, we faced two key\nchallenges: Defining the metrics, and creating a useful process.\n\nMetrics\n\nNo single metric perfectly captures the different dimensions of synthetic data\nusers may want to evaluate. Some want to preserve a high degree of mathematical\nlikeness, others want to emphasize a particular column for machine learning\npredictions, and still others are more focused on threat models that can\ncompromise privacy. \n\nTo address this, we created a separate library, SDMetrics\n[https://github.com/sdv-dev/SDMetrics], to define evaluation metrics. The\nlibrary now includes a suite of metrics that cover differentiation of synthetic\nand real data, statistical likeness, and privacy.\n\nApplication\n\nRather than apply metrics on an ad-hoc basis, some SDV power users were creating\nmini-workflows to rapidly test out different models, datasets and evaluation\ncriteria in succession. Inspired by their innovation, we created SDGym\n[https://github.com/sdv-dev/SDGym], a system that allows users to input models,\ndatasets and success metrics to build a comprehensive evaluation framework.\n\nThe SDV Software Today\nThe SDV software is continuously evolving based on community feedback. In this\narticle, we discussed improvements to the workflow surrounding synthetic data\ngeneration, including data transformations, sampling methods and evaluation\ntools. Earlier, in Part 1 [https://sdv.dev/blog/community-feedback-models] of\nthis series, we discussed the core synthetic data models themselves. In future\nblog articles, we plan to dig deeper into each of these areas, and to uncover\nnew ones with you.\n\nLike the SDV, this blog is a collaborative effort. Use our Slack\n[https://bit.ly/sdv-slack-invite] to let us know which topics you'd like to hear\nmore about. And as always, use GitHub [https://github.com/sdv-dev/SDV] to file\ntechnical issues with the system. Working together, we can make SDV the most\ntrusted, transparent and comprehensive platform for synthetic data generation!\n\nFor other inquiries, please contact info@sdv.dev [ info@sdv.dev].","html":"<p>The Synthetic Data Vault (SDV) is a software system that allows users all over the world to input a dataset and generate synthetic data. The SDV was born out of academic research at MIT — but in 2018, we open-sourced it, so that people all over the world could use it.</p><p>Since then, we've been listening carefully to our community's feedback, making sure that we address any gaps between theoretical academic research and practical use. This article is the second in a multi-part series detailing recent improvements to the SDV that make it work in the real world. Here we'll discuss how we've amped up the data synthesis workflow. (For our previous discussion about how we've improved core models, see <a href=\"http://sdv.dev/blog/community-feedback-models\">Part 1</a>.)</p><h3 id=\"what-are-workflows\">What are workflows?</h3><p>We open sourced the SDV not just to let users generate synthetic data, but also to allow them <em>use</em> that data to solve real-world problems. Our community taught us that actually using the SDV involves a multi-step process — and that improving the system means paying attention to this entire workflow, not just the core machine learning.</p><p>According to our users, this workflow boils down to a few generalizable steps:</p><ol><li>Identifying real datasets that need to be synthesized</li><li>Transforming the datasets into a machine-readable format</li><li>Running the machine learning model</li><li>Synthesizing data according to particular specifications</li><li>Reversing the transformations such that the synthesized data looks like the original</li><li>Evaluating the synthesized data that results</li></ol><p>These steps are illustrated in the diagram below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----1.png\" class=\"kg-image\" alt=\"An illustration of the synthetic data workflow: Transforming data, modeling, synthesizing, reverse transforming, and evaluating.\" loading=\"lazy\" width=\"2000\" height=\"1106\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----1.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/05/Community-Feedback--Part-2----1.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The entire synthetic data workflow involves more than just modeling. Data also needs to be transformed, synthesized, reverse transformed, and evaluated.</figcaption></figure><p>The key insight from our users was that the application of machine learning models is only one step of a much larger puzzle. When the open source community helped us understand this, we were able to improve on the SDV software by adding in transformations, synthesizing options, and evaluation tools -- all detailed below.</p><h3 id=\"transforming-data\">Transforming Data</h3><p>One major lesson from our open source community was how messy real-world datasets are compared to those used in academia. Academic datasets often come pre-sanitized and ready for numerical use. In the real world, however, databases are growing and changing constantly, and are often significantly different from the optimal yet theoretical structures used by machine learning researchers.</p><p>Two thorny data types frequently encountered in the real world are <em>datetimes</em> and <em>null values</em>.</p><ul><li><strong>Datetimes</strong> can follow many different formats, including YYYY-MM-DD or MM-DD-YY. However, machine learning models accept numerical values only. Usually these are Unix timestamps, defined as the number of seconds that have elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will transform into the number 1609488000.</li><li><strong>Null values</strong> also present a problem for mathematical models when they appear in numerical data. While users can tell models to ignore these values, the presence of a null might actually indicate something important, like a user declining to answer a question. To account for this, the SDV creates a new, binary column to address whether the original value is null.</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png\" class=\"kg-image\" alt=\"Two tables showing data in its original and transformed formats. The original format includes a human-readable date column and a weight column that can be null.\" loading=\"lazy\" width=\"2000\" height=\"754\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----2-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----2-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----2-1.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png 2280w\" sizes=\"(min-width: 720px) 720px\"><figcaption>When working with real-world datasets, it's necessary to apply transformations between real data and machine-readable data. This example transforms datetimes and null values.</figcaption></figure><p>To solve this problem, we introduced a new library called <a href=\"https://github.com/sdv-dev/RDT\">Reversible Data Transforms</a> (RDT). The RDT library contains necessary logic for transforming different types of real world data to its machine-ready counterpart — as well as the logic for its reversal, so that a synthetic data user won't know the difference. The RDT is a standalone library that can reach beyond the synthetic data space, helping data scientists and academics across fields to clean their data. Since November 2020, the RDT has been supported on all major platforms including MacOS, Windows, and Linux.</p><h3 id=\"synthesizing-data-conditionally\">Synthesizing Data Conditionally</h3><p>When we first imagined the SDV, we assumed users would simply want to use all the synthetic data generated by the model. However, we soon found that some users have more complex needs, and require more control over the data they synthesize — opening up new possibilities for synthetic data in the process.</p><p>For example, one of our users, an engineer, found a whole new use for SDV. The engineer was writing a machine learning classifier on a dataset when they noticed it was unbalanced. Applying any algorithms to this dataset would lead to biased models. The engineer realized that, if used strategically, SDV could actually debias the data — if it only generated data with rarer attributes, the synthetic data it created could be combined with the real data to form a fully balanced dataset.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png\" class=\"kg-image\" alt=\"Biased data that contains more males, plus synthesized data with only females, combines to form a balanced dataset with both males and females.\" loading=\"lazy\" width=\"1705\" height=\"960\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----3.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----3.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----3.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png 1705w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Synthesized data can help remove bias by creating balanced datasets. In this example, synthesizing those rows that only correspond to females creates a balance between males and females.</figcaption></figure><p>In February of 2021, we added <a href=\"https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling\">conditional sampling</a> to the SDV to enable this use case. Now, users can specify attributes or values that must be present in the synthesized data. In addition to debiasing datasets, users can use this feature to test hypothetical scenarios.</p><h3 id=\"evaluating-synthesized-data\">Evaluating Synthesized Data</h3><p>When the entire system is working smoothly and outputting synthetic data, users still need to know: Is the data good enough to use? This vital question inspired us to add evaluation capabilities to the SDV. In doing so, we faced two key challenges: Defining the metrics, and creating a useful process<strong>.</strong></p><p><strong>Metrics</strong></p><p>No single metric perfectly captures the different dimensions of synthetic data users may want to evaluate. Some want to preserve a high degree of mathematical likeness, others want to emphasize a particular column for machine learning predictions, and still others are more focused on threat models that can compromise privacy. </p><p>To address this, we created a separate library, <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>, to define evaluation metrics. The library now includes a suite of metrics that cover differentiation of synthetic and real data, statistical likeness, and privacy.</p><p><strong>Application</strong></p><p>Rather than apply metrics on an ad-hoc basis, some SDV power users were creating mini-workflows to rapidly test out different models, datasets and evaluation criteria in succession. Inspired by their innovation, we created <a href=\"https://github.com/sdv-dev/SDGym\">SDGym</a>, a system that allows users to input models, datasets and success metrics to build a comprehensive evaluation framework.</p><h3 id=\"the-sdv-software-today\">The SDV Software Today</h3><p>The SDV software is continuously evolving based on community feedback. In this article, we discussed improvements to the workflow surrounding synthetic data generation, including data transformations, sampling methods and evaluation tools. Earlier, in <a href=\"https://sdv.dev/blog/community-feedback-models\">Part 1</a> of this series, we discussed the core synthetic data models themselves. In future blog articles, we plan to dig deeper into each of these areas, and to uncover new ones with you.</p><p>Like the SDV, this blog is a collaborative effort. Use our <a href=\"https://bit.ly/sdv-slack-invite\">Slack</a> to let us know which topics you'd like to hear more about. And as always, use <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a> to file technical issues with the system. Working together, we can make SDV the most trusted, transparent and comprehensive platform for synthetic data generation!</p><p><em>For other inquiries, please contact <a href=\"mailto: info@sdv.dev\">info@sdv.dev</a>.</em><br></p>","url":"https://sdv.ghost.io/community-feedback-workflow/","canonical_url":"https://sdv.dev/blog/community-feedback-workflow","uuid":"b55a798b-c1d5-4851-995d-d4b5931184b8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"609c384488b3f9003e080016","reading_time":5}},{"node":{"id":"Ghost__Post__609c351b88b3f9003e07ffb8","title":"Your Feedback in Action, Part 1: Data Models","slug":"community-feedback-models","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2021/05/Banner-2.png","excerpt":"After thousands of downloads, see how SDV's machine learning models have evolved based on feedback from users.","custom_excerpt":"After thousands of downloads, see how SDV's machine learning models have evolved based on feedback from users.","visibility":"public","created_at_pretty":"12 May, 2021","published_at_pretty":"12 May, 2021","updated_at_pretty":"16 June, 2022","created_at":"2021-05-12T16:05:47.000-04:00","published_at":"2021-05-12T16:15:30.000-04:00","updated_at":"2022-06-16T14:08:01.000-04:00","meta_title":"Improving machine learning for synthetic data","meta_description":"Based on feedback from real users, SDV's machine learning models have evolved to offer more choices, understand sequential data, and encode business logic.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Based on feedback from real users, SDV's machine learning models have evolved to offer more choices, understand sequential data, and encode business logic.","twitter_image":null,"twitter_title":"Improving machine learning for synthetic data","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In our last post [https://sdv.dev/blog/intro-to-sdv/], we introduced the \nSynthetic Data Vault [https://github.com/sdv-dev/SDV] (SDV) — a software system\nthat allows users to input a dataset and generate synthetic data. The SDV was\nborn out of academic research at MIT — but in 2018, we open-sourced it, so that\npeople all over the world could use it.\n\nSince then, we've been listening carefully to our community's feedback, making\nsure that we address any gaps between theoretical academic research and\npractical use. This multi-part series details recent improvements we've made so\nthat SDV works in the real world. In this article, we focus on the machine\nlearning-based modeling techniques that form the core of the system, while Part\n2 [https://sdv.dev/blog/community-feedback-workflow/] will cover the surrounding\nworkflow.\n\nWhat's in a model?\nAt its core, the SDV is a set of machine learning models designed to understand\nand mimic real world data. Once the SDV creates a particular model, developers\ncan generate synthetic data by sampling it. For synthetic data to be successful,\nthis generative model must be correct — but through discussions with our open\nsource community, we realized that there is no such thing as a single, winning\napproach that works every time. Each dataset and use case is different.\n\n\nOur solution is to provide choices, giving users all the necessary tools to make\nuseful synthetic data for each new case at hand. Let's dive into three popular\nuses of the SDV where such options are available: Tabular models, sequential\ndata and business logic.\n\nMore Options for Tabular Models\nThe earliest version of SDV was based on a classic statistical method: Gaussian\nCopulas [https://en.wikipedia.org/wiki/Copula_(probability_theory)]. This model\nis transparent by definition. It allows us to understand and exert control over\nformulas in the model, notably the distributions of each variable. This can be\nespecially useful for business applications, where data often follows\npredictable distributions. For example, wind speed is known to follow a Weibull\ndistribution [https://en.wikipedia.org/wiki/Wind_power], biological measures\nlike height usually follow normal distributions\n[https://en.wikipedia.org/wiki/Normal_distribution#Occurrence_and_applications] \nand credit default rates often follow exponential distributions\n[https://en.wikipedia.org/wiki/Exponential_distribution].\n\nMeanwhile, advances in the AI space had also produced a robust, alternative\nmodel for those willing to sacrifice transparency: A deep learning technique\ncalled Generative Adversarial Networks\n[https://en.wikipedia.org/wiki/Generative_adversarial_network] (GANs). GANs\nmodel complex processes that don't follow known formulas. While these models’\ninner workings aren’t easily explained by humans, they produce highly accurate\nresults. We created a GAN, called CTGAN, specifically for synthetic data. This\nblack box model is especially good at figuring out complex correlations between\nvariables in large datasets.\n\nFor a long time, SDV allowed users a choice between our Gaussian Copulas based\nmodel, called GaussianCopula, and CTGAN to model tabular data. While this choice\nprovided some flexibility, our users reported they had a hard time choosing\nbetween such extreme alternatives. We wondered if a middle ground was possible:\nCould we specify distributions while also using GANs to identify complex\ncorrelations?\n\nWe couldn't find any model that fit both of these requirements, so we made our\nown! A key insight was that we could use Gaussian Copulas to understand the data\nand transform it before applying it to a GAN. The result is CopulaGAN\n[https://sdv.dev/SDV/user_guides/single_table/copulagan.html], a hybrid model we\nreleased in October 2020.\n\nCopulaGAN is in the middle of the spectrum, between simple, easily understood\nmodels (like GaussianCopula) and complex black box models (like CTGAN).CopulaGAN\ncombines the human accessibility of Gaussian Copulas with the robust accuracy of\nGANs. This innovation provides users with a new choice: a hybrid approach.\n\nThe Special Case of Sequential Data\nAnother tricky case pointed out by our users involved sequential data. While\nsequential data is stored in a table, it is unlike a regular table in that its\nrows are linked together, usually by a time component. This use case is\nextremely frequent, especially in finance — any table with credit card\ntransactions, stock prices, or payments is almost certainly sequential. \n\nAt the time, solutions treated sequential data as a case of general tabular\nmodeling. After all, sequential data is inside a table. However, these solutions\nfailed to incorporate the key information that makes sequential data unique: The\nrelationships that exist between rows.\n\nIn this table of stock prices, rows that describe the same company — in this\ncase, Google — are related to each other through time. Related rows are a\nspecial feature of sequential datasets.While considering this pain point, we\nrecognized sequential data as an entirely new case that required its own unique\nset of modeling techniques. In October 2020, we released our DeepEcho library,\nwhich focuses entirely on sequential data. We also introduced our PAR model:\n[https://sdv.dev/SDV/user_guides/timeseries/par.html] a GAN approach made\nspecifically for sequential data.\n\nEncoding Business Logic using Constraints\nEven with a plethora of modeling choices, it's vital to capture nuances in\nbusiness logic while modeling synthetic data. This is due to differences in how\nhumans and machines understand datasets.\n\nOften, humans can easily glean the meaning of a dataset using context clues.\nConsider a table showing the names and ages of students and their legal\nguardians. A human will intuitively realize that a student must be younger than\ntheir guardian.\n\nIn this table of students and their guardians, the student is always younger\nthan their guardian. This is a constraint that humans intuitively understand.But\nwill a machine understand the same rule? Because all of the SDV's models use\nstatistics, they analyze trends generally — meaning that in this case, they will\ninclude a small possibility that a student could be older than their guardian.\nAfter all, is it totally out of the question that an older individual could\nenroll and list their child as their guardian? Either way, only a human expert\ncan truly figure out what makes sense for this dataset!\n\nTo solve this pain point, SDV introduced the concept of constraints\n[https://sdv.dev/SDV/user_guides/single_table/constraints.html] in July 2020.\nConstraints give users the ability to encode their business knowledge and\nexpertise into an SDV model. In our example, they could specify that a\nguardian's age must be greater than the student's. Currently, the GreaterThan\nand UniqueCombination constraints allow for easy handling of common scenarios.\nWe also provide a blanket CustomConstraint class, which gives users flexibility\nto capture more nuanced knowledge.\n\nMore Community Feedback\nWe believe that the more humans and machines can work together, the more\nefficient our processes can become. In this article, we explained how user\nfeedback about the SDV led to new core modeling techniques and innovations —\nenabling a system that now provides a choice of multiple models, handles\nsequential data, and understands constraints. In Part 2\n[https://sdv.dev/blog/community-feedback-workflow/], we will discuss similar\nfeedback-driven innovations in the rest of the workflow.\n\nUsing SDV — and giving us feedback — fuels this rapid evolution. To start a\ndiscussion, please message us on Slack [https://bit.ly/sdv-slack-invite] or file\nan issue on GitHub [https://github.com/sdv-dev/SDV]. Working together, we can\nmake SDV the most trusted, transparent and comprehensive platform for synthetic\ndata generation!\n\nFor other inquiries, please contact info@sdv.dev.","html":"<p>In our <a href=\"https://sdv.dev/blog/intro-to-sdv/\">last post</a>, we introduced the <a href=\"https://github.com/sdv-dev/SDV\">Synthetic Data Vault</a> (SDV) — a software system that allows users to input a dataset and generate synthetic data. The SDV was born out of academic research at MIT — but in 2018, we open-sourced it, so that people all over the world could use it.</p><p>Since then, we've been listening carefully to our community's feedback, making sure that we address any gaps between theoretical academic research and practical use. This multi-part series details recent improvements we've made so that SDV works in the real world. In this article, we focus on the machine learning-based modeling techniques that form the core of the system, while <a href=\"https://sdv.dev/blog/community-feedback-workflow/\">Part 2</a> will cover the surrounding workflow.</p><h3 id=\"whats-in-a-model\">What's in a model?</h3><p>At its core, the SDV is a set of machine learning models designed to understand and mimic real world data. Once the SDV creates a particular model, developers can generate synthetic data by sampling it. For synthetic data to be successful, this generative model must be correct — but through discussions with our open source community, we realized that there is no such thing as a single, winning approach that works every time. Each dataset and use case is different.<br></p><p>Our solution is to provide choices, giving users all the necessary tools to make useful synthetic data for each new case at hand. Let's dive into three popular uses of the SDV where such options are available: Tabular models, sequential data and business logic.</p><h3 id=\"more-options-for-tabular-models\">More Options for Tabular Models</h3><p>The earliest version of SDV was based on a classic statistical method: <a href=\"https://en.wikipedia.org/wiki/Copula_(probability_theory)\">Gaussian Copulas</a>. This model is transparent by definition. It allows us to understand and exert control over formulas in the model, notably the distributions of each variable. This can be especially useful for business applications, where data often follows predictable distributions. For example, wind speed is known to follow a <a href=\"https://en.wikipedia.org/wiki/Wind_power\">Weibull distribution</a>, biological measures like height usually follow <a href=\"https://en.wikipedia.org/wiki/Normal_distribution#Occurrence_and_applications\">normal distributions</a> and credit default rates often follow <a href=\"https://en.wikipedia.org/wiki/Exponential_distribution\">exponential distributions</a>.</p><p>Meanwhile, advances in the AI space had also produced a robust, alternative model for those willing to sacrifice transparency: A deep learning technique called <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\">Generative Adversarial Networks</a> (GANs). GANs model complex processes that don't follow known formulas. While these models’ inner workings aren’t easily explained by humans, they produce highly accurate results. We created a GAN, called CTGAN, specifically for synthetic data. This black box model is especially good at figuring out complex correlations between variables in large datasets.</p><p>For a long time, SDV allowed users a choice between our Gaussian Copulas based model, called GaussianCopula, and CTGAN to model tabular data. While this choice provided some flexibility, our users reported they had a hard time choosing between such extreme alternatives. We wondered if a middle ground was possible: Could we specify distributions while also using GANs to identify complex correlations?</p><p>We couldn't find any model that fit both of these requirements, so we made our own! A key insight was that we could use Gaussian Copulas to understand the data and transform it before applying it to a GAN. The result is <a href=\"https://sdv.dev/SDV/user_guides/single_table/copulagan.html\">CopulaGAN</a>, a hybrid model we released in October 2020.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----1.png\" class=\"kg-image\" alt=\"A diagram showing a scale of simple human accessible models (GaussianCopula) versus complex black box models (like CTGAN), with CopulaGAN is in the middle.\" loading=\"lazy\" width=\"2000\" height=\"695\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-1----1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-1----1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-1----1.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----1.png 2100w\" sizes=\"(min-width: 720px) 720px\"><figcaption>CopulaGAN is in the middle of the spectrum, between simple, easily understood models (like GaussianCopula) and complex black box models (like CTGAN).</figcaption></figure><p>CopulaGAN combines the human accessibility of Gaussian Copulas with the robust accuracy of GANs. This innovation provides users with a new choice: a hybrid approach.</p><h3 id=\"the-special-case-of-sequential-data\">The Special Case of Sequential Data</h3><p>Another tricky case pointed out by our users involved sequential data. While sequential data is stored in a table, it is unlike a regular table in that its rows are linked together, usually by a time component. This use case is extremely frequent, especially in finance — any table with credit card transactions, stock prices, or payments is almost certainly sequential. </p><p>At the time, solutions treated sequential data as a case of general tabular modeling. After all, sequential data is inside a table. However, these solutions failed to incorporate the key information that makes sequential data unique: The relationships that exist between rows.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----2.png\" class=\"kg-image\" alt=\"A table that shows sequential, time series data of daily stock prices corresponding to different companies.\" loading=\"lazy\" width=\"1840\" height=\"1210\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-1----2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-1----2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-1----2.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----2.png 1840w\" sizes=\"(min-width: 720px) 720px\"><figcaption>In this table of stock prices, rows that describe the same company — in this case, Google — are related to each other through time. Related rows are a special feature of sequential datasets.</figcaption></figure><p>While considering this pain point, we recognized sequential data as an entirely new case that required its own unique set of modeling techniques. In October 2020, we released our DeepEcho library, which focuses entirely on sequential data. We also introduced our <a href=\"https://sdv.dev/SDV/user_guides/timeseries/par.html\">PAR model:</a> a GAN approach made specifically for sequential data.</p><h3 id=\"encoding-business-logic-using-constraints\">Encoding Business Logic using Constraints</h3><p>Even with a plethora of modeling choices, it's vital to capture nuances in business logic while modeling synthetic data. This is due to differences in how humans and machines understand datasets.</p><p>Often, humans can easily glean the meaning of a dataset using context clues. Consider a table showing the names and ages of students and their legal guardians. A human will intuitively realize that a student must be younger than their guardian.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----3.png\" class=\"kg-image\" alt=\"A table of student names, their ages, their guardians, and the guardians' ages.\" loading=\"lazy\" width=\"2000\" height=\"969\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-1----3.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-1----3.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-1----3.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----3.png 2230w\" sizes=\"(min-width: 720px) 720px\"><figcaption>In this table of students and their guardians, the student is always younger than their guardian. This is a constraint that humans intuitively understand.</figcaption></figure><p>But will a machine understand the same rule? Because all of the SDV's models use statistics, they analyze trends generally — meaning that in this case, they will include a small possibility that a student could be older than their guardian. After all, is it totally out of the question that an older individual could enroll and list their child as their guardian? Either way, only a human expert can truly figure out what makes sense for this dataset!</p><p>To solve this pain point, SDV introduced the concept of <a href=\"https://sdv.dev/SDV/user_guides/single_table/constraints.html\">constraints</a> in July 2020. Constraints give users the ability to encode their business knowledge and expertise into an SDV model. In our example, they could specify that a guardian's age must be greater than the student's. Currently, the GreaterThan and UniqueCombination constraints allow for easy handling of common scenarios. We also provide a blanket CustomConstraint class, which gives users flexibility to capture more nuanced knowledge.</p><h3 id=\"more-community-feedback\">More Community Feedback</h3><p>We believe that the more humans and machines can work together, the more efficient our processes can become. In this article, we explained how user feedback about the SDV led to new core modeling techniques and innovations — enabling a system that now provides a choice of multiple models, handles sequential data, and understands constraints. In <a href=\"https://sdv.dev/blog/community-feedback-workflow/\">Part 2</a>, we will discuss similar feedback-driven innovations in the rest of the workflow.</p><p>Using SDV — and giving us feedback — fuels this rapid evolution. To start a discussion, please message us on <a href=\"https://bit.ly/sdv-slack-invite\">Slack</a> or file an issue on <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a>. Working together, we can make SDV the most trusted, transparent and comprehensive platform for synthetic data generation!</p><p><em>For other inquiries, please contact <strong>info@sdv.dev</strong>.</em><br></p>","url":"https://sdv.ghost.io/community-feedback-models/","canonical_url":null,"uuid":"b07a410f-1cf1-45f1-a82e-e66cfdaf61b9","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"609c351b88b3f9003e07ffb8","reading_time":5}},{"node":{"id":"Ghost__Post__608c5562f9741d003b6f73b8","title":"Meet the Synthetic Data Vault","slug":"intro-to-sdv","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2021/05/blog-header--1-.png","excerpt":"Welcome to the SDV Blog! The SDV is a comprehensive, open source software for synthetic data generation. Join our growing community as we create an ecosystem to solve real world problems!","custom_excerpt":"Welcome to the SDV Blog! The SDV is a comprehensive, open source software for synthetic data generation. Join our growing community as we create an ecosystem to solve real world problems!","visibility":"public","created_at_pretty":"30 April, 2021","published_at_pretty":"04 May, 2021","updated_at_pretty":"10 January, 2023","created_at":"2021-04-30T15:07:14.000-04:00","published_at":"2021-05-04T09:00:00.000-04:00","updated_at":"2023-01-10T13:00:27.000-05:00","meta_title":"Meet the Synthetic Data Vault","meta_description":"Check out our new blog introducing MIT’s Synthetic Data Vault. Join us for discussions on synthetic data, our libraries and the industry!","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Check out our new blog introducing MIT’s Synthetic Data Vault. Join us for discussions on synthetic data, our libraries and the industry!","twitter_image":null,"twitter_title":"Meet the Synthetic Data Vault","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},{"name":"Carles Sala","slug":"carles","bio":"Carles is a seasoned ML and Software Engineer, and former researcher at MIT, where he led the development efforts to grow the SDV prototype into the successful open source project that it is today.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Carles_Sala.jpg","twitter":"@csalacat","facebook":null,"website":"https://csala.dev/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great user experience at DataCebo.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Open Source","slug":"open-source","description":"The Synthetic Data Vault (SDV) is the largest open source platform for tabular synthetic data creation and evaluation. Join our journey as we share insights from our global user base and evolve our strategy.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Hello world! We, the creators of MIT's Synthetic Data Vault, warmly welcome you\nto our official blog. Soon we'll be using this space to deep-dive into topics\nrelated to our libraries, and to unpack ideas in the synthetic data space. We're\nlooking forward to exploring this exciting area with you.\n\nBut first, we want to properly introduce our project: The Synthetic Data Vault\n[https://github.com/sdv-dev/SDV] (SDV), an open source software ecosystem for\ngenerating synthetic data. In this post, we’ll explain why synthetic data is\nimportant, and tell the story of how we created the vault. We’ll also lay out\nwhat’s in store — and how you can get involved. Let’s get started with a brief\noverview.\n\nSynthetic Data What?\nSynthetic data is a bold new frontier in machine learning. It allows developers\nto share and use data more effectively.\n\nIt may seem counterintuitive, but although billions of gigabytes of data are\nproduced every day, there are still huge gaps in what developers are actually\nable to use. Accessibility concerns, regulatory issues and imbalanced datasets\ncan all keep experts from using data. This impedes progress in finance, health\ncare and other domains.\n\nGood synthetic data can fill these gaps. The SDV uses machine learning to\nanalyze data. Then, it creates fully synthetic datasets that mimic the original.\nAlthough the synthetic data is entirely machine generated, it maintains the\noriginal format and mathematical properties. This makes synthetic data\nversatile. It can completely replace the existing data in a workflow, or it can\nsupplement the data to enhance its utility. Already, our users have successfully\nused the SDV to augment datasets, test applications, remove bias and more.\n\nA History of the SDV\nOur story starts in 2013. In MIT's Laboratory for Information and Decision\nSystems (LIDS), we were working on general data science projects. We had\ndeveloped new techniques, and we were excited to test them on real datasets.\nHowever, as soon as we asked for the data, we hit roadblocks. The process for\ngetting access to data turned out to be much more complex than we anticipated,\nwith many regulations and security red tape. \n\nWe wondered: What if we didn't need the real data in the first place? If we had\nsynthetic data with the same mathematical properties as the original, it would\nbe much easier for everyone to share and use.\n\nIn 2016, we released a paper describing the very first iteration of the SDV\n[https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf]. It introduced a\nnovel technique for synthesizing multi-table data, and included trials where\ndata scientists successfully used synthetic data instead of real data for\nmachine learning tasks. Related research to come out of the lab included CTGAN\n[https://arxiv.org/pdf/1907.00503.pdf], a novel approach to generating synthetic\ndata using deep learning.\n\nAfter these successes in the research community, we decided to move beyond\npurely academic solutions. Synthetic data has the potential to solve real-world\nproblems faced by people on all sides of data science: internal developers\nwriting software, external contractors working offshore, 3rd party partners\noffering services and even the end users who create the data. After some pilot\ntesting on enterprise applications, we open sourced our work in 2018, publishing \nsdv on PyPi [https://pypi.org/project/sdv/] for general use. Open sourcing\noffered ample opportunities for collaboration and customization. It allowed\nusers all over the world to test the SDV in enterprise settings, and helped the\nSDV ecosystem evolve into a one-stop shop for synthetic data needs!\n\nUsers all over the world are using our software to create synthetic data. This\nmap shows the total downloads* of CTGAN [https://github.com/sdv-dev/CTGAN] (our\nmost popular synthetic data model) per continent.We listened to feedback and, as\nof today, have made 93 releases (across all our libraries), addressing 504\nissues. We have been thrilled to see a burgeoning community of invested users\nusing the SDV to solve problems. We've seen over 200K user downloads from PyPi,\n400 stars in the SDV GitHub repository [https://github.com/sdv-dev/SDV] and 200\ndevelopers in our Slack channel. Our community is global and includes people in\ndiverse roles: academics, data scientists, operations managers, engineers and\nmore. We are continually learning from our community, and we're excited to bring\nnew innovations to you!\n\nJust the Beginning\nSynthetic data has the potential to revolutionize the entire field of data\nscience, allowing us to solve problems that once seemed untouchable. We want the\nSynthetic Data Vault to be the most trusted, transparent and comprehensive\nplatform for synthetic data generation, but we can't do it without our users.\nIt's our ever-growing open source community that allows us to quickly repair\nbugs, triage feature requests and improve to serve a variety of real-world\nneeds.\n\nThat’s where you come in. If you’re already a member of this community, we can’t\nthank you enough. And if you’d like to get involved, see below for ways to get\nstarted. Either way, watch this space for more nuanced discussions about\nsynthetic data. We're excited to share what we've learned from you, and show how\nwe are collectively improving the ecosystem. It’s time to open the vault!\n\nWant more ways to get involved?\n\n * Follow us on Twitter @sdv_dev [https://twitter.com/sdv_dev] for release\n   announcements, blog updates and more\n * Join our Slack [https://bit.ly/sdv-slack-invite] community to meet other\n   users, discuss synthetic data solutions and suggest topics for the blog\n * Visit & star our GitHub repositories [https://github.com/sdv-dev]\n * If you've successfully used the SDV for your project, share your experience\n   and tag us\n\nFor other inquiries, please contact us at info@sdv.dev.\n\n\n*Total download statistics per continent come from the Linehaul project\n[https://github.com/pypa/linehaul] using BigQuery, and include mirrors. Are you\naware of more accurate ways to count Python package downloads? Let us know!","html":"<p>Hello world! We, the creators of MIT's Synthetic Data Vault, warmly welcome you to our official blog. Soon we'll be using this space to deep-dive into topics related to our libraries, and to unpack ideas in the synthetic data space. We're looking forward to exploring this exciting area with you.</p><p>But first, we want to properly introduce our project: The <a href=\"https://github.com/sdv-dev/SDV\">Synthetic Data Vault</a> (SDV), an open source software ecosystem for generating synthetic data. In this post, we’ll explain why synthetic data is important, and tell the story of how we created the vault. We’ll also lay out what’s in store — and how you can get involved. Let’s get started with a brief overview.</p><h3 id=\"synthetic-data-what\">Synthetic Data What?</h3><p>Synthetic data is a bold new frontier in machine learning. It allows developers to share and use data more effectively.</p><p>It may seem counterintuitive, but although billions of gigabytes of data are produced every day, there are still huge gaps in what developers are actually able to use. Accessibility concerns, regulatory issues and imbalanced datasets can all keep experts from using data. This impedes progress in finance, health care and other domains.</p><p>Good synthetic data can fill these gaps. The SDV uses machine learning to analyze data. Then, it creates fully synthetic datasets that mimic the original. Although the synthetic data is entirely machine generated, it maintains the original format and mathematical properties. This makes synthetic data versatile. It can completely replace the existing data in a workflow, or it can supplement the data to enhance its utility. Already, our users have successfully used the SDV to augment datasets, test applications, remove bias and more.</p><h3 id=\"a-history-of-the-sdv\">A History of the SDV</h3><p>Our story starts in 2013. In MIT's Laboratory for Information and Decision Systems (LIDS), we were working on general data science projects. We had developed new techniques, and we were excited to test them on real datasets. However, as soon as we asked for the data, we hit roadblocks. The process for getting access to data turned out to be much more complex than we anticipated, with many regulations and security red tape. </p><p>We wondered: What if we didn't need the real data in the first place? If we had synthetic data with the same mathematical properties as the original, it would be much easier for everyone to share and use.</p><p>In 2016, we released a paper describing the very first iteration of the <a href=\"https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf\">SDV</a>. It introduced a novel technique for synthesizing multi-table data, and included trials where data scientists successfully used synthetic data instead of real data for machine learning tasks. Related research to come out of the lab included <a href=\"https://arxiv.org/pdf/1907.00503.pdf\">CTGAN</a>, a novel approach to generating synthetic data using deep learning.</p><p>After these successes in the research community, we decided to move beyond purely academic solutions. Synthetic data has the potential to solve real-world problems faced by people on all sides of data science: internal developers writing software, external contractors working offshore, 3rd party partners offering services and even the end users who create the data. After some pilot testing on enterprise applications, we open sourced our work in 2018, publishing <a href=\"https://pypi.org/project/sdv/\">sdv on PyPi</a> for general use. Open sourcing offered ample opportunities for collaboration and customization. It allowed users all over the world to test the SDV in enterprise settings, and helped the SDV ecosystem evolve into a one-stop shop for synthetic data needs!</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/04/Blog-Map.png\" class=\"kg-image\" alt=\"A world map with download statistics from different continents.\" loading=\"lazy\" width=\"2000\" height=\"1279\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/04/Blog-Map.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/04/Blog-Map.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/04/Blog-Map.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/04/Blog-Map.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Users all over the world are using our software to create synthetic data. This map shows the total downloads* of <a href=\"https://github.com/sdv-dev/CTGAN\">CTGAN</a> (our most popular synthetic data model) per continent.</figcaption></figure><p>We listened to feedback and, as of today, have made 93 releases (across all our libraries), addressing 504 issues. We have been thrilled to see a burgeoning community of invested users using the SDV to solve problems. We've seen over 200K user downloads from PyPi, 400 stars in the SDV <a href=\"https://github.com/sdv-dev/SDV\">GitHub repository</a> and 200 developers in our Slack channel. Our community is global and includes people in diverse roles: academics, data scientists, operations managers, engineers and more. We are continually learning from our community, and we're excited to bring new innovations to you!</p><h3 id=\"just-the-beginning\">Just the Beginning</h3><p>Synthetic data has the potential to revolutionize the entire field of data science, allowing us to solve problems that once seemed untouchable. We want the Synthetic Data Vault to be the most trusted, transparent and comprehensive platform for synthetic data generation, but we can't do it without our users. It's our ever-growing open source community that allows us to quickly repair bugs, triage feature requests and improve to serve a variety of real-world needs.  </p><p>That’s where you come in. If you’re already a member of this community, we can’t thank you enough. And if you’d like to get involved, see below for ways to get started. Either way, watch this space for more nuanced discussions about synthetic data. We're excited to share what we've learned from you, and show how we are collectively improving the ecosystem. It’s time to open the vault!</p><p><strong>Want more ways to get involved?</strong></p><ul><li>Follow us on Twitter <a href=\"https://twitter.com/sdv_dev\">@sdv_dev</a> for release announcements, blog updates and more</li><li>Join our <a href=\"https://bit.ly/sdv-slack-invite\">Slack</a> community to meet other users, discuss synthetic data solutions and suggest topics for the blog</li><li>Visit &amp; star our <a href=\"https://github.com/sdv-dev\">GitHub repositories</a></li><li>If you've successfully used the SDV for your project, share your experience and tag us</li></ul><p>For other inquiries, please contact us at <em><strong>info@sdv.dev</strong></em>.<br></p><p><em>*Total download statistics per continent come from the </em><a href=\"https://github.com/pypa/linehaul\"><em>Linehaul project</em></a><em> using BigQuery, and include mirrors. Are you aware of more accurate ways to count Python package downloads? Let us know!</em></p>","url":"https://sdv.ghost.io/intro-to-sdv/","canonical_url":"https://datacebo.com/blog/intro-to-sdv","uuid":"13e75b5b-86d2-49b0-8940-b8e2861ea952","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"608c5562f9741d003b6f73b8","reading_time":4}}]}},"pageContext":{"slug":"open-source","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":12,"numberOfPages":1,"previousPagePath":"","nextPagePath":""}},"staticQueryHashes":["2061773391","2358152166","2362887240","2439066133","2561578252","2657115718","2731221146","2839364760","4145280475"]}