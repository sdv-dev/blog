{"componentChunkName":"component---src-templates-author-js","path":"/authors/santiago/","result":{"data":{"ghostAuthor":{"slug":"santiago","name":"Santiago Gomez Paz","bio":"Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent a summer interning at DataCebo, learning and experimenting with CTGAN.","cover_image":null,"profile_image":"https://sdv.ghost.io/content/images/2022/10/Santi_Gomez_Paz.jpg","location":"Provo, UT","website":null,"twitter":null,"facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__63a0bc44ac52ed003d6a169a","title":"Interpreting the Progress of CTGAN","slug":"interpreting-ctgan-progress","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2022/12/Header--4-.png","excerpt":"It can be difficult to verify the progress that a GAN is making. What if we combined it with easily interpretable metrics and visualizations?","custom_excerpt":"It can be difficult to verify the progress that a GAN is making. What if we combined it with easily interpretable metrics and visualizations?","visibility":"public","created_at_pretty":"19 December, 2022","published_at_pretty":"20 December, 2022","updated_at_pretty":"23 January, 2023","created_at":"2022-12-19T14:32:20.000-05:00","published_at":"2022-12-20T14:13:29.000-05:00","updated_at":"2023-01-23T17:09:24.000-05:00","meta_title":"Interpreting the Progress of CTGAN","meta_description":"It can be difficult to verify the progress that a GAN is making. What if we combined it with easily interpretable metrics and visualizations?","og_description":null,"og_image":null,"og_title":null,"twitter_description":"It can be difficult to see the progress of a GAN. What if we verify it with metrics and visualizations?","twitter_image":null,"twitter_title":"Interpreting the Progress of CTGAN","authors":[{"name":"Santiago Gomez Paz","slug":"santiago","bio":"Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent a summer interning at DataCebo, learning and experimenting with CTGAN.","profile_image":"https://sdv.ghost.io/content/images/2022/10/Santi_Gomez_Paz.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Santiago Gomez Paz","slug":"santiago","bio":"Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent a summer interning at DataCebo, learning and experimenting with CTGAN.","profile_image":"https://sdv.ghost.io/content/images/2022/10/Santi_Gomez_Paz.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"Our product blog provides insights and tips into creating and deploying high quality synthetic data. We'll support our findings with experiments, illustrations and tutorials.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"This article was researched by Santiago Gomez Paz, a DataCebo intern. Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent his summer learning and experimenting with CTGAN.\n\nThe open source SDV library offers many options for creating synthetic data tables. Some of the library's models use tried-and-true methods from classical statistics, while others use newer innovations like deep learning. One of the newest and most popular models is CTGAN, which uses a type of neural network called a Generative Adversarial Network (GAN).\n\nGenerative models are a popular choice for creating all kinds of synthetic data – for example, you may have heard of OpenAI's DALL-E or ChatGPT tools, which use trained models to create synthetic images and text respectively. A large driver behind their popularity is that they work well — they create synthetic data that closely resembles the real deal. But this high quality often comes at a cost.\n\nGenerative models can be resource-intensive. It can take a lot of time to properly train one, and it's not always clear whether the model is improving much during the training process.\n\nIn this article, we'll unpack this complexity by performing experiments on CTGAN. We'll cover –\n\n * A high-level explanation of how GANs work\n * How to measure and interpret the progress of CTGAN\n * How to confirm this progress with more interpretable, user-centric metrics\n\nSince the library is open source, you can see and run the code yourself with this Colab Notebook.\n\n\nHow do GANs work?\n\nBefore we begin, it's important to understand how GANs work. At a high level, a GAN is an algorithm that makes two neural networks compete against each other (thus the label “Adversarial”). These neural networks are known as the generator and the discriminator, and they each have competing goals:\n\n * The discriminator's goal is to tell real data apart from synthetic data\n * The generator's goal is to create synthetic data that fools the discriminator\n\nThe setup is illustrated below.\n\nThis setup allows us to measure – and improve – both neural networks over many iterations by telling them what they got wrong. Each of these iterations is called an epoch, and CTGAN tracks inaccuracies as loss values. The neural networks are trying to minimize their loss values for every epoch.\n\nThe CTGAN algorithm calculates loss values using a specific formula that can be found in this discussion. The intuition behind it is shown below.\n\nAs shown by the table, lower loss values – even if they are negative – mean that the neural networks are doing well.\n\nAs the epochs progress, we expect both neural networks to improve at their respective goals – but each epoch is resource-intensive and takes time to run. A common request is to find a tradeoff between the improvement achieved and the resources used.\n\n\nMeasuring progress using CTGAN\n\nThe open source SDV library makes it easy to train a CTGAN model and inspect its progress. The code below shows the steps. We train CTGAN using a publicly available SDV demo dataset named RacketSports, which stores various measurements of the strokes that tennis and squash players make over the course of a game.\n\nfrom sdv.demo import load_tabular_demo\nfrom sdv.tabular import CTGAN\n\nmetadata, real_data = load_tabular_demo('RacketSports', metadata=True)\ntable_metadata = metadata.to_dict()\n\nmodel = CTGAN(table_metadata, verbose=True, epochs=800)\nmodel.fit(real_data)\n\nAs part of the fitting process, CTGAN trains the neural networks for multiple epochs. After each epoch, it prints out the count, the generator loss (G) and the discriminator loss (D). Keep in mind that lower numbers are better – even if they are negative. An example is shown below.\n\nEpoch 1, Loss G:  1.0435,Loss D: -0.1401\nEpoch 2, Loss G:  0.4489,Loss D: -0.1455\nEpoch 3, Loss G:  0.4756,Loss D: -0.0956\nEpoch 4, Loss G:  0.3902,Loss D:  0.0344\nEpoch 5, Loss G:  0.0912,Loss D:  0.3030\n...\n\nTo see how the neural networks are improving, we plot the loss values for every epoch. The results from our experiment are shown in the graph below.\n\nBased on the characteristics of this graph, it's possible to deduce how the GAN is progressing.\n\n\nInterpreting the loss values\n\nThe graph above may seem confusing at first glance: Why is the discriminator's loss value score oscillating at 0 if it is supposed to improve (minimize and become negative) over time? The key to interpreting the loss values is to remember that the neural networks are adversaries. As one improves, the other must also improve just to keep its score consistent. Here are three scenarios that we frequently see:\n\n 1. Generator loss is slightly positive while discriminator loss is 0. This means that the generator is producing poor quality synthetic data while the discriminator is blindly guessing what is real vs. synthetic. This is a common starting point, where neither neural network has optimized for its goal.\n 2. Generator loss is becoming negative while the discriminator loss remains at 0. This means that the generator is producing better and better synthetic data. The discriminator is improving too, but because the synthetic data quality has increased, it is still unable to clearly differentiate real vs. synthetic data.\n 3. Generator loss has stabilized at a negative value while the discriminator loss remains at 0. This means that the generator has optimized, creating synthetic data that looks so real, the discriminator cannot tell it apart.\n\nIt is encouraging to see that the general pattern for the RacketSports dataset is similar to a variety of other datasets. These are shown below.\n\nOf course, other patterns may be possible for different datasets. But if loss values are not stabilizing, watch out! This would indicate that the neural networks were not able to effectively learn patterns in the real data.\n\n\nMetrics-Powered Analysis\n\nYou may be wondering whether to trust the loss values. Do they indicate a meaningful difference in synthetic data quality? To answer this question, it's helpful to create synthetic data sets after training the model for different numbers of epochs, and assess the quality of the data sets.\n\nNUM_SYNTHETIC_ROWS = len(real_data)\n\nsynthetic_data = model.sample(num_rows=NUM_SYNTHETIC_ROWS)\n\nIt is important to select a few key metrics for a quantifiable quality measure. For our experiments, we chose 4 metrics from the open source SDMetrics library:\n\n * KSComplement evaluates the shape of numerical columns\n * TVComplement evaluates the shape of discrete columns\n * CorrelationSimilarity evaluates pairwise correlations between columns\n * CategoryCoverage evaluates whether the synthetic data covers all possible values\n\nEach metric produces a score ranging from 0 (worst quality) to 1 (best quality). In the example below, we use the KSComplement metric on a numerical column in the RacketSports dataset.\n\nfrom sdmetrics.single_column import KSComplement\n\nNUMERICAL_COLUMN_NAME='dim_2'\n\nscore = KSComplement.compute(\n   real_data[NUMERICAL_COLUMN_NAME],\n   synthetic_data[NUMERICAL_COLUMN_NAME])\n\nOur results validate that the scores do, indeed, correlate with the loss value from the generator: The quality improves as the loss is minimized. Some of the metrics – such as CorrelationSimilarity and CategoricalCoverage – are high to begin with, so there is not much room to improve. But other metrics, like KSComplement, show significant improvement. This is shown in the graph below.\n\nIt's also possible to visualize the synthetic data that corresponds to a specific metric. For example, KSComplement compares the overall shape of a real and a synthetic data column, so we can visualize it using histograms.\n\nfrom sdmetrics.reports import utils\n\nutils.get_column_plot(\n  real_data,\n  synthetic_data,\n  column_name=NUMERICAL_COLUMN_NAME,\n  metadata=table_metadata)\n\nOverall, we can conclude that the generator and discriminator losses correspond to the quality metrics that we measured – which means we can trust the loss values, as well as the synthetic data that our CTGAN created!\n\n\nConclusion\n\nIn this article, we explored the improvements that the CTGAN model makes as it iterates over many epochs. We started by interpreting the loss values that each of the neural networks – the generator and the discriminator – reports over time. This helped us reason about how they were progressing. But to fully trust the progress of our model, we then turned to the SDMetrics library, which provides metrics that are easier to interpret. Using this library, we could verify whether the reported loss values truly resulted in synthetic data quality improvements.\n\nThis may lead us to a new, potential feature: What if we integrated these easily interpretable, user-centric metrics into the CTGAN training progress? This feature would allow you to specify the exact metrics you'd like to optimize upfront – for example, KSComplement. In addition to the generator and discriminator loss, CTGAN may be able to report a snapshot of this metric. A hypothetical example is shown below.\n\nmodel = CTGAN(\n  table_metadata,\n  verbose=True,\n  epochs=800,\n  optimization_metric='KSComplement',\n  optimization_column='dim_2')\n  \nmodel.fit(real_data)\n\nEpoch 1, Loss G: 1.0435, Loss D: -0.1401, KSComplement: 0.7832\nEpoch 2, Loss G: 0.4489, Loss D: -0.1455, KSComplement: 0.7671\nEpoch 3, Loss G: 0.4756, Loss D: -0.0956, KSComplement: 0.7664\n…\nEpoch 200: Loss G: -2.542, Loss D: 0.0002911, KSComplement: 0.92391\n\n\nSuch a feature would allow more transparency over CTGAN's learning process, and allow you to stop training your models once the metrics are high.\n\nWhat do you think? If you're interested in exploring the inner workings of CTGAN and optimizing your synthetic data, drop us a comment below!","html":"<p><em>This article was researched by Santiago Gomez Paz, a DataCebo intern. Santiago is a Sophomore at BYU and an aspiring entrepreneur who spent his summer learning and experimenting with CTGAN.</em></p><p>The <a href=\"https://github.com/sdv-dev/SDV\">open source SDV library</a> offers many options for creating synthetic data tables. Some of the library's models use tried-and-true methods from classical statistics, while others use newer innovations like deep learning. One of the newest and most popular models is <strong>CTGAN</strong>, which uses a type of neural network called a Generative Adversarial Network (GAN). </p><p>Generative models are a popular choice for creating all kinds of synthetic data – for example, you may have heard of <a href=\"https://openai.com/dall-e-2/\">OpenAI's DALL-E</a> or <a href=\"https://openai.com/blog/chatgpt/\">ChatGPT</a> tools, which use trained models to create synthetic images and text respectively. A large driver behind their popularity is that they work well — they create synthetic data that closely resembles the real deal. But this high quality often comes at a cost.</p><p>Generative models can be resource-intensive. It can take a lot of time to properly train one, and it's not always clear whether the model is improving much during the training process. </p><p>In this article, we'll unpack this complexity by performing experiments on CTGAN. We'll cover –</p><ul><li>A high-level explanation of how GANs work</li><li>How to measure and interpret the progress of CTGAN</li><li>How to confirm this progress with more interpretable, user-centric metrics</li></ul><p>Since the library is open source, you can see and run the code yourself with this <a href=\"https://colab.research.google.com/drive/1RbIYxkbPP3JQY7W0S1p_XprY25wOYTPL?usp=sharing\">Colab Notebook</a>.</p><h3 id=\"how-do-gans-work\">How do GANs work?</h3><p>Before we begin, it's important to understand how GANs work. At a high level, a GAN is an algorithm that makes two neural networks compete against each other (thus the label “Adversarial”). These neural networks are known as the <strong>generator</strong> and the <strong>discriminator</strong>, and they each have competing goals:</p><ul><li>The discriminator's goal is to tell real data apart from synthetic data</li><li>The generator's goal is to create synthetic data that fools the discriminator</li></ul><p>The setup is illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2023/01/How-a-GAN-works-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1000\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/How-a-GAN-works-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/How-a-GAN-works-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/How-a-GAN-works-2.png 1600w, https://sdv.ghost.io/content/images/2023/01/How-a-GAN-works-2.png 2000w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>The <strong>generator</strong> is a neural network that creates synthetic data. In this case, it creates a table describing the names of different people, along with their heights and ages. The <strong>discriminator</strong> is an adversarial network that tries to tell these synthetic people apart from the real ones.</em></figcaption></figure><p>This setup allows us to measure – and improve – both neural networks over many iterations by telling them what they got wrong. Each of these iterations is called an <strong>epoch</strong>, and CTGAN tracks inaccuracies as <strong>loss values</strong>. The neural networks are trying to minimize their loss values for every epoch.</p><p>The CTGAN algorithm calculates loss values using a specific formula that can be found in <a href=\"https://github.com/sdv-dev/SDV/discussions/980\">this discussion</a>. The intuition behind it is shown below.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2023/01/Loss-Values-Interpretation-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"800\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2023/01/Loss-Values-Interpretation-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2023/01/Loss-Values-Interpretation-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2023/01/Loss-Values-Interpretation-2.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2023/01/Loss-Values-Interpretation-2.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>As shown by the table, lower loss values – even if they are <em>negative </em>– mean that the neural networks are doing well.</p><p>As the epochs progress, we expect both neural networks to improve at their respective goals – but each epoch is resource-intensive and takes time to run. A common request is to find a tradeoff between the improvement achieved and the resources used.</p><h3 id=\"measuring-progress-using-ctgan\">Measuring progress using CTGAN</h3><p>The open source SDV library makes it easy to train a CTGAN model and inspect its progress. The code below shows the steps. We train CTGAN using a publicly available SDV demo dataset named <code>RacketSports</code>, which stores various measurements of the strokes that tennis and squash players make over the course of a game.</p><pre><code class=\"language-python\">from sdv.demo import load_tabular_demo\nfrom sdv.tabular import CTGAN\n\nmetadata, real_data = load_tabular_demo('RacketSports', metadata=True)\ntable_metadata = metadata.to_dict()\n\nmodel = CTGAN(table_metadata, verbose=True, epochs=800)\nmodel.fit(real_data)</code></pre><p>As part of the fitting process, CTGAN trains the neural networks for multiple epochs. After each epoch, it prints out the count, the generator loss (G) and the discriminator loss (D). Keep in mind that lower numbers are better – even if they are <em>negative</em>. An example is shown below.</p><pre><code>Epoch 1, Loss G:  1.0435,Loss D: -0.1401\nEpoch 2, Loss G:  0.4489,Loss D: -0.1455\nEpoch 3, Loss G:  0.4756,Loss D: -0.0956\nEpoch 4, Loss G:  0.3902,Loss D:  0.0344\nEpoch 5, Loss G:  0.0912,Loss D:  0.3030\n...</code></pre><p>To see how the neural networks are improving, we plot the loss values for every epoch. The results from our experiment are shown in the graph below. </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/Racket-Sports-Loss.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/Racket-Sports-Loss.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/Racket-Sports-Loss.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/Racket-Sports-Loss.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/Racket-Sports-Loss.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>A graph of the GAN's progress over time. The generator loss is shown in blue, while the discriminator loss for the same epoch is shown in red.</em></figcaption></figure><p>Based on the characteristics of this graph, it's possible to deduce how the GAN is progressing.</p><h3 id=\"interpreting-the-loss-values\">Interpreting the loss values</h3><p>The graph above may seem confusing at first glance: Why is the discriminator's loss value score oscillating at 0 if it is supposed to improve (minimize and become negative) over time? The key to interpreting the loss values is to remember that the neural networks are adversaries. As one improves, the other must also improve just to keep its score consistent. Here are three scenarios that we frequently see:</p><ol><li><strong>Generator loss is slightly positive while discriminator loss is 0. </strong>This means that the generator is producing poor quality synthetic data while the discriminator is blindly guessing what is real vs. synthetic. This is a common starting point, where neither neural network has optimized for its goal.</li><li><strong>Generator loss is becoming negative while the discriminator loss remains at 0.</strong> This means that the generator is producing better and better synthetic data. The discriminator is improving too, but because the synthetic data quality has increased, it is still unable to clearly differentiate real vs. synthetic data.</li><li><strong>Generator loss has stabilized at a negative value while the discriminator loss remains at 0. </strong>This means that the generator has optimized, creating synthetic data that looks so real, the discriminator cannot tell it apart.</li></ol><p>It is encouraging to see that the general pattern for the <code>RacketSports</code> dataset is similar to a variety of other datasets. These are shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/Multi-Datsets.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/Multi-Datsets.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/Multi-Datsets.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/Multi-Datsets.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/Multi-Datsets.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>The generator and discriminator loss values for a variety of other datasets all follow the same learning pattern. The dataset names are shown in <strong>bold.</strong> They can be downloaded from the SDV demo module.</em></figcaption></figure><p>Of course, other patterns may be possible for different datasets. But if loss values are not stabilizing, watch out! This would indicate that the neural networks were not able to effectively learn patterns in the real data.</p><h3 id=\"metrics-powered-analysis\">Metrics-Powered Analysis</h3><p>You may be wondering whether to trust the loss values. Do they indicate a meaningful difference in synthetic data quality? To answer this question, it's helpful to create synthetic data sets after training the model for different numbers of epochs, and assess the quality of the data sets.</p><pre><code class=\"language-python\">NUM_SYNTHETIC_ROWS = len(real_data)\n\nsynthetic_data = model.sample(num_rows=NUM_SYNTHETIC_ROWS)</code></pre><p>It is important to select a few key metrics for a quantifiable quality measure. For our experiments, we chose 4 metrics from the open source <a href=\"https://docs.sdv.dev/sdmetrics/\">SDMetrics library</a>:</p><ul><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/kscomplement\"><strong>KSComplement</strong></a> evaluates the shape of numerical columns</li><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/tvcomplement\"><strong>TVComplement</strong></a> evaluates the shape of discrete columns</li><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/correlationsimilarity\"><strong>CorrelationSimilarity</strong></a> evaluates pairwise correlations between columns</li><li><a href=\"https://docs.sdv.dev/sdmetrics/metrics/metrics-glossary/categorycoverage\"><strong>CategoryCoverage</strong></a> evaluates whether the synthetic data covers all possible values</li></ul><p>Each metric produces a score ranging from 0 (worst quality) to 1 (best quality). In the example below, we use the <code>KSComplement</code> metric on a numerical column in the <code>RacketSports</code> dataset.</p><pre><code class=\"language-python\">from sdmetrics.single_column import KSComplement\n\nNUMERICAL_COLUMN_NAME='dim_2'\n\nscore = KSComplement.compute(\n   real_data[NUMERICAL_COLUMN_NAME],\n   synthetic_data[NUMERICAL_COLUMN_NAME])</code></pre><p>Our results validate that the scores do, indeed, correlate with the loss value from the generator: The quality improves as the loss is minimized. Some of the metrics – such as <code>CorrelationSimilarity</code> and <code>CategoricalCoverage</code> – are high to begin with, so there is not much room to improve. But other metrics, like <code>KSComplement</code>, show significant improvement. This is shown in the graph below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/CTGAN-Loss-vs.-KSComplement.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1290\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/CTGAN-Loss-vs.-KSComplement.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/CTGAN-Loss-vs.-KSComplement.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/CTGAN-Loss-vs.-KSComplement.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/CTGAN-Loss-vs.-KSComplement.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>A comparison of loss values and the KSComplement metric. The two are linked: Lower generator loss (blue) correspond to higher quality scores (green).</em></figcaption></figure><p>It's also possible to visualize the synthetic data that corresponds to a specific metric. For example, <code>KSComplement</code> compares the overall shape of a real and a synthetic data column, so we can visualize it using histograms.</p><pre><code class=\"language-python\">from sdmetrics.reports import utils\n\nutils.get_column_plot(\n  real_data,\n  synthetic_data,\n  column_name=NUMERICAL_COLUMN_NAME,\n  metadata=table_metadata)</code></pre><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2022/12/CTGAN-Epochs-vs.-Improvement.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"645\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/12/CTGAN-Epochs-vs.-Improvement.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/12/CTGAN-Epochs-vs.-Improvement.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2022/12/CTGAN-Epochs-vs.-Improvement.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2022/12/CTGAN-Epochs-vs.-Improvement.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><em>Three histograms were created after training CTGAN for 10, 100 and 500 epochs on the RacketSports dataset. We plotted the dim_2 column. The real data (gray) doesn't change, but the synthetic data (green) improves with more epochs. The KSComplement metric measures the similarity: 0.74, 0.89 and 0.91 (left to right).</em></figcaption></figure><p>Overall, we can conclude that the generator and discriminator losses correspond to the quality metrics that we measured – which means we can trust the loss values, as well as the synthetic data that our CTGAN created!</p><h3 id=\"conclusion\">Conclusion</h3><p>In this article, we explored the improvements that the CTGAN model makes as it iterates over many epochs. We started by interpreting the loss values that each of the neural networks – the generator and the discriminator – reports over time. This helped us reason about how they were progressing. But to fully trust the progress of our model, we then turned to the <a href=\"https://docs.sdv.dev/sdmetrics/\">SDMetrics library</a>, which provides metrics that are easier to interpret. Using this library, we could verify whether the reported loss values truly resulted in synthetic data quality improvements.</p><p>This may lead us to a new, potential feature: What if we integrated these easily interpretable, user-centric metrics into the CTGAN training progress? This feature would allow you to specify the exact metrics you'd like to optimize upfront – for example, KSComplement. In addition to the generator and discriminator loss, CTGAN may be able to report a snapshot of this metric. A hypothetical example is shown below.</p><pre><code class=\"language-python\">model = CTGAN(\n  table_metadata,\n  verbose=True,\n  epochs=800,\n  optimization_metric='KSComplement',\n  optimization_column='dim_2')\n  \nmodel.fit(real_data)</code></pre><pre><code>Epoch 1, Loss G: 1.0435, Loss D: -0.1401, KSComplement: 0.7832\nEpoch 2, Loss G: 0.4489, Loss D: -0.1455, KSComplement: 0.7671\nEpoch 3, Loss G: 0.4756, Loss D: -0.0956, KSComplement: 0.7664\n…\nEpoch 200: Loss G: -2.542, Loss D: 0.0002911, KSComplement: 0.92391\n</code></pre><p>Such a feature would allow more transparency over CTGAN's learning process, and allow you to stop training your models once the metrics are high. </p><p><strong>What do you think? </strong>If you're interested in exploring the inner workings of CTGAN and optimizing your synthetic data, drop us a comment below!</p>","url":"https://sdv.ghost.io/interpreting-ctgan-progress/","canonical_url":"https://datacebo.com/blog/interpreting-ctg-progress","uuid":"b5ed5d15-21b9-4da5-8f28-7682e7522844","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"63a0bc44ac52ed003d6a169a","reading_time":7}}]}},"pageContext":{"slug":"santiago","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":12,"numberOfPages":1,"previousPagePath":"","nextPagePath":""}},"staticQueryHashes":["2061773391","2358152166","2362887240","2439066133","2561578252","2657115718","2731221146","2839364760","4145280475"]}